{
 "cells": [ 
  { 
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from transformers import pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "read=PdfReader(r\"C:\\Users\\sarthak mohapatra\\Downloads\\P2- UQ.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text=''\n",
    "for page_num in range(len(read.pages)):\n",
    "        page = read.pages[page_num]\n",
    "        content = page.extract_text()\n",
    "        raw_text += content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045 /gid00001\n",
      "/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046Citation: Barandas, M.; Folgado, D.;\n",
      "Santos, R.; Simão, R.; Gamboa, H.\n",
      "Uncertainty-Based Rejection in Machine\n",
      "Learning: Implications for Model\n",
      "Development and Interpretability.\n",
      "Electronics 2022 ,11, 396. https://\n",
      "Santos, R.; Simão, R.; Gamboa, H.\n",
      "Uncertainty-Based Rejection in Machine\n",
      "Learning: Implications for Model\n",
      "Development and Interpretability.\n",
      "Electronics 2022 ,11, 396. https://\n",
      "doi.org/10.3390/electronics11030396\n",
      "Academic Editors: Christian\n",
      "Morbidoni, Francesco Di Nardo and\n",
      "Alessandro Cucchiarelli\n",
      "Received: 20 December 2021\n",
      "Accepted: 26 January 2022\n",
      "Published: 28 January 2022\n",
      "Academic Editors: Christian\n",
      "Morbidoni, Francesco Di Nardo and\n",
      "Alessandro Cucchiarelli\n",
      "Received: 20 December 2021\n",
      "Accepted: 26 January 2022\n",
      "Published: 28 January 2022\n",
      "Publisher’s Note: MDPI stays neutral\n",
      "with regard to jurisdictional claims in\n",
      "published maps and institutional afﬁl-\n",
      "iations.\n",
      "Copyright: © 2022 by the authors.\n",
      "Licensee MDPI, Basel, Switzerland.\n",
      "This article is an open access article\n",
      "with regard to jurisdictional claims in\n",
      "published maps and institutional afﬁl-\n",
      "iations.\n",
      "Copyright: © 2022 by the authors.\n",
      "Licensee MDPI, Basel, Switzerland.\n",
      "This article is an open access article\n",
      "distributed under the terms and\n",
      "conditions of the Creative Commons\n",
      "Attribution (CC BY) license (https://\n",
      "creativecommons.org/licenses/by/\n",
      "4.0/).\n",
      "electronics\n",
      "Article\n",
      "distributed under the terms and\n",
      "conditions of the Creative Commons\n",
      "Attribution (CC BY) license (https://\n",
      "creativecommons.org/licenses/by/\n",
      "4.0/).\n",
      "electronics\n",
      "Article\n",
      "Uncertainty-Based Rejection in Machine Learning: Implications\n",
      "for Model Development and Interpretability\n",
      "Marília Barandas1,2,*\n",
      ", Duarte Folgado1,2\n",
      ", Ricardo Santos1,2\n",
      ", Raquel Simão2\n",
      "and Hugo Gamboa1,2\n",
      "for Model Development and Interpretability\n",
      "Marília Barandas1,2,*\n",
      ", Duarte Folgado1,2\n",
      ", Ricardo Santos1,2\n",
      ", Raquel Simão2\n",
      "and Hugo Gamboa1,2\n",
      "1Associação Fraunhofer Portugal Research, Rua Alfredo Allen 455/461, 4200-135 Porto, Portugal;\n",
      "duarte.folgado@fraunhofer.pt (D.F.); ricardo.santos@fraunhofer.pt (R.S.); hugo.gamboa@fraunhofer.pt (H.G.)\n",
      "duarte.folgado@fraunhofer.pt (D.F.); ricardo.santos@fraunhofer.pt (R.S.); hugo.gamboa@fraunhofer.pt (H.G.)\n",
      "2Laboratório de Instrumentação, Engenharia Biomédica e Física da Radiação (LIBPhys-UNL),\n",
      "Departamento de Física, Faculdade de Ciências e Tecnologia, Universidade Nova de Lisboa,\n",
      "2829-516 Caparica, Portugal; rf.simao@campus.fct.unl.pt\n",
      "*Correspondence: marilia.barandas@fraunhofer.pt\n",
      "Departamento de Física, Faculdade de Ciências e Tecnologia, Universidade Nova de Lisboa,\n",
      "2829-516 Caparica, Portugal; rf.simao@campus.fct.unl.pt\n",
      "*Correspondence: marilia.barandas@fraunhofer.pt\n",
      "Abstract: Uncertainty is present in every single prediction of Machine Learning (ML) models. Uncer-\n",
      "tainty Quantiﬁcation (UQ) is arguably relevant, in particular for safety-critical applications. Prior\n",
      "tainty Quantiﬁcation (UQ) is arguably relevant, in particular for safety-critical applications. Prior\n",
      "research focused on the development of methods to quantify uncertainty; however, less attention has\n",
      "been given to how to leverage the knowledge of uncertainty in the process of model development.\n",
      "This work focused on applying UQ into practice, closing the gap of its utility in the ML pipeline\n",
      "been given to how to leverage the knowledge of uncertainty in the process of model development.\n",
      "This work focused on applying UQ into practice, closing the gap of its utility in the ML pipeline\n",
      "and giving insights into how UQ is used to improve model development and its interpretability. We\n",
      "identiﬁed three main research questions: (1) How can UQ contribute to choosing the most suitable\n",
      "and giving insights into how UQ is used to improve model development and its interpretability. We\n",
      "identiﬁed three main research questions: (1) How can UQ contribute to choosing the most suitable\n",
      "model for a given classiﬁcation task? (2) Can UQ be used to combine different models in a prin-\n",
      "cipled manner? (3) Can visualization techniques improve UQ’s interpretability? These questions\n",
      "model for a given classiﬁcation task? (2) Can UQ be used to combine different models in a prin-\n",
      "cipled manner? (3) Can visualization techniques improve UQ’s interpretability? These questions\n",
      "are answered by applying several methods to quantify uncertainty in both a simulated dataset and\n",
      "a real-world dataset of Human Activity Recognition (HAR). Our results showed that uncertainty\n",
      "are answered by applying several methods to quantify uncertainty in both a simulated dataset and\n",
      "a real-world dataset of Human Activity Recognition (HAR). Our results showed that uncertainty\n",
      "quantiﬁcation can increase model robustness and interpretability.\n",
      "Keywords: artiﬁcial intelligence; uncertainty quantiﬁcation; machine learning; rejection option;\n",
      "interpretability; human activity recognition\n",
      "Keywords: artiﬁcial intelligence; uncertainty quantiﬁcation; machine learning; rejection option;\n",
      "interpretability; human activity recognition\n",
      "1. Introduction\n",
      "Machine Learning (ML) has continuously attracted the interest of the research com-\n",
      "munity, motivated by the promising results obtained in many decision-critical domains.\n",
      "1. Introduction\n",
      "Machine Learning (ML) has continuously attracted the interest of the research com-\n",
      "munity, motivated by the promising results obtained in many decision-critical domains.\n",
      "However, we argue that approaches that are safe to use in decision-critical domains must\n",
      "account for the inherent uncertainty in the process [ 1]. ML models learn from data and\n",
      "However, we argue that approaches that are safe to use in decision-critical domains must\n",
      "account for the inherent uncertainty in the process [ 1]. ML models learn from data and\n",
      "use the extracted models to make predictions. Learning from data is inseparably con-\n",
      "nected with uncertainty [ 2]. Thus, the predictions made by ML models have an associated\n",
      "use the extracted models to make predictions. Learning from data is inseparably con-\n",
      "nected with uncertainty [ 2]. Thus, the predictions made by ML models have an associated\n",
      "uncertainty, as they are susceptible to noise and suboptimal model inference. It is highly de-\n",
      "sirable to take into account uncertainty as a path towards trustworthy Artiﬁcial Intelligence\n",
      "uncertainty, as they are susceptible to noise and suboptimal model inference. It is highly de-\n",
      "sirable to take into account uncertainty as a path towards trustworthy Artiﬁcial Intelligence\n",
      "(AI)-based systems. As such, ML models should have the ability to quantify uncertainty in\n",
      "their predictions and abstain from providing a decision when a large amount of uncertainty\n",
      "is present [3].\n",
      "(AI)-based systems. As such, ML models should have the ability to quantify uncertainty in\n",
      "their predictions and abstain from providing a decision when a large amount of uncertainty\n",
      "is present [3].\n",
      "Based on the origin of uncertainty, a distinction between two different sources of uncer-\n",
      "tainty is commonly made: aleatoric and epistemic uncertainty. Aleatoric uncertainty refers\n",
      "is present [3].\n",
      "Based on the origin of uncertainty, a distinction between two different sources of uncer-\n",
      "tainty is commonly made: aleatoric and epistemic uncertainty. Aleatoric uncertainty refers\n",
      "to the notion of randomness, and it is related to the data-measurement process. Epistemic\n",
      "uncertainty refers to the uncertainty associated with the model and by the lack of knowl-\n",
      "to the notion of randomness, and it is related to the data-measurement process. Epistemic\n",
      "uncertainty refers to the uncertainty associated with the model and by the lack of knowl-\n",
      "edge. In principle, epistemic uncertainty can be reduced by extending the training data,\n",
      "better modeling, or better data analysis. Although different types of uncertainty should\n",
      "edge. In principle, epistemic uncertainty can be reduced by extending the training data,\n",
      "better modeling, or better data analysis. Although different types of uncertainty should\n",
      "be measured differently, this distinction in ML has only received attention recently [ 4].\n",
      "In particular, in the literature on deep learning, this distinction has been studied due to\n",
      "be measured differently, this distinction in ML has only received attention recently [ 4].\n",
      "In particular, in the literature on deep learning, this distinction has been studied due to\n",
      "the limited awareness of neural networks of their own conﬁdence. Recently there has\n",
      "In particular, in the literature on deep learning, this distinction has been studied due to\n",
      "the limited awareness of neural networks of their own conﬁdence. Recently there has\n",
      "Electronics 2022 ,11, 396. https://doi.org/10.3390/electronics11030396 https://www.mdpi.com/journal/electronicsElectronics 2022 ,11, 396 2 of 20\n",
      "Electronics 2022 ,11, 396. https://doi.org/10.3390/electronics11030396 https://www.mdpi.com/journal/electronicsElectronics 2022 ,11, 396 2 of 20\n",
      "been more focus on epistemic uncertainty since deep learning models are known as being\n",
      "overconﬁdent with out-of-distribution examples or even adversarial examples [5].\n",
      "Although Uncertainty Quantiﬁcation (UQ) plays an important role in AI deployment\n",
      "overconﬁdent with out-of-distribution examples or even adversarial examples [5].\n",
      "Although Uncertainty Quantiﬁcation (UQ) plays an important role in AI deployment\n",
      "scenarios for cost-sensitive decision-making domains, such as medicine [ 6], it is also an\n",
      "important concept within the ML methodology itself, as for instance, in active learning [ 7,8].\n",
      "scenarios for cost-sensitive decision-making domains, such as medicine [ 6], it is also an\n",
      "important concept within the ML methodology itself, as for instance, in active learning [ 7,8].\n",
      "Recent uncertainty frameworks have been proposed that provide different capabilities to\n",
      "quantify and evaluate uncertainty in the AI development lifecycle [ 9,10]. UQ is important\n",
      "Recent uncertainty frameworks have been proposed that provide different capabilities to\n",
      "quantify and evaluate uncertainty in the AI development lifecycle [ 9,10]. UQ is important\n",
      "across several stakeholders of the ML lifecycle. It helps developers debug their models,\n",
      "in understanding their ﬂaws so they can be used for model improvement. For the users\n",
      "across several stakeholders of the ML lifecycle. It helps developers debug their models,\n",
      "in understanding their ﬂaws so they can be used for model improvement. For the users\n",
      "of AI systems, UQ increases interpretability and trust in model predictions, answering\n",
      "the question: Can I trust this model? For regulators and certiﬁcation bodies, it contributes\n",
      "of AI systems, UQ increases interpretability and trust in model predictions, answering\n",
      "the question: Can I trust this model? For regulators and certiﬁcation bodies, it contributes\n",
      "to algorithm auditing and quality control as a path towards the effective and reliable\n",
      "application of ML systems [11].\n",
      "Previous research has been focused on the development of techniques to characterize\n",
      "application of ML systems [11].\n",
      "Previous research has been focused on the development of techniques to characterize\n",
      "and quantify uncertainty. However, few studies addressed a comprehensive analysis of\n",
      "how UQ can be used to improve model performance and its interpretability. This work\n",
      "focused on leveraging the outcome from uncertainty quantiﬁcation to improve the model\n",
      "how UQ can be used to improve model performance and its interpretability. This work\n",
      "focused on leveraging the outcome from uncertainty quantiﬁcation to improve the model\n",
      "development process. We applied the UQ concept in practice, giving insights into why it\n",
      "can be an effective procedure to improve model development. We identiﬁed the following\n",
      "research questions:\n",
      "development process. We applied the UQ concept in practice, giving insights into why it\n",
      "can be an effective procedure to improve model development. We identiﬁed the following\n",
      "research questions:\n",
      "1. How can UQ contribute to choosing the most suitable model for a given classification task?\n",
      "2. Can UQ be used to combine different models in a principled manner?\n",
      "research questions:\n",
      "1. How can UQ contribute to choosing the most suitable model for a given classification task?\n",
      "2. Can UQ be used to combine different models in a principled manner?\n",
      "3. Can visualization techniques improve UQ’s interpretability?\n",
      "In ML, various criteria can be used in the problem of model selection. Model selection\n",
      "3. Can visualization techniques improve UQ’s interpretability?\n",
      "In ML, various criteria can be used in the problem of model selection. Model selection\n",
      "consists of selecting a ﬁnal model among a collection of candidates for a training dataset. It\n",
      "can be applied either to different types of models or the same type conﬁgured with different\n",
      "consists of selecting a ﬁnal model among a collection of candidates for a training dataset. It\n",
      "can be applied either to different types of models or the same type conﬁgured with different\n",
      "hyperparameters. The main goal of model selection is to achieve the best predictive\n",
      "performance for modeling learning data and for making predictions for new examples that\n",
      "hyperparameters. The main goal of model selection is to achieve the best predictive\n",
      "performance for modeling learning data and for making predictions for new examples that\n",
      "were not included in the learning process [ 12,13]. In supervised learning, the predictive\n",
      "accuracy is usually considered as the most important criterion for model selection. However,\n",
      "were not included in the learning process [ 12,13]. In supervised learning, the predictive\n",
      "accuracy is usually considered as the most important criterion for model selection. However,\n",
      "various criteria for the predictive model quality, such as interpretability or computational\n",
      "cost, can also play a key role in model selection. To the best of our knowledge, uncertainty is\n",
      "various criteria for the predictive model quality, such as interpretability or computational\n",
      "cost, can also play a key role in model selection. To the best of our knowledge, uncertainty is\n",
      "not being considered as criterion for model selection. Question 1 addresses how uncertainty\n",
      "might contribute to model characterization with valuable quantitative information, either\n",
      "not being considered as criterion for model selection. Question 1 addresses how uncertainty\n",
      "might contribute to model characterization with valuable quantitative information, either\n",
      "by describing the quality of the model’s ﬁt or evaluating if sufﬁcient training data were\n",
      "provided to calculate trustworthy predictions.\n",
      "by describing the quality of the model’s ﬁt or evaluating if sufﬁcient training data were\n",
      "provided to calculate trustworthy predictions.\n",
      "It is often found that, in particularly complex classiﬁcation problems, performance\n",
      "can be improved by combining multiple models, instead of just using a single one. There\n",
      "are several combination rules to train and combine different models. Some rules address\n",
      "can be improved by combining multiple models, instead of just using a single one. There\n",
      "are several combination rules to train and combine different models. Some rules address\n",
      "models’ combination using the average of the predictions or the class probabilities. Nev-\n",
      "ertheless, the uncertainty of multiple models is seldom considered. With Question 2, we\n",
      "models’ combination using the average of the predictions or the class probabilities. Nev-\n",
      "ertheless, the uncertainty of multiple models is seldom considered. With Question 2, we\n",
      "address how uncertainty can be taken into account for model combination.\n",
      "In ordinary classiﬁcation, the classiﬁer is usually forced to predict a label. For difﬁcult\n",
      "address how uncertainty can be taken into account for model combination.\n",
      "In ordinary classiﬁcation, the classiﬁer is usually forced to predict a label. For difﬁcult\n",
      "samples, it might lead to misclassiﬁcation, which may cause problems in risk-sensitive\n",
      "applications. In these scenarios, it will be more appropriate to avoid making decisions\n",
      "samples, it might lead to misclassiﬁcation, which may cause problems in risk-sensitive\n",
      "applications. In these scenarios, it will be more appropriate to avoid making decisions\n",
      "on the difﬁcult cases in anticipation of a lower error rate on those examples for which\n",
      "a classiﬁcation decision is made [ 3]. This approach is known as classiﬁcation with a\n",
      "on the difﬁcult cases in anticipation of a lower error rate on those examples for which\n",
      "a classiﬁcation decision is made [ 3]. This approach is known as classiﬁcation with a\n",
      "rejecting option. In addition to quantitative methods for sample rejection, it is important\n",
      "to provide the interpretability of why a particular sample was rejected. In this context,\n",
      "rejecting option. In addition to quantitative methods for sample rejection, it is important\n",
      "to provide the interpretability of why a particular sample was rejected. In this context,\n",
      "Neto et al. [14] proposed a visualization explainable matrix applied to random forests\n",
      "with a focus on global and local explanations where conﬁdence scores were used as an\n",
      "Neto et al. [14] proposed a visualization explainable matrix applied to random forests\n",
      "with a focus on global and local explanations where conﬁdence scores were used as an\n",
      "interpretability measure. However, with regard to uncertainty visualization for a given\n",
      "prediction or applied to the model itself, few or no studies have considered this in theElectronics 2022 ,11, 396 3 of 20\n",
      "prediction or applied to the model itself, few or no studies have considered this in theElectronics 2022 ,11, 396 3 of 20\n",
      "literature. Therefore, Question 3 addresses how visualization techniques might be used to\n",
      "improve UQ’s interpretability.\n",
      "The remainder of this paper is organized as follows: In Section 2, we introduce the\n",
      "improve UQ’s interpretability.\n",
      "The remainder of this paper is organized as follows: In Section 2, we introduce the\n",
      "background concepts and related work. Section 3 contains a thorough description of the\n",
      "methods used to answer the research questions. Section 4 contains experimental results,\n",
      "and in Section 5, we detail the conclusions and discuss possible directions for future work.\n",
      "methods used to answer the research questions. Section 4 contains experimental results,\n",
      "and in Section 5, we detail the conclusions and discuss possible directions for future work.\n",
      "2. Background and Related Work\n",
      "The awareness of uncertainty is of major importance in ML and constitutes a key\n",
      "element of its methodology. Traditionally, uncertainty in ML is modeled using probability\n",
      "2. Background and Related Work\n",
      "The awareness of uncertainty is of major importance in ML and constitutes a key\n",
      "element of its methodology. Traditionally, uncertainty in ML is modeled using probability\n",
      "theory, which has always been perceived as the reference tool for uncertainty handling [ 4].\n",
      "In the recent ML literature, two inherently different sources of uncertainty are commonly\n",
      "theory, which has always been perceived as the reference tool for uncertainty handling [ 4].\n",
      "In the recent ML literature, two inherently different sources of uncertainty are commonly\n",
      "distinguished, referred to as aleatoric and epistemic [ 15]. Aleatoric uncertainty refers to\n",
      "the notion of randomness and cannot be reduced by adding more samples to the training\n",
      "distinguished, referred to as aleatoric and epistemic [ 15]. Aleatoric uncertainty refers to\n",
      "the notion of randomness and cannot be reduced by adding more samples to the training\n",
      "process. On the other hand, epistemic uncertainty refers to the uncertainty caused by a lack\n",
      "of knowledge, either due to the uncertainty associated with the model or the lack of data.\n",
      "process. On the other hand, epistemic uncertainty refers to the uncertainty caused by a lack\n",
      "of knowledge, either due to the uncertainty associated with the model or the lack of data.\n",
      "In principle, this uncertainty can be reduced by adding more training data.\n",
      "In the following subsections, we present an overview of previous works that have\n",
      "In principle, this uncertainty can be reduced by adding more training data.\n",
      "In the following subsections, we present an overview of previous works that have\n",
      "explored different strategies for UQ and methods about classiﬁcation with rejection.\n",
      "2.1. Uncertainty Quantiﬁcation\n",
      "In standard probabilistic modeling and Bayesian inference, the representation of\n",
      "explored different strategies for UQ and methods about classiﬁcation with rejection.\n",
      "2.1. Uncertainty Quantiﬁcation\n",
      "In standard probabilistic modeling and Bayesian inference, the representation of\n",
      "uncertainty about a prediction is given by the posterior distribution. Let us consider a ﬁnite\n",
      "training dataset, D=f(xi,wi)gN\n",
      "i, with Nsamples, composed of pairs of input features\n",
      "uncertainty about a prediction is given by the posterior distribution. Let us consider a ﬁnite\n",
      "training dataset, D=f(xi,wi)gN\n",
      "i, with Nsamples, composed of pairs of input features\n",
      "xand labels w, where wk2fw1, ...,wKgconsists of a ﬁnite set of Kclass labels. Suppose\n",
      "a hypothesis space of probabilistic predictors, where a hypothesis hmaps instances x\n",
      "xand labels w, where wk2fw1, ...,wKgconsists of a ﬁnite set of Kclass labels. Suppose\n",
      "a hypothesis space of probabilistic predictors, where a hypothesis hmaps instances x\n",
      "to probability distributions on outcomes w. Each hypothesis can be considered as an\n",
      "explanation of how the world works. Samples from the posterior distribution should\n",
      "to probability distributions on outcomes w. Each hypothesis can be considered as an\n",
      "explanation of how the world works. Samples from the posterior distribution should\n",
      "yield explanations consistent with the observations of the world contained within the\n",
      "training data, D[16]. From a Bayesian perspective, each hypothesis is equipped with a\n",
      "yield explanations consistent with the observations of the world contained within the\n",
      "training data, D[16]. From a Bayesian perspective, each hypothesis is equipped with a\n",
      "prior distribution p(h), and the posterior distribution, p(hjD), can be computed via the\n",
      "Bayes rule:\n",
      "p(hjD) =p(Djh)p(h)\n",
      "p(D)(1)\n",
      "where p(Djh)is the probability of the data given h, i.e., the likelihood of the parameters h.\n",
      "Bayes rule:\n",
      "p(hjD) =p(Djh)p(h)\n",
      "p(D)(1)\n",
      "where p(Djh)is the probability of the data given h, i.e., the likelihood of the parameters h.\n",
      "For a given instance x, the predictive uncertainty of a classiﬁcation model depends\n",
      "on how the uncertainty is represented as a basis for prediction and decision-making. In\n",
      "Bayesian inference, the belief about the outcome wkis represented by a second-order\n",
      "on how the uncertainty is represented as a basis for prediction and decision-making. In\n",
      "Bayesian inference, the belief about the outcome wkis represented by a second-order\n",
      "probability: a probability distribution of probability distributions [ 15]. In this type of\n",
      "Bayesian inference, a given prediction is obtained through model averaging, i.e., different\n",
      "probability: a probability distribution of probability distributions [ 15]. In this type of\n",
      "Bayesian inference, a given prediction is obtained through model averaging, i.e., different\n",
      "hypotheses hprovide predictions, which are aggregated in terms of a weighted average.\n",
      "Thus, the predictive posterior distribution is given by:\n",
      "p(wjx) =Z\n",
      "p(wjx,h)dP(hjD) (2)\n",
      "hypotheses hprovide predictions, which are aggregated in terms of a weighted average.\n",
      "Thus, the predictive posterior distribution is given by:\n",
      "p(wjx) =Z\n",
      "p(wjx,h)dP(hjD) (2)\n",
      "Thus, the predicted probability of an outcome wis the expected probability p(wjx,h),\n",
      "where the expectation over the hypotheses is taken with respect to the posterior distribution,\n",
      "p(wjx,h)dP(hjD) (2)\n",
      "Thus, the predicted probability of an outcome wis the expected probability p(wjx,h),\n",
      "where the expectation over the hypotheses is taken with respect to the posterior distribution,\n",
      "P(hjD). However, since model averaging is often difﬁcult and computationally costly, in\n",
      "ML, it is common to make predictions considering a single probability distribution for each\n",
      "P(hjD). However, since model averaging is often difﬁcult and computationally costly, in\n",
      "ML, it is common to make predictions considering a single probability distribution for each\n",
      "class. The most well-known measure of uncertainty of a single probability distribution, p,\n",
      "is the (Shannon) entropy, which for discrete class labels is given as:\n",
      "H(p) =\u0000K\n",
      "å\n",
      "class. The most well-known measure of uncertainty of a single probability distribution, p,\n",
      "is the (Shannon) entropy, which for discrete class labels is given as:\n",
      "H(p) =\u0000K\n",
      "å\n",
      "k=1p(w)log2p(w) (3)Electronics 2022 ,11, 396 4 of 20\n",
      "This measure of uncertainty primarily captures the shape of the distribution and,\n",
      "hence, is mostly concerned with the aleatoric part of the overall uncertainty.\n",
      "This measure of uncertainty primarily captures the shape of the distribution and,\n",
      "hence, is mostly concerned with the aleatoric part of the overall uncertainty.\n",
      "In order to account for both aleatoric and epistemic uncertainty, the Bayesian per-\n",
      "spective is quite common in ML, where the (total) uncertainty is quantiﬁed on the basis\n",
      "In order to account for both aleatoric and epistemic uncertainty, the Bayesian per-\n",
      "spective is quite common in ML, where the (total) uncertainty is quantiﬁed on the basis\n",
      "of the predictive posterior distribution. In the context of neural networks for regression,\n",
      "Depeweg et al. [ 17] proposed an approach to quantify and separate uncertainties with\n",
      "of the predictive posterior distribution. In the context of neural networks for regression,\n",
      "Depeweg et al. [ 17] proposed an approach to quantify and separate uncertainties with\n",
      "classical information-theoretic measures. The authors’ idea was more general and can\n",
      "also be applied to other settings, such as in the work of Shaker et al. [ 18], where mea-\n",
      "classical information-theoretic measures. The authors’ idea was more general and can\n",
      "also be applied to other settings, such as in the work of Shaker et al. [ 18], where mea-\n",
      "sures of entropy were applied using a random forest classiﬁer, or the work of Andrey\n",
      "Malinin et al. [16], who adopted these measures in the context of gradient boosting models.\n",
      "sures of entropy were applied using a random forest classiﬁer, or the work of Andrey\n",
      "Malinin et al. [16], who adopted these measures in the context of gradient boosting models.\n",
      "More speciﬁcally, Depeweg et al. [ 17] proposed to measure the total uncertainty in terms of\n",
      "the entropy of the predictive posterior distribution, H[p(wjx)], and measure the aleatoric\n",
      "More speciﬁcally, Depeweg et al. [ 17] proposed to measure the total uncertainty in terms of\n",
      "the entropy of the predictive posterior distribution, H[p(wjx)], and measure the aleatoric\n",
      "uncertainty in terms of the expectation of entropy with regard to the posterior probability,\n",
      "Ep(hjD)H[p(wjx,h)]. The aleatoric uncertainty is measured in terms of the expectation over\n",
      "uncertainty in terms of the expectation of entropy with regard to the posterior probability,\n",
      "Ep(hjD)H[p(wjx,h)]. The aleatoric uncertainty is measured in terms of the expectation over\n",
      "the entropies of distributions, since his not precisely known. However, the idea is that by\n",
      "ﬁxing a hypothesis h, the epistemic uncertainty is essentially removed. Then, the epistemic\n",
      "the entropies of distributions, since his not precisely known. However, the idea is that by\n",
      "ﬁxing a hypothesis h, the epistemic uncertainty is essentially removed. Then, the epistemic\n",
      "uncertainty is measured in terms of the mutual information between hypotheses and out-\n",
      "comes, I(w,hjx,D). Epistemic uncertainty is high if the distribution p(wjx,h)varies greatly\n",
      "uncertainty is measured in terms of the mutual information between hypotheses and out-\n",
      "comes, I(w,hjx,D). Epistemic uncertainty is high if the distribution p(wjx,h)varies greatly\n",
      "for different hypotheses hwith high probability, but leading to quite different predictions.\n",
      "Due to the computational complexity of these measures, which involve the integration\n",
      "for different hypotheses hwith high probability, but leading to quite different predictions.\n",
      "Due to the computational complexity of these measures, which involve the integration\n",
      "over the hypothesis space, an approximation by means of ensemble techniques, based on\n",
      "an ensemble of Mhypotheses, can be obtained using the following equations:\n",
      "ualeat(x) =Ep(hjD)H[p(wjx,h)]\u00191\n",
      "MM\n",
      "å\n",
      "i=1H[p(wjx,hi)] (4)\n",
      "an ensemble of Mhypotheses, can be obtained using the following equations:\n",
      "ualeat(x) =Ep(hjD)H[p(wjx,h)]\u00191\n",
      "MM\n",
      "å\n",
      "i=1H[p(wjx,hi)] (4)\n",
      "utotal(x) =H[Ep(hjD)p(wjx,h)]\u0019H\"\n",
      "1\n",
      "MM\n",
      "å\n",
      "i=1P(wjx,hi)#\n",
      "(5)\n",
      "uepist(x) =I(w,hjx,D) =H[Ep(hjD)p(wjx,h)]\u0000Ep(hjD)H[p(wjx,h)] (6)\n",
      "Besides the classical information-theoretic measures, the bootstrap method [ 19] is also\n",
      "1\n",
      "MM\n",
      "å\n",
      "i=1P(wjx,hi)#\n",
      "(5)\n",
      "uepist(x) =I(w,hjx,D) =H[Ep(hjD)p(wjx,h)]\u0000Ep(hjD)H[p(wjx,h)] (6)\n",
      "Besides the classical information-theoretic measures, the bootstrap method [ 19] is also\n",
      "a common approach to estimate uncertainty. In order to quantify the uncertainty in the\n",
      "results of a given algorithm, the sampling distribution of a parameter of interest is required.\n",
      "a common approach to estimate uncertainty. In order to quantify the uncertainty in the\n",
      "results of a given algorithm, the sampling distribution of a parameter of interest is required.\n",
      "Because data represent one collection of observable data, resampling methods that generate\n",
      "additional representative samples in order to obtain a sampling distribution are used [ 20].\n",
      "Because data represent one collection of observable data, resampling methods that generate\n",
      "additional representative samples in order to obtain a sampling distribution are used [ 20].\n",
      "The bootstrap method uses Monte Carlo simulation to approximate the sampling\n",
      "distribution by repeatedly simulating bootstrap samples, which are new datasets created\n",
      "The bootstrap method uses Monte Carlo simulation to approximate the sampling\n",
      "distribution by repeatedly simulating bootstrap samples, which are new datasets created\n",
      "by sampling with replacement from the uniform distribution over the original dataset. To\n",
      "bootstrap a supervised learning algorithm, one would need to sample Sbootstrap datasets\n",
      "and run the learning procedure from scratch each time.\n",
      "bootstrap a supervised learning algorithm, one would need to sample Sbootstrap datasets\n",
      "and run the learning procedure from scratch each time.\n",
      "A measure to quantify uncertainty using the bootstrap method is the variation ratios.\n",
      "Variation ratios measure the variability of the predictions obtained from sampling by\n",
      "A measure to quantify uncertainty using the bootstrap method is the variation ratios.\n",
      "Variation ratios measure the variability of the predictions obtained from sampling by\n",
      "computing the fraction of samples with the correct output. This heuristic is a measure of\n",
      "the dispersion of the predictions around its mode [ 21]. For a given instance x, the variation\n",
      "ratios are computed as follows:\n",
      "VR=1\u0000fw\u0003\n",
      "the dispersion of the predictions around its mode [ 21]. For a given instance x, the variation\n",
      "ratios are computed as follows:\n",
      "VR=1\u0000fw\u0003\n",
      "S(7)\n",
      "where fwk=åS\n",
      "i=11[wi=w\u0003]andw\u0003corresponds to the sampled majority class,\n",
      "w\u0003=arg max\n",
      "w=w1,...,wKS\n",
      "å\n",
      "i=11[wi=w] (8)\n",
      "Additionally, measures for novelty, anomaly, or outlier detection, where testing sam-\n",
      "where fwk=åS\n",
      "i=11[wi=w\u0003]andw\u0003corresponds to the sampled majority class,\n",
      "w\u0003=arg max\n",
      "w=w1,...,wKS\n",
      "å\n",
      "i=11[wi=w] (8)\n",
      "Additionally, measures for novelty, anomaly, or outlier detection, where testing sam-\n",
      "ples come from a different population than the training set, can also be used to quantifyElectronics 2022 ,11, 396 5 of 20\n",
      "ples come from a different population than the training set, can also be used to quantifyElectronics 2022 ,11, 396 5 of 20\n",
      "uncertainty. In this scenario, the open set recognition and out-of-distribution problems are\n",
      "commonly mentioned [ 22]. Approaches based on generative models typically use densities\n",
      "to decide whether to reject a test input that is located in a region without training inputs.\n",
      "commonly mentioned [ 22]. Approaches based on generative models typically use densities\n",
      "to decide whether to reject a test input that is located in a region without training inputs.\n",
      "These low-density regions, where no training inputs have been encountered so far, repre-\n",
      "sent a high knowledge uncertainty. Traditional methods, such as Kernel Density Estimation\n",
      "These low-density regions, where no training inputs have been encountered so far, repre-\n",
      "sent a high knowledge uncertainty. Traditional methods, such as Kernel Density Estimation\n",
      "(KDE), can be used to estimate densities, and often, threshold-based methods are applied\n",
      "on top of the density where a classiﬁer can refuse to predict a test input in that region [ 23].\n",
      "(KDE), can be used to estimate densities, and often, threshold-based methods are applied\n",
      "on top of the density where a classiﬁer can refuse to predict a test input in that region [ 23].\n",
      "In this context, Knowledge Uncertainty Estimation (KUE) [ 24] learns the feature density\n",
      "estimation from the training data, to reject test inputs that represent a density different\n",
      "In this context, Knowledge Uncertainty Estimation (KUE) [ 24] learns the feature density\n",
      "estimation from the training data, to reject test inputs that represent a density different\n",
      "from the training dataset. For a test input xi, represented by P-dimensional feature vectors,\n",
      "where fj2ff1,. . .,fPgis the feature vector in a bounded area of the feature space and wk\n",
      "from the training dataset. For a test input xi, represented by P-dimensional feature vectors,\n",
      "where fj2ff1,. . .,fPgis the feature vector in a bounded area of the feature space and wk\n",
      "is the predicted class, the KUE measure is calculated as follows:\n",
      "KUE(xijwk) =1\u0000 \n",
      "P\n",
      "Õ\n",
      "j=1dunc(fjjwk,xi)!1\n",
      "P\n",
      "(9)\n",
      "where duncis an uncertainty distance obtained from the feature density, assuming values\n",
      "is the predicted class, the KUE measure is calculated as follows:\n",
      "KUE(xijwk) =1\u0000 \n",
      "P\n",
      "Õ\n",
      "j=1dunc(fjjwk,xi)!1\n",
      "P\n",
      "(9)\n",
      "where duncis an uncertainty distance obtained from the feature density, assuming values\n",
      "in the interval [0, 1], where one represents the maximum density seen in training and\n",
      "near-zero values represent low-density regions where no training inputs were observed\n",
      "during training.\n",
      "in the interval [0, 1], where one represents the maximum density seen in training and\n",
      "near-zero values represent low-density regions where no training inputs were observed\n",
      "during training.\n",
      "2.2. Classiﬁcation with the Rejection Option\n",
      "The process of abstaining from producing an answer or discarding a prediction when\n",
      "the system is not conﬁdent enough is more than 60 years old and was introduced by\n",
      "The process of abstaining from producing an answer or discarding a prediction when\n",
      "the system is not conﬁdent enough is more than 60 years old and was introduced by\n",
      "Chow [ 25]. Chow’s theory suggests that objects are rejected for which the maximum\n",
      "posterior probability is below a threshold. If the classiﬁer is not sufﬁciently accurate for\n",
      "Chow [ 25]. Chow’s theory suggests that objects are rejected for which the maximum\n",
      "posterior probability is below a threshold. If the classiﬁer is not sufﬁciently accurate for\n",
      "the task at hand, then one can take the approach not to classify all examples, but only\n",
      "those whose posterior probability is sufﬁciently high. Chow’s theory is suitable when a\n",
      "the task at hand, then one can take the approach not to classify all examples, but only\n",
      "those whose posterior probability is sufﬁciently high. Chow’s theory is suitable when a\n",
      "sufﬁciently large training sample is available for all classes and when the training sample\n",
      "is not contaminated by outliers [ 26]. Fumera et al. [ 27] showed that Chow’s rule does not\n",
      "sufﬁciently large training sample is available for all classes and when the training sample\n",
      "is not contaminated by outliers [ 26]. Fumera et al. [ 27] showed that Chow’s rule does not\n",
      "perform well if a signiﬁcant error in the probability estimation is present. In that case, a\n",
      "different rejection threshold per class has to be used. In classiﬁers with a rejection option,\n",
      "perform well if a signiﬁcant error in the probability estimation is present. In that case, a\n",
      "different rejection threshold per class has to be used. In classiﬁers with a rejection option,\n",
      "the key parameters are the thresholds that deﬁne the rejection area, which may be hard to\n",
      "deﬁne and may vary signiﬁcantly in value, especially when classes have a large spread.\n",
      "the key parameters are the thresholds that deﬁne the rejection area, which may be hard to\n",
      "deﬁne and may vary signiﬁcantly in value, especially when classes have a large spread.\n",
      "In these kinds of methods, the rejection is mostly applied to samples with high\n",
      "aleatoric uncertainty, since it has been argued that probability distributions are less suitable\n",
      "In these kinds of methods, the rejection is mostly applied to samples with high\n",
      "aleatoric uncertainty, since it has been argued that probability distributions are less suitable\n",
      "for representing ignorance in the sense of a lack of knowledge [ 4]. Alternatively, more\n",
      "recent works [ 15,18,21] included the classiﬁcation with rejection with a distinction between\n",
      "for representing ignorance in the sense of a lack of knowledge [ 4]. Alternatively, more\n",
      "recent works [ 15,18,21] included the classiﬁcation with rejection with a distinction between\n",
      "aleatoric and epistemic uncertainty using ensemble techniques and/or deep learning\n",
      "approaches. For the classiﬁcation with rejection, a conﬁdence threshold value needs to be\n",
      "aleatoric and epistemic uncertainty using ensemble techniques and/or deep learning\n",
      "approaches. For the classiﬁcation with rejection, a conﬁdence threshold value needs to be\n",
      "deﬁned indicating the rejection point. Different cost-based rejection methods have been\n",
      "proposed to minimize the classiﬁcation risk [ 28–30]. In probabilistic classiﬁers, risk can\n",
      "deﬁned indicating the rejection point. Different cost-based rejection methods have been\n",
      "proposed to minimize the classiﬁcation risk [ 28–30]. In probabilistic classiﬁers, risk can\n",
      "derive from the observation of the output probabilities employing different metrics, such\n",
      "as the least conﬁdence, margin of conﬁdence, variation ratios, and predictive entropy [ 31].\n",
      "derive from the observation of the output probabilities employing different metrics, such\n",
      "as the least conﬁdence, margin of conﬁdence, variation ratios, and predictive entropy [ 31].\n",
      "The evaluation of the performance of classiﬁers with rejection usually uses standard\n",
      "metrics, such as accuracy, to obtain an Accuracy-Rejection Curve (ARC) [ 32]. According to\n",
      "The evaluation of the performance of classiﬁers with rejection usually uses standard\n",
      "metrics, such as accuracy, to obtain an Accuracy-Rejection Curve (ARC) [ 32]. According to\n",
      "Nadeem et al. [ 32], an ARC is a function representing the accuracy of a classiﬁer as a function\n",
      "of its rejection rate. Therefore, the ARCs plot the rejection rate of the metrics (from 0–1)\n",
      "Nadeem et al. [ 32], an ARC is a function representing the accuracy of a classiﬁer as a function\n",
      "of its rejection rate. Therefore, the ARCs plot the rejection rate of the metrics (from 0–1)\n",
      "against the accuracy of the classiﬁer. Since the accuracy is always 100% when the rejection\n",
      "rate is one, all curves converge to the point (1, 1), and they start from the point (0,a), where\n",
      "against the accuracy of the classiﬁer. Since the accuracy is always 100% when the rejection\n",
      "rate is one, all curves converge to the point (1, 1), and they start from the point (0,a), where\n",
      "ais the initial accuracy of the classiﬁer, with 0% of rejected samples. Using this approach, it\n",
      "is not possible to determine the optimal rejection rate by comparing the performance of\n",
      "ais the initial accuracy of the classiﬁer, with 0% of rejected samples. Using this approach, it\n",
      "is not possible to determine the optimal rejection rate by comparing the performance of\n",
      "the classiﬁers. Although there are other metrics for evaluating classiﬁers with rejection,\n",
      "they are centered only on the nonrejected accuracy as a core component of ARCs [ 33].Electronics 2022 ,11, 396 6 of 20\n",
      "they are centered only on the nonrejected accuracy as a core component of ARCs [ 33].Electronics 2022 ,11, 396 6 of 20\n",
      "Condessa et al. [ 33] expanded the set of performance measures for classiﬁcation with\n",
      "rejection and, besides the nonrejected accuracy, proposed two novel performance measures\n",
      "to evaluate the best rejection point, namely classiﬁcation quality and rejection quality.\n",
      "rejection and, besides the nonrejected accuracy, proposed two novel performance measures\n",
      "to evaluate the best rejection point, namely classiﬁcation quality and rejection quality.\n",
      "Considering a partition of a set of samples in subsets A,M,N, and R, where Ais a\n",
      "subset of accurately classiﬁed samples, Mis a subset of misclassiﬁed samples, Nis a subset\n",
      "Considering a partition of a set of samples in subsets A,M,N, and R, where Ais a\n",
      "subset of accurately classiﬁed samples, Mis a subset of misclassiﬁed samples, Nis a subset\n",
      "of nonrejected samples, and Ris a subset of the rejected samples, each metric can be derived\n",
      "as follows:\n",
      "• Nonrejected accuracy measures the ability of the classiﬁer to accurately classify nonre-\n",
      "of nonrejected samples, and Ris a subset of the rejected samples, each metric can be derived\n",
      "as follows:\n",
      "• Nonrejected accuracy measures the ability of the classiﬁer to accurately classify nonre-\n",
      "jected samples, and it is computed as,\n",
      "NRA =jA\\Nj\n",
      "jNj; (10)\n",
      "• Classiﬁcation quality measures the ability of the classiﬁer with rejection to accurately\n",
      "jected samples, and it is computed as,\n",
      "NRA =jA\\Nj\n",
      "jNj; (10)\n",
      "• Classiﬁcation quality measures the ability of the classiﬁer with rejection to accurately\n",
      "classify nonrejected samples and to reject misclassiﬁed samples. It is computed as,\n",
      "CQ=jA\\Nj+jM\\Rj\n",
      "jNj+jRj; (11)\n",
      "• Rejection quality measures the ability of the classiﬁer with rejection to make errors on\n",
      "rejected samples only, and it is computed as,\n",
      "CQ=jA\\Nj+jM\\Rj\n",
      "jNj+jRj; (11)\n",
      "• Rejection quality measures the ability of the classiﬁer with rejection to make errors on\n",
      "rejected samples only, and it is computed as,\n",
      "RQ=jM\\RjjAj\n",
      "jA\\RjjMj. (12)\n",
      "The nonrejected accuracy and the classiﬁcation quality are bounded in the interval\n",
      "[0, 1]. Unlike these measures, the rejection quality has a minimum value of zero, and its\n",
      "RQ=jM\\RjjAj\n",
      "jA\\RjjMj. (12)\n",
      "The nonrejected accuracy and the classiﬁcation quality are bounded in the interval\n",
      "[0, 1]. Unlike these measures, the rejection quality has a minimum value of zero, and its\n",
      "maximum is unbounded by construction. Nonetheless, the higher the values, the better the\n",
      "metric performs for rejection.\n",
      "3. Methods\n",
      "maximum is unbounded by construction. Nonetheless, the higher the values, the better the\n",
      "metric performs for rejection.\n",
      "3. Methods\n",
      "In this work, we considered the uncertainty estimation problem in a traditional ML\n",
      "classiﬁcation setting. Besides the common division between aleatoric and epistemic uncer-\n",
      "tainty, we further divided the epistemic uncertainty into two additional categories, namely\n",
      "classiﬁcation setting. Besides the common division between aleatoric and epistemic uncer-\n",
      "tainty, we further divided the epistemic uncertainty into two additional categories, namely\n",
      "knowledge and model uncertainty. Although these terms are commonly used to refer to the\n",
      "broad view of epistemic uncertainty, we refer to knowledge uncertainty as the uncertainty\n",
      "knowledge and model uncertainty. Although these terms are commonly used to refer to the\n",
      "broad view of epistemic uncertainty, we refer to knowledge uncertainty as the uncertainty\n",
      "related to the lack of data, i.e., to the regions in space where there is little or no evidence of\n",
      "any class regardless of being far from/near the decision boundary. On the other hand, we\n",
      "related to the lack of data, i.e., to the regions in space where there is little or no evidence of\n",
      "any class regardless of being far from/near the decision boundary. On the other hand, we\n",
      "refer to model uncertainty as the uncertainty related to the model itself, i.e., the quality of\n",
      "the model ﬁt on known data or uncertainty about the model parameters.\n",
      "refer to model uncertainty as the uncertainty related to the model itself, i.e., the quality of\n",
      "the model ﬁt on known data or uncertainty about the model parameters.\n",
      "ML systems share a set of core components comprising data, an ML model, and\n",
      "its outputs. Uncertainties are present in all ML components under different sources, as\n",
      "visualized in Figure 1.\n",
      "ML systems share a set of core components comprising data, an ML model, and\n",
      "its outputs. Uncertainties are present in all ML components under different sources, as\n",
      "visualized in Figure 1.\n",
      "Figure 1. Uncertainty in Machine Learning (ML) classiﬁcation settings.Electronics 2022 ,11, 396 7 of 20\n",
      "• Data: Data used to feed ML models are limited in their accuracy and potentially\n",
      "Figure 1. Uncertainty in Machine Learning (ML) classiﬁcation settings.Electronics 2022 ,11, 396 7 of 20\n",
      "• Data: Data used to feed ML models are limited in their accuracy and potentially\n",
      "affected by various kinds of quality issues, which limits the models from being ap-\n",
      "plied under optimal conditions [ 34,35]. For example, the uncertainty caused due to\n",
      "affected by various kinds of quality issues, which limits the models from being ap-\n",
      "plied under optimal conditions [ 34,35]. For example, the uncertainty caused due to\n",
      "errors in the measurement might affect the performance of a given classiﬁcation task.\n",
      "Although the aleatoric uncertainty is supposed to be irreducible for a speciﬁc dataset,\n",
      "errors in the measurement might affect the performance of a given classiﬁcation task.\n",
      "Although the aleatoric uncertainty is supposed to be irreducible for a speciﬁc dataset,\n",
      "incorporating additional features or improving the quality of the existing features can\n",
      "assist in its reduction [36];\n",
      "• Model: For a given classiﬁcation task, several ML models can be applied and de-\n",
      "incorporating additional features or improving the quality of the existing features can\n",
      "assist in its reduction [36];\n",
      "• Model: For a given classiﬁcation task, several ML models can be applied and de-\n",
      "veloped. The choice of a model is arguably important and is often based on the\n",
      "degree of error in the model’s outcomes. However, besides models’ accuracy, the\n",
      "veloped. The choice of a model is arguably important and is often based on the\n",
      "degree of error in the model’s outcomes. However, besides models’ accuracy, the\n",
      "use of uncertainty quantiﬁcation methods during model development can provide\n",
      "important elements to choose the right model for the problem at hand. Moreover,\n",
      "use of uncertainty quantiﬁcation methods during model development can provide\n",
      "important elements to choose the right model for the problem at hand. Moreover,\n",
      "understanding the model’s uncertainty during training can give us insights about the\n",
      "speciﬁc limitations of each model and help in developing more robust models. The\n",
      "understanding the model’s uncertainty during training can give us insights about the\n",
      "speciﬁc limitations of each model and help in developing more robust models. The\n",
      "estimation of model uncertainty increases model interpretability, by allowing the user\n",
      "to interpret how conﬁdent the model is for a given prediction;\n",
      "• Output: After the model’s training, estimating and quantifying uncertainty in a\n",
      "to interpret how conﬁdent the model is for a given prediction;\n",
      "• Output: After the model’s training, estimating and quantifying uncertainty in a\n",
      "transductive way, in the sense of tailoring it to individual instances, are arguably\n",
      "relevant, all the more in safety-critical applications. For instance, in the context of\n",
      "computer-aided diagnosis systems, a prediction with high uncertainty shall justify\n",
      "relevant, all the more in safety-critical applications. For instance, in the context of\n",
      "computer-aided diagnosis systems, a prediction with high uncertainty shall justify\n",
      "either disregarding its output or conducting further medical examinations of the\n",
      "patient. In the latter, the goal is to retrieve additional evidence that supports or\n",
      "either disregarding its output or conducting further medical examinations of the\n",
      "patient. In the latter, the goal is to retrieve additional evidence that supports or\n",
      "contradicts a given hypothesis. In the former, it is the case of classiﬁcation with\n",
      "rejection, which is a viable option, where the presence and cost of errors can be\n",
      "contradicts a given hypothesis. In the former, it is the case of classiﬁcation with\n",
      "rejection, which is a viable option, where the presence and cost of errors can be\n",
      "detrimental to the performance of automated classiﬁcation systems [33].\n",
      "To illustrate the different sources of uncertainty and the methods for UQ, we introduce\n",
      "detrimental to the performance of automated classiﬁcation systems [33].\n",
      "To illustrate the different sources of uncertainty and the methods for UQ, we introduce\n",
      "a scenario using a simulated small dataset shown in Figure 2. The scenario consists of a\n",
      "two-dimensional dataset with two classes, where features from class A were modeled with\n",
      "a scenario using a simulated small dataset shown in Figure 2. The scenario consists of a\n",
      "two-dimensional dataset with two classes, where features from class A were modeled with\n",
      "an unimodal Gaussian distribution and features from class B were modeled as a bimodal\n",
      "distribution with a mixture of two Gaussian distributions with highly unequal mass. The\n",
      "an unimodal Gaussian distribution and features from class B were modeled as a bimodal\n",
      "distribution with a mixture of two Gaussian distributions with highly unequal mass. The\n",
      "minor mode is approximately 5.5% of the mass of the major mode.\n",
      "0.4\n",
      " 0.2\n",
      " 0.0 0.2 0.4 0.6\n",
      "Feature 10.40.60.81.01.21.4Feature 2Class A\n",
      "Class B\n",
      "minor mode is approximately 5.5% of the mass of the major mode.\n",
      "0.4\n",
      " 0.2\n",
      " 0.0 0.2 0.4 0.6\n",
      "Feature 10.40.60.81.01.21.4Feature 2Class A\n",
      "Class B\n",
      "Figure 2. Synthetic dataset used to illustrate the different sources of uncertainty in a toy scenario.Electronics 2022 ,11, 396 8 of 20\n",
      "For model training, a Naive Bayes (NB) classiﬁer using KDE was applied using a\n",
      "For model training, a Naive Bayes (NB) classiﬁer using KDE was applied using a\n",
      "bootstrap approach with 50 bootstrap samples to estimate the sampling distribution of\n",
      "arbitrary functions of a dataset. Using this approach, it is possible to access the amount\n",
      "that a prediction changes when the model is ﬁt on slightly different data.\n",
      "arbitrary functions of a dataset. Using this approach, it is possible to access the amount\n",
      "that a prediction changes when the model is ﬁt on slightly different data.\n",
      "The selected uncertainty quantiﬁcation methods for each source of uncertainty were\n",
      "the following:\n",
      "• Aleatoric uncertainty: The (Shannon) entropy is the most notable measure of uncer-\n",
      "The selected uncertainty quantiﬁcation methods for each source of uncertainty were\n",
      "the following:\n",
      "• Aleatoric uncertainty: The (Shannon) entropy is the most notable measure of uncer-\n",
      "tainty for probability distributions being more akin to aleatoric uncertainty. Equation (4) ,\n",
      "which measures the aleatoric uncertainty in terms of expectation over the entropies of\n",
      "tainty for probability distributions being more akin to aleatoric uncertainty. Equation (4) ,\n",
      "which measures the aleatoric uncertainty in terms of expectation over the entropies of\n",
      "distributions, was used for the rest of the analysis;\n",
      "• Model uncertainty: Variation ratios (Equation (7)) were selected as a primary uncer-\n",
      "distributions, was used for the rest of the analysis;\n",
      "• Model uncertainty: Variation ratios (Equation (7)) were selected as a primary uncer-\n",
      "tainty quantiﬁcation method, to estimate model uncertainty, as we were interested in\n",
      "evaluating the quality of the model ﬁt. In this sense, changes in the predicted label\n",
      "have a signiﬁcant impact on the variation ratio measure. Contrarily, measures based\n",
      "evaluating the quality of the model ﬁt. In this sense, changes in the predicted label\n",
      "have a signiﬁcant impact on the variation ratio measure. Contrarily, measures based\n",
      "on entropies (Equation (6) is commonly used) can also be used, but the impact on the\n",
      "measure is lower, since in variation ratios, we are merely counting changes in the pre-\n",
      "on entropies (Equation (6) is commonly used) can also be used, but the impact on the\n",
      "measure is lower, since in variation ratios, we are merely counting changes in the pre-\n",
      "dictions, and in entropy measures, we are averaging the prediction probabilities [ 21];\n",
      "• Knowledge uncertainty: Although the majority of works addressed the quantiﬁcation\n",
      "dictions, and in entropy measures, we are averaging the prediction probabilities [ 21];\n",
      "• Knowledge uncertainty: Although the majority of works addressed the quantiﬁcation\n",
      "of knowledge uncertainty with measures such as the mutual information using ensem-\n",
      "bles (Equation (6)), we argue that these kinds of measures are more akin to model un-\n",
      "of knowledge uncertainty with measures such as the mutual information using ensem-\n",
      "bles (Equation (6)), we argue that these kinds of measures are more akin to model un-\n",
      "certainty. The uncertainty related to the lack of data might be poorly modeled by these\n",
      "measures. In this perspective, we considered density estimation methods, commonly\n",
      "certainty. The uncertainty related to the lack of data might be poorly modeled by these\n",
      "measures. In this perspective, we considered density estimation methods, commonly\n",
      "used for outlier or novelty detection, more prone to model knowledge uncertainty.\n",
      "Thus, the KUE measure (Equation (9)) was used to model knowledge uncertainty.\n",
      "used for outlier or novelty detection, more prone to model knowledge uncertainty.\n",
      "Thus, the KUE measure (Equation (9)) was used to model knowledge uncertainty.\n",
      "In order to visualize the uncertainty estimations in the whole region presented in\n",
      "Figure 2, we applied the uncertainty quantiﬁcation measures to a new set of points that\n",
      "In order to visualize the uncertainty estimations in the whole region presented in\n",
      "Figure 2, we applied the uncertainty quantiﬁcation measures to a new set of points that\n",
      "included all combinations of feature values in the deﬁned region. Figure 3 shows the\n",
      "uncertainty values for each point of the feature space.\n",
      "0.5\n",
      " 0.0 0.5\n",
      "Feature 10.500.751.001.251.50Feature 2Aleatoric Uncertainty\n",
      "0.5\n",
      " 0.0 0.5\n",
      "uncertainty values for each point of the feature space.\n",
      "0.5\n",
      " 0.0 0.5\n",
      "Feature 10.500.751.001.251.50Feature 2Aleatoric Uncertainty\n",
      "0.5\n",
      " 0.0 0.5\n",
      "Feature 1Model Uncertainty\n",
      "0.5\n",
      " 0.0 0.5\n",
      "Feature 1Knowledge Uncertainty\n",
      "0.00.20.40.60.81.0\n",
      "entropy\n",
      "0.00.10.20.30.40.5\n",
      "variation ratios\n",
      "0.00.20.40.60.81.0\n",
      "KUE\n",
      "Figure 3. Toy dataset uncertainty measures for aleatoric, model, and knowledge uncertainty (from\n",
      "0.00.20.40.60.81.0\n",
      "entropy\n",
      "0.00.10.20.30.40.5\n",
      "variation ratios\n",
      "0.00.20.40.60.81.0\n",
      "KUE\n",
      "Figure 3. Toy dataset uncertainty measures for aleatoric, model, and knowledge uncertainty (from\n",
      "lefttoright ).\n",
      "Observing the uncertainty regions for each source of uncertainty, one can see com-\n",
      "pletely different behaviors depending on the uncertainty. The aleatoric uncertainty is high\n",
      "lefttoright ).\n",
      "Observing the uncertainty regions for each source of uncertainty, one can see com-\n",
      "pletely different behaviors depending on the uncertainty. The aleatoric uncertainty is high\n",
      "in the middle of the two major clusters (Feature 1 equals to 0.15 approximately), due to\n",
      "the overlap between the classes. The overlap between the cluster of class A and the minor\n",
      "in the middle of the two major clusters (Feature 1 equals to 0.15 approximately), due to\n",
      "the overlap between the classes. The overlap between the cluster of class A and the minor\n",
      "cluster of class B also presents a higher uncertainty compared to the rest of the region.\n",
      "However, it does not produce an uncertainty as high as the overlap between the two\n",
      "cluster of class B also presents a higher uncertainty compared to the rest of the region.\n",
      "However, it does not produce an uncertainty as high as the overlap between the two\n",
      "major clusters due to the differences in the masses of both clusters. The entropy value is\n",
      "normalized to the maximum entropy, i.e., the logarithm of the number of classes.\n",
      "major clusters due to the differences in the masses of both clusters. The entropy value is\n",
      "normalized to the maximum entropy, i.e., the logarithm of the number of classes.\n",
      "Regarding the model uncertainty and referring to this toy scenario with two classes,\n",
      "the maximum possible value occurs when the frequency of both classes is equal, i.e., the\n",
      "Regarding the model uncertainty and referring to this toy scenario with two classes,\n",
      "the maximum possible value occurs when the frequency of both classes is equal, i.e., the\n",
      "variation ratios have a value of 0.5. The regions with higher uncertainty values are the\n",
      "ones with little evidence, since the model ﬁt in these regions is highly dependent on the\n",
      "variation ratios have a value of 0.5. The regions with higher uncertainty values are the\n",
      "ones with little evidence, since the model ﬁt in these regions is highly dependent on the\n",
      "available data. Therefore, it is expected that slight differences in the training data, especiallyElectronics 2022 ,11, 396 9 of 20\n",
      "available data. Therefore, it is expected that slight differences in the training data, especiallyElectronics 2022 ,11, 396 9 of 20\n",
      "in regions with little evidence, have a high impact on the model ﬁt and produce high model\n",
      "uncertainty. Observing the ﬁgure, it is possible to see that the minor cluster of class B\n",
      "produces a high model uncertainty. Additionally, the upper and lower regions between\n",
      "uncertainty. Observing the ﬁgure, it is possible to see that the minor cluster of class B\n",
      "produces a high model uncertainty. Additionally, the upper and lower regions between\n",
      "the major clusters also produce a high uncertainty, due to slight differences in the decision\n",
      "boundary on different bootstrap samples.\n",
      "Finally, knowledge uncertainty was modeled using the feature density on the training\n",
      "boundary on different bootstrap samples.\n",
      "Finally, knowledge uncertainty was modeled using the feature density on the training\n",
      "data, which produces a high uncertainty in all the feature space without data.\n",
      "For the classiﬁcation with rejection, we deﬁne a rejection rule for each type of uncer-\n",
      "tainty, using the previously uncertainty measures to deﬁne the conﬁdence threshold. The\n",
      "For the classiﬁcation with rejection, we deﬁne a rejection rule for each type of uncer-\n",
      "tainty, using the previously uncertainty measures to deﬁne the conﬁdence threshold. The\n",
      "problem of choosing the optimal rejection point is not trivial and was not addressed in\n",
      "this work. There are several works entirely dedicated to this topic, such as the work of\n",
      "Condessa et al. [33] and Fisher et al. [37].\n",
      "this work. There are several works entirely dedicated to this topic, such as the work of\n",
      "Condessa et al. [33] and Fisher et al. [37].\n",
      "In our classiﬁcation setting, the ﬁnal prediction is given by the following rejection rule:\n",
      "ˆw=(\n",
      "reject ifF(x)>0\n",
      "f(x) otherwise(13)\n",
      "where f(x)is the classiﬁer without rejection and F(x)is a function on the input that\n",
      "ˆw=(\n",
      "reject ifF(x)>0\n",
      "f(x) otherwise(13)\n",
      "where f(x)is the classiﬁer without rejection and F(x)is a function on the input that\n",
      "evaluates the uncertainty of the prediction model. This uncertainty function is given\n",
      "by the set of uncertainties—aleatoric ( a), model ( m), and knowledge ( k)—through the\n",
      "following equation:\n",
      "F(x) =å\n",
      "u2U1[fu(x)>tu] (14)\n",
      "by the set of uncertainties—aleatoric ( a), model ( m), and knowledge ( k)—through the\n",
      "following equation:\n",
      "F(x) =å\n",
      "u2U1[fu(x)>tu] (14)\n",
      "where U2[a,m,k]is the set of available uncertainties, fuis an uncertainty function that\n",
      "evaluates uncertainty u, and tuis a threshold for the rejection point for uncertainty u.\n",
      "Regarding aleatoric uncertainty, fais equal to Equation (4) and the optimal threshold,\n",
      "evaluates uncertainty u, and tuis a threshold for the rejection point for uncertainty u.\n",
      "Regarding aleatoric uncertainty, fais equal to Equation (4) and the optimal threshold,\n",
      "ta, was obtained using the following equation:\n",
      "ta=argmax\n",
      "q\u0012\n",
      "jM\\Rqj\u0000b\n",
      "1\u0000b\u0001jA\\Rqj\u0013\n",
      "(15)\n",
      "where qis a threshold in the interval [0, 1], representing a normalized entropy value\n",
      "ta, was obtained using the following equation:\n",
      "ta=argmax\n",
      "q\u0012\n",
      "jM\\Rqj\u0000b\n",
      "1\u0000b\u0001jA\\Rqj\u0013\n",
      "(15)\n",
      "where qis a threshold in the interval [0, 1], representing a normalized entropy value\n",
      "measured with Equation (4), and bis a rejection cost, here set to 0.5. For jM\\Rqjand\n",
      "jA\\Rqj, the notation from Section 2.2 was used, and the subsets represent the true rejections\n",
      "measured with Equation (4), and bis a rejection cost, here set to 0.5. For jM\\Rqjand\n",
      "jA\\Rqj, the notation from Section 2.2 was used, and the subsets represent the true rejections\n",
      "and false rejections using threshold q, respectively.\n",
      "The uncertainty function used for model uncertainty, fm, is equal to Equation (7), and\n",
      "and false rejections using threshold q, respectively.\n",
      "The uncertainty function used for model uncertainty, fm, is equal to Equation (7), and\n",
      "tmwas set to zero, which means that a prediction must be equal in all bootstraps samples\n",
      "to not be rejected. This assumption was made because if a sample is predicted differently\n",
      "tmwas set to zero, which means that a prediction must be equal in all bootstraps samples\n",
      "to not be rejected. This assumption was made because if a sample is predicted differently\n",
      "using slightly different datasets, the model in that particular region will still have some\n",
      "uncertainty associated.\n",
      "For knowledge uncertainty, fkis equal to Equation (9). To deﬁne tk, we used a\n",
      "using slightly different datasets, the model in that particular region will still have some\n",
      "uncertainty associated.\n",
      "For knowledge uncertainty, fkis equal to Equation (9). To deﬁne tk, we used a\n",
      "95% value of the training uncertainty values, meaning that tk=P95%[KUE]. A detailed\n",
      "description of this approach is available in [24].\n",
      "95% value of the training uncertainty values, meaning that tk=P95%[KUE]. A detailed\n",
      "description of this approach is available in [24].\n",
      "In summary, our proposed approach was developed in the context of classiﬁcation\n",
      "with rejection where rejection was obtained through measures of uncertainty. These un-\n",
      "certainty measures were distinguished by three different sources: aleatoric, model, and\n",
      "with rejection where rejection was obtained through measures of uncertainty. These un-\n",
      "certainty measures were distinguished by three different sources: aleatoric, model, and\n",
      "knowledge uncertainty. For the uncertainty quantiﬁcation, we used an entropy measure\n",
      "for aleatoric uncertainty (Equation (4)), the variation ratio measure for model uncertainty\n",
      "knowledge uncertainty. For the uncertainty quantiﬁcation, we used an entropy measure\n",
      "for aleatoric uncertainty (Equation (4)), the variation ratio measure for model uncertainty\n",
      "(Equation (7)), and KUE to quantify the knowledge uncertainty. Regarding the rejection\n",
      "setting, we applied the rejection rule from Equation (13), where each source of uncertainty\n",
      "(Equation (7)), and KUE to quantify the knowledge uncertainty. Regarding the rejection\n",
      "setting, we applied the rejection rule from Equation (13), where each source of uncertainty\n",
      "has an uncertainty function given by Equation (14). For the training procedure, a bootstrap\n",
      "approach with 20 bootstrap samples was used, and the uncertainty measures were calcu-\n",
      "has an uncertainty function given by Equation (14). For the training procedure, a bootstrap\n",
      "approach with 20 bootstrap samples was used, and the uncertainty measures were calcu-\n",
      "lated. The evaluation of the selected models was performed through the accuracy and the\n",
      "nonrejection accuracy followed by the rejection fraction for each individual measure andElectronics 2022 ,11, 396 10 of 20\n",
      "nonrejection accuracy followed by the rejection fraction for each individual measure andElectronics 2022 ,11, 396 10 of 20\n",
      "also the total rejection fraction. In the case of the models’ combination, the performance\n",
      "measures from Equations (10)–(12) were also employed.\n",
      "4. Experiments\n",
      "In this section, we demonstrate the usefulness of uncertainty quantiﬁcation using\n",
      "measures from Equations (10)–(12) were also employed.\n",
      "4. Experiments\n",
      "In this section, we demonstrate the usefulness of uncertainty quantiﬁcation using\n",
      "synthetic datasets and a benchmark dataset from the University of California Irvine (UCI)\n",
      "ML repository [38]. Speciﬁcally, we answer the following questions:\n",
      "• Q1. How can UQ contribute to choosing the most suitable model for a given\n",
      "ML repository [38]. Speciﬁcally, we answer the following questions:\n",
      "• Q1. How can UQ contribute to choosing the most suitable model for a given\n",
      "classiﬁcation task?\n",
      "• Q2. Can UQ be use to combine different models?\n",
      "• Q3. Can visualization techniques improve UQ’s interpretability?\n",
      "4.1. Analysis on Synthetic Data\n",
      "Predicted uncertainties are often evaluated indirectly, since normally, data do not\n",
      "• Q3. Can visualization techniques improve UQ’s interpretability?\n",
      "4.1. Analysis on Synthetic Data\n",
      "Predicted uncertainties are often evaluated indirectly, since normally, data do not\n",
      "contain information about any sort of “ground truth” uncertainties. For this reason, the\n",
      "use of a synthetic dataset can more easily provide an intuition about the different types of\n",
      "contain information about any sort of “ground truth” uncertainties. For this reason, the\n",
      "use of a synthetic dataset can more easily provide an intuition about the different types of\n",
      "uncertainties and their quantiﬁcation. Furthermore, in a controllable setting, we can alter\n",
      "the size of the datasets, evaluate the models’ performance and uncertainties in different\n",
      "uncertainties and their quantiﬁcation. Furthermore, in a controllable setting, we can alter\n",
      "the size of the datasets, evaluate the models’ performance and uncertainties in different\n",
      "conditions, and introduce noise in the data to check the models’ robustness.\n",
      "4.1.1. Uncertainty for Model Selection (Q1)\n",
      "To answer Q1, we generated a dataset composed of a total of 150,000 ten-dimensional\n",
      "4.1.1. Uncertainty for Model Selection (Q1)\n",
      "To answer Q1, we generated a dataset composed of a total of 150,000 ten-dimensional\n",
      "points corresponding to six different classes equally distributed. Features from each class\n",
      "were modeled using Gaussian, exponential, and uniform distributions. The distributions\n",
      "were randomly selected and could be unimodal or bimodal distributions. To evaluate\n",
      "were modeled using Gaussian, exponential, and uniform distributions. The distributions\n",
      "were randomly selected and could be unimodal or bimodal distributions. To evaluate\n",
      "the behavior of uncertainty estimations with the increasing number of training samples,\n",
      "the models were trained for different training sizes using a k-fold cross-validation as the\n",
      "the behavior of uncertainty estimations with the increasing number of training samples,\n",
      "the models were trained for different training sizes using a k-fold cross-validation as the\n",
      "validation strategy where k was set to 5. An exponential growth of the training samples\n",
      "was applied, starting with 50 samples per class (training size equals 300 samples).\n",
      "validation strategy where k was set to 5. An exponential growth of the training samples\n",
      "was applied, starting with 50 samples per class (training size equals 300 samples).\n",
      "For model training, different classiﬁers using a training size of 7692 samples were\n",
      "tested as presented in Table 1. Since features data were simulated using Gaussian, expo-\n",
      "For model training, different classiﬁers using a training size of 7692 samples were\n",
      "tested as presented in Table 1. Since features data were simulated using Gaussian, expo-\n",
      "nential, and uniform distributions, a focus on Bayesian models using Gaussian, KDE, and\n",
      "exponential distributions was employed. As expected, Bayesian models obtained higher\n",
      "nential, and uniform distributions, a focus on Bayesian models using Gaussian, KDE, and\n",
      "exponential distributions was employed. As expected, Bayesian models obtained higher\n",
      "baseline accuracies than the other tested classiﬁers, since part of the features likelihood\n",
      "was modeled with the true data distribution. With the purpose of answering Q1, the three\n",
      "baseline accuracies than the other tested classiﬁers, since part of the features likelihood\n",
      "was modeled with the true data distribution. With the purpose of answering Q1, the three\n",
      "classiﬁers highlighted in Table 1, with a similar baseline accuracy, were selected to continue\n",
      "the analysis. These classiﬁers were: (1) the NB classiﬁer where the features likelihood\n",
      "classiﬁers highlighted in Table 1, with a similar baseline accuracy, were selected to continue\n",
      "the analysis. These classiﬁers were: (1) the NB classiﬁer where the features likelihood\n",
      "was assumed to be Gaussian; (2) the NB classiﬁer where the features likelihood was as-\n",
      "sumed to be exponential; (3) the Bayes classiﬁer where the features likelihood was based\n",
      "was assumed to be Gaussian; (2) the NB classiﬁer where the features likelihood was as-\n",
      "sumed to be exponential; (3) the Bayes classiﬁer where the features likelihood was based\n",
      "on KDE. Additionally, the selected classiﬁers were trained using a bootstrap procedure\n",
      "with 20 bootstrap samples.\n",
      "For this analysis, only aleatoric and model uncertainty measures were considered,\n",
      "on KDE. Additionally, the selected classiﬁers were trained using a bootstrap procedure\n",
      "with 20 bootstrap samples.\n",
      "For this analysis, only aleatoric and model uncertainty measures were considered,\n",
      "since a synthetic dataset without outliers was used. Therefore, KUE would be near zero\n",
      "and would not bring relevant information for this analysis.\n",
      "since a synthetic dataset without outliers was used. Therefore, KUE would be near zero\n",
      "and would not bring relevant information for this analysis.\n",
      "Figure 4 shows the rejection fraction and accuracy with the increasing number of\n",
      "training samples for the different tested models. The rejection fraction was obtained\n",
      "using both aleatoric and model uncertainty measures independently, and the nonrejected\n",
      "training samples for the different tested models. The rejection fraction was obtained\n",
      "using both aleatoric and model uncertainty measures independently, and the nonrejected\n",
      "accuracy was obtained by rejecting all samples with aleatoric and/or model uncertainty\n",
      "(see Equation (13)).\n",
      "As previously mentioned, the model’s accuracy is often one of the most important\n",
      "accuracy was obtained by rejecting all samples with aleatoric and/or model uncertainty\n",
      "(see Equation (13)).\n",
      "As previously mentioned, the model’s accuracy is often one of the most important\n",
      "elements to model selection. However, we argue that uncertainty quantiﬁcation methods\n",
      "should also be evaluated during the model’s training, to help us choose the right model.\n",
      "elements to model selection. However, we argue that uncertainty quantiﬁcation methods\n",
      "should also be evaluated during the model’s training, to help us choose the right model.\n",
      "Observing Figure 4, different models can achieve the same accuracy, but with different\n",
      "degrees of uncertainty. For example, for a training size of 7692 samples (dashed gray line inElectronics 2022 ,11, 396 11 of 20\n",
      "degrees of uncertainty. For example, for a training size of 7692 samples (dashed gray line inElectronics 2022 ,11, 396 11 of 20\n",
      "Figure 4), the three models obtained a baseline accuracy of 84%, approximately. Seen only\n",
      "from this point of view, the decision between the three models would be equal. However,\n",
      "observing the rejection fraction from uncertainty measures, it is easy to understand that\n",
      "from this point of view, the decision between the three models would be equal. However,\n",
      "observing the rejection fraction from uncertainty measures, it is easy to understand that\n",
      "the KDE model had higher model uncertainty compared with the other two models. The\n",
      "reason for this difference is that the KDE model is more complex, which means that it\n",
      "the KDE model had higher model uncertainty compared with the other two models. The\n",
      "reason for this difference is that the KDE model is more complex, which means that it\n",
      "needs more data to correctly model the data distribution. Therefore, the differences in the\n",
      "bootstrap samples have a high impact on the model ﬁt, meaning that the same sample is\n",
      "needs more data to correctly model the data distribution. Therefore, the differences in the\n",
      "bootstrap samples have a high impact on the model ﬁt, meaning that the same sample is\n",
      "classiﬁed differently depending on the bootstrap sample used to ﬁt the model. Additionally,\n",
      "observing the standard deviation with the increasing number of training samples, we can\n",
      "classiﬁed differently depending on the bootstrap sample used to ﬁt the model. Additionally,\n",
      "observing the standard deviation with the increasing number of training samples, we can\n",
      "note a slight decrease in both the rejection fraction and accuracy values, except from the\n",
      "exponential model, which seemed to have an almost constant value across the different\n",
      "note a slight decrease in both the rejection fraction and accuracy values, except from the\n",
      "exponential model, which seemed to have an almost constant value across the different\n",
      "training sizes. Using this information and since the accuracy was approximately equal for\n",
      "the three models, the choice of a Gaussian NB would be probably preferable due to its low\n",
      "aleatoric and model uncertainty.\n",
      "the three models, the choice of a Gaussian NB would be probably preferable due to its low\n",
      "aleatoric and model uncertainty.\n",
      "Table 1. Performance measures (mean \u0006standard deviation) for different models using a training\n",
      "size of 7692 samples. The highlighted baseline accuracies represent the selected models that were\n",
      "considered for further analysis, since the models attained similar accuracy values.\n",
      "size of 7692 samples. The highlighted baseline accuracies represent the selected models that were\n",
      "considered for further analysis, since the models attained similar accuracy values.\n",
      "ModelBaseline Nonrejected Rejection\n",
      "Accuracy Accuracy Fraction\n",
      "Gaussian Naive Bayes 0.838\u00060.004 0.861\u00060.004 0.056\u00060.006\n",
      "KDE Naive Bayes 0.918 \u00060.004 0.929\u00060.004 0.050\u00060.007\n",
      "ModelBaseline Nonrejected Rejection\n",
      "Accuracy Accuracy Fraction\n",
      "Gaussian Naive Bayes 0.838\u00060.004 0.861\u00060.004 0.056\u00060.006\n",
      "KDE Naive Bayes 0.918 \u00060.004 0.929\u00060.004 0.050\u00060.007\n",
      "Exponential Naive Bayes 0.848\u00060.012 0.894\u00060.011 0.109\u00060.041\n",
      "KDE Bayes 0.845\u00060.003 0.914\u00060.004 0.178\u00060.004\n",
      "Logistic Regression 0.717 \u00060.003 0.788\u00060.005 0.198\u00060.006\n",
      "Decision Tree 0.764 \u00060.024 0.884\u00060.004 0.328\u00060.111\n",
      "KDE Bayes 0.845\u00060.003 0.914\u00060.004 0.178\u00060.004\n",
      "Logistic Regression 0.717 \u00060.003 0.788\u00060.005 0.198\u00060.006\n",
      "Decision Tree 0.764 \u00060.024 0.884\u00060.004 0.328\u00060.111\n",
      "Random Forest 0.806 \u00060.004 0.871\u00060.006 0.169\u00060.004\n",
      "k-Nearest Neighbors 0.820 \u00060.004 0.902\u00060.007 0.202\u00060.005\n",
      "Support Vector Machines 0.744 \u00060.004 0.806\u00060.005 0.173\u00060.010\n",
      "0.00.20.4Rejection Fraction\n",
      "Guassian Naive Bayes\n",
      " Exponential Naive Bayes\n",
      "k-Nearest Neighbors 0.820 \u00060.004 0.902\u00060.007 0.202\u00060.005\n",
      "Support Vector Machines 0.744 \u00060.004 0.806\u00060.005 0.173\u00060.010\n",
      "0.00.20.4Rejection Fraction\n",
      "Guassian Naive Bayes\n",
      " Exponential Naive Bayes\n",
      " KDE Model\n",
      "Aleatoric\n",
      "Model\n",
      "103104105\n",
      "# train samples0.60.70.80.91.0Accuracy\n",
      "103104105\n",
      "# train samples\n",
      "103104105\n",
      "# train samples\n",
      "Baseline\n",
      "NRA\n",
      "Guassian Naive Bayes\n",
      " Exponential Naive Bayes\n",
      " KDE Model\n",
      "Aleatoric\n",
      "Model\n",
      "103104105\n",
      "# train samples0.60.70.80.91.0Accuracy\n",
      "103104105\n",
      "# train samples\n",
      "103104105\n",
      "# train samples\n",
      "Baseline\n",
      "NRA\n",
      "Figure 4. Uncertainties’ rejection fraction and obtained accuracies using a k-fold cross-validation\n",
      "with an increasing number of training samples for 3 different models. The vertical line represents a\n",
      "Figure 4. Uncertainties’ rejection fraction and obtained accuracies using a k-fold cross-validation\n",
      "with an increasing number of training samples for 3 different models. The vertical line represents a\n",
      "training size that obtained a similar baseline accuracy for all models.\n",
      "Nonetheless, if the rejection of samples or the addition of new samples is an option, a\n",
      "training size that obtained a similar baseline accuracy for all models.\n",
      "Nonetheless, if the rejection of samples or the addition of new samples is an option, a\n",
      "different analysis can be performed. By deﬁnition, aleatoric uncertainty is irreducible for theElectronics 2022 ,11, 396 12 of 20\n",
      "same dataset, which was veriﬁed with these experimental results. Increasing the number\n",
      "same dataset, which was veriﬁed with these experimental results. Increasing the number\n",
      "of training samples did not change the aleatoric uncertainty, making the rejection fraction\n",
      "mostly constant across the different training sizes. Contrarily, model uncertainty decreased\n",
      "with the increase of the number of training samples, tending towards zero when the model\n",
      "mostly constant across the different training sizes. Contrarily, model uncertainty decreased\n",
      "with the increase of the number of training samples, tending towards zero when the model\n",
      "ﬁt was equal for all bootstrap samples. Thus, the analysis of model uncertainty can give us\n",
      "insights about the usefulness of adding more samples for the model’s training. In Gaussian\n",
      "ﬁt was equal for all bootstrap samples. Thus, the analysis of model uncertainty can give us\n",
      "insights about the usefulness of adding more samples for the model’s training. In Gaussian\n",
      "and KDE models, the decrease of model uncertainty had a clear increase in the baseline\n",
      "accuracy. For the Gaussian NB model, from 103training samples, the baseline accuracy was\n",
      "and KDE models, the decrease of model uncertainty had a clear increase in the baseline\n",
      "accuracy. For the Gaussian NB model, from 103training samples, the baseline accuracy was\n",
      "mostly constant and the decrease of model uncertainty was not signiﬁcant. This means that\n",
      "the model ﬁt did not change using different bootstrap samples, and the addition of new\n",
      "mostly constant and the decrease of model uncertainty was not signiﬁcant. This means that\n",
      "the model ﬁt did not change using different bootstrap samples, and the addition of new\n",
      "data did not improve the model’s performance. However, observing the KDE model, due to\n",
      "its high rejection fraction of model uncertainty, the addition of new samples still increased\n",
      "data did not improve the model’s performance. However, observing the KDE model, due to\n",
      "its high rejection fraction of model uncertainty, the addition of new samples still increased\n",
      "the model’s performance. Furthermore, the nonrejected accuracy was always higher than\n",
      "the baseline accuracy, and it was mostly constant across the different training sizes. This\n",
      "the model’s performance. Furthermore, the nonrejected accuracy was always higher than\n",
      "the baseline accuracy, and it was mostly constant across the different training sizes. This\n",
      "means that the model uncertainty measure was in fact detecting the regions in the feature\n",
      "space responsible for a high number of misclassiﬁcations due to a poor model ﬁt.\n",
      "4.1.2. Uncertainty for Models’ Combination (Q2)\n",
      "space responsible for a high number of misclassiﬁcations due to a poor model ﬁt.\n",
      "4.1.2. Uncertainty for Models’ Combination (Q2)\n",
      "From the analysis of the previous question, we observed that different models had\n",
      "different degrees of uncertainty for the same training size. Since different models were\n",
      "based on different assumptions, we hypothesized that uncertainty measures can be used\n",
      "different degrees of uncertainty for the same training size. Since different models were\n",
      "based on different assumptions, we hypothesized that uncertainty measures can be used\n",
      "to combine different models, producing a more robust model. In order to validate this\n",
      "hypothesis, a new dataset composed of 150,000 ten-dimensional points corresponding to\n",
      "to combine different models, producing a more robust model. In order to validate this\n",
      "hypothesis, a new dataset composed of 150,000 ten-dimensional points corresponding to\n",
      "six different classes equally distributed and modeled as a bimodal Gaussian distribution\n",
      "was generated.\n",
      "A Gaussian NB and a KDE Bayes classiﬁer were trained with a bootstrap approach\n",
      "six different classes equally distributed and modeled as a bimodal Gaussian distribution\n",
      "was generated.\n",
      "A Gaussian NB and a KDE Bayes classiﬁer were trained with a bootstrap approach\n",
      "with 20 bootstrap samples. Figure 5 shows the rejection fraction and accuracy with the\n",
      "increasing number of training samples for both models. As the Gaussian model uses\n",
      "with 20 bootstrap samples. Figure 5 shows the rejection fraction and accuracy with the\n",
      "increasing number of training samples for both models. As the Gaussian model uses\n",
      "unimodal distributions to ﬁt the features data and the dataset was composed of features\n",
      "modeled as bimodal Gaussian distributions, the Gaussian NB classiﬁer presented a high\n",
      "unimodal distributions to ﬁt the features data and the dataset was composed of features\n",
      "modeled as bimodal Gaussian distributions, the Gaussian NB classiﬁer presented a high\n",
      "rejection fraction due to aleatoric uncertainty, since the overlap between the ﬁt distributions\n",
      "was high. Contrarily, the KDE Bayes classiﬁer deals well with bimodal distributions, which\n",
      "rejection fraction due to aleatoric uncertainty, since the overlap between the ﬁt distributions\n",
      "was high. Contrarily, the KDE Bayes classiﬁer deals well with bimodal distributions, which\n",
      "resulted in a low overlap between classes, obtaining a low rejection fraction due to aleatoric\n",
      "uncertainty. Regarding model uncertainty, although both models started with a high\n",
      "resulted in a low overlap between classes, obtaining a low rejection fraction due to aleatoric\n",
      "uncertainty. Regarding model uncertainty, although both models started with a high\n",
      "rejection fraction, the Gaussian NB reached 105training samples with almost zero rejection,\n",
      "and the KDE model, due to its complexity, still had a 10% rejection rate, approximately. In\n",
      "rejection fraction, the Gaussian NB reached 105training samples with almost zero rejection,\n",
      "and the KDE model, due to its complexity, still had a 10% rejection rate, approximately. In\n",
      "summary, the Gaussian NB had high aleatoric uncertainty and low model uncertainty, and\n",
      "the KDE Bayes classiﬁer had low aleatoric uncertainty and high model uncertainty.\n",
      "summary, the Gaussian NB had high aleatoric uncertainty and low model uncertainty, and\n",
      "the KDE Bayes classiﬁer had low aleatoric uncertainty and high model uncertainty.\n",
      "To verify the potential for combining both models using uncertainty measures, the\n",
      "following combination rules were applied:\n",
      "ˆw=8\n",
      ">>>><\n",
      ">>>>:fc1(x) ifFc1(x) =0 and Fc2(x)>0\n",
      "fc2(x) ifFc1(x)>0 and Fc2(x) =0\n",
      "following combination rules were applied:\n",
      "ˆw=8\n",
      ">>>><\n",
      ">>>>:fc1(x) ifFc1(x) =0 and Fc2(x)>0\n",
      "fc2(x) ifFc1(x)>0 and Fc2(x) =0\n",
      "fc1(x) ifFc1(x) =0 and Fc2(x) =0 and fc1(x) = fc2(x)\n",
      "reject otherwise(16)\n",
      "where c1and c2represent the Gaussian NB and KDE Bayes classiﬁer and Fcis the uncer-\n",
      "tainty function deﬁned in Equation (14).\n",
      "fc1(x) ifFc1(x) =0 and Fc2(x) =0 and fc1(x) = fc2(x)\n",
      "reject otherwise(16)\n",
      "where c1and c2represent the Gaussian NB and KDE Bayes classiﬁer and Fcis the uncer-\n",
      "tainty function deﬁned in Equation (14).\n",
      "To validate that the proposed combination strategy performed better than the individual\n",
      "models, we applied the performance measures proposed in the work of Condessa et al. [33] .\n",
      "To validate that the proposed combination strategy performed better than the individual\n",
      "models, we applied the performance measures proposed in the work of Condessa et al. [33] .\n",
      "To compare the performance of the classifiers with rejection, 10% of the rejected samples were\n",
      "used with the highest training size available ( \u001890,000 training samples).\n",
      "To compare the performance of the classifiers with rejection, 10% of the rejected samples were\n",
      "used with the highest training size available ( \u001890,000 training samples).\n",
      "In Table 2, the obtained results for the three models using a 10% rejection fraction\n",
      "are shown. The combination strategy using the uncertainties of both individual modelsElectronics 2022 ,11, 396 13 of 20\n",
      "are shown. The combination strategy using the uncertainties of both individual modelsElectronics 2022 ,11, 396 13 of 20\n",
      "resulted in higher values for the three performance measures for classiﬁers with rejection,\n",
      "namely the nonrejected accuracy, classiﬁcation quality, and rejection quality.\n",
      "0.00.20.4Rejection Fraction\n",
      "Guassian Naive Bayes\n",
      " KDE Model\n",
      "Aleatoric\n",
      "Model\n",
      "103104105\n",
      "namely the nonrejected accuracy, classiﬁcation quality, and rejection quality.\n",
      "0.00.20.4Rejection Fraction\n",
      "Guassian Naive Bayes\n",
      " KDE Model\n",
      "Aleatoric\n",
      "Model\n",
      "103104105\n",
      "# train samples0.70.80.9Accuracy\n",
      "103104105\n",
      "# train samples\n",
      "Baseline\n",
      "NRA\n",
      "Figure 5. Uncertainties’ rejection fraction and obtained accuracies using a k-fold cross-validation\n",
      "Aleatoric\n",
      "Model\n",
      "103104105\n",
      "# train samples0.70.80.9Accuracy\n",
      "103104105\n",
      "# train samples\n",
      "Baseline\n",
      "NRA\n",
      "Figure 5. Uncertainties’ rejection fraction and obtained accuracies using a k-fold cross-validation\n",
      "with an increasing number of training samples for Gaussian NB and KDE Bayes models.\n",
      "These preliminary results showed that the access to uncertainty estimations during\n",
      "with an increasing number of training samples for Gaussian NB and KDE Bayes models.\n",
      "These preliminary results showed that the access to uncertainty estimations during\n",
      "the model’s development might be a useful source of information to develop more robust\n",
      "models. Although a simpler model, such as an NB classiﬁer, can have a lower performance\n",
      "the model’s development might be a useful source of information to develop more robust\n",
      "models. Although a simpler model, such as an NB classiﬁer, can have a lower performance\n",
      "in comparison with more complex models, the use of uncertainty estimations can provide\n",
      "information about the speciﬁc regions where the model has low uncertainty. Using this\n",
      "in comparison with more complex models, the use of uncertainty estimations can provide\n",
      "information about the speciﬁc regions where the model has low uncertainty. Using this\n",
      "information in combination with more powerful models can in fact increase the overall\n",
      "model performance.\n",
      "Table 2. Performance measures for individual models (Gaussian naive Bayes and KDE Bayes) and\n",
      "information in combination with more powerful models can in fact increase the overall\n",
      "model performance.\n",
      "Table 2. Performance measures for individual models (Gaussian naive Bayes and KDE Bayes) and\n",
      "a combination of both models. The results were obtained using a rejection fraction of 10% and a\n",
      "training size of 90,000 samples.\n",
      "ModelNonrejected Classiﬁcation Rejection\n",
      "Accuracy Quality Quality\n",
      "a combination of both models. The results were obtained using a rejection fraction of 10% and a\n",
      "training size of 90,000 samples.\n",
      "ModelNonrejected Classiﬁcation Rejection\n",
      "Accuracy Quality Quality\n",
      "Gaussian Naive Bayes 0.72 0.72 2.60\n",
      "KDE Bayes 0.85 0.82 5.84\n",
      "Model’s Combination 0.86 0.83 6.89\n",
      "4.1.3. Uncertainty Visualization (Q3)\n",
      "ModelNonrejected Classiﬁcation Rejection\n",
      "Accuracy Quality Quality\n",
      "Gaussian Naive Bayes 0.72 0.72 2.60\n",
      "KDE Bayes 0.85 0.82 5.84\n",
      "Model’s Combination 0.86 0.83 6.89\n",
      "4.1.3. Uncertainty Visualization (Q3)\n",
      "To use ML in high-stakes applications, we need auditing tools to build conﬁdence in\n",
      "the models and their decisions. Besides quantiﬁcation metrics, visualization techniques\n",
      "To use ML in high-stakes applications, we need auditing tools to build conﬁdence in\n",
      "the models and their decisions. Besides quantiﬁcation metrics, visualization techniques\n",
      "have been used to support the interpretability of classiﬁcation models. Therefore, to answer\n",
      "this question, we quantiﬁed the different sources of uncertainty using visualization methods\n",
      "have been used to support the interpretability of classiﬁcation models. Therefore, to answer\n",
      "this question, we quantiﬁed the different sources of uncertainty using visualization methods\n",
      "to assist in interpreting the models’ uncertainty during model development and also to\n",
      "audit a given decision.\n",
      "For uncertainty visualization, the dataset from Section 4.1.2 with a training size of\n",
      "to assist in interpreting the models’ uncertainty during model development and also to\n",
      "audit a given decision.\n",
      "For uncertainty visualization, the dataset from Section 4.1.2 with a training size of\n",
      "2.6\u0002104was used. To simulate a realistic real-world setting, some outliers were addedElectronics 2022 ,11, 396 14 of 20\n",
      "2.6\u0002104was used. To simulate a realistic real-world setting, some outliers were addedElectronics 2022 ,11, 396 14 of 20\n",
      "to the test set. These outliers were generated from a Gaussian distribution that had a\n",
      "covariance matrix that is four-times larger than that of the dataset itself. Fifty outliers per\n",
      "class were generated, resulting in a total of 300 outliers.\n",
      "covariance matrix that is four-times larger than that of the dataset itself. Fifty outliers per\n",
      "class were generated, resulting in a total of 300 outliers.\n",
      "In Figure 6, an overview of the uncertainty estimation obtained during the model’s\n",
      "development is shown. In this visualization, the x-axis represents the number of samples\n",
      "In Figure 6, an overview of the uncertainty estimation obtained during the model’s\n",
      "development is shown. In this visualization, the x-axis represents the number of samples\n",
      "where samples are ordered by uncertainty. Using this ordering scheme, it was possible\n",
      "to interpret the overall dataset uncertainty (upper bar), as well as the proportion of the\n",
      "where samples are ordered by uncertainty. Using this ordering scheme, it was possible\n",
      "to interpret the overall dataset uncertainty (upper bar), as well as the proportion of the\n",
      "different sources of uncertainty across the dataset (lower bars). The size of each bar\n",
      "represents the number of samples rejected by each type of uncertainty. Furthermore, this\n",
      "different sources of uncertainty across the dataset (lower bars). The size of each bar\n",
      "represents the number of samples rejected by each type of uncertainty. Furthermore, this\n",
      "visualization allowed us to make some observations, such as noting that all rejected samples\n",
      "by model uncertainty were also rejected by aleatoric uncertainty.\n",
      "0.0 0.2 0.4 0.6 0.8 1.0\n",
      "# Samples1e4Uncertain\n",
      "by model uncertainty were also rejected by aleatoric uncertainty.\n",
      "0.0 0.2 0.4 0.6 0.8 1.0\n",
      "# Samples1e4Uncertain\n",
      "0.0 1.0 2.0 3.0 4.0 5.0\n",
      "# Uncertain Samples1e3Aleatoric\n",
      "Model\n",
      "Knowledge\n",
      "Figure 6. Overview of the overall dataset uncertainty ( upper bar ) and uncertainties distribution by\n",
      "the uncertainty source ( lower bars ).\n",
      "# Uncertain Samples1e3Aleatoric\n",
      "Model\n",
      "Knowledge\n",
      "Figure 6. Overview of the overall dataset uncertainty ( upper bar ) and uncertainties distribution by\n",
      "the uncertainty source ( lower bars ).\n",
      "Similarly, this representation can be applied to each individual class. Analyzing the\n",
      "uncertainty by each class can give us insights about the particular limitations of the model\n",
      "Similarly, this representation can be applied to each individual class. Analyzing the\n",
      "uncertainty by each class can give us insights about the particular limitations of the model\n",
      "being used. Figure 7 presents the obtained uncertainty by uncertainty source and class.\n",
      "Note that almost all samples with knowledge uncertainty from Figure 6 were the generated\n",
      "being used. Figure 7 presents the obtained uncertainty by uncertainty source and class.\n",
      "Note that almost all samples with knowledge uncertainty from Figure 6 were the generated\n",
      "outliers and do not have a representation in Figure 7.\n",
      "0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\n",
      "# Samples1e3Class 0\n",
      "0.0 1.0 2.0 3.0 4.0 5.0 6.0\n",
      "# Uncertain Samples1e20.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\n",
      "# Samples1e3Class 1\n",
      "0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\n",
      "# Samples1e3Class 0\n",
      "0.0 1.0 2.0 3.0 4.0 5.0 6.0\n",
      "# Uncertain Samples1e20.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\n",
      "# Samples1e3Class 1\n",
      "0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0\n",
      "# Uncertain Samples1e20.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\n",
      "# Samples1e3Class 2\n",
      "Uncertain\n",
      "0.0 2.0 4.0 6.0 8.0\n",
      "# Uncertain Samples1e2Aleatoric\n",
      "Model\n",
      "Knowledge\n",
      "0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\n",
      "# Samples1e3Class 3\n",
      "# Samples1e3Class 2\n",
      "Uncertain\n",
      "0.0 2.0 4.0 6.0 8.0\n",
      "# Uncertain Samples1e2Aleatoric\n",
      "Model\n",
      "Knowledge\n",
      "0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\n",
      "# Samples1e3Class 3\n",
      "0.0 2.0 4.0 6.0 8.0\n",
      "# Uncertain Samples1e20.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\n",
      "# Samples1e3Class 4\n",
      "0.0 2.0 4.0 6.0 8.0\n",
      "# Uncertain Samples1e20.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\n",
      "# Samples1e3Class 5\n",
      "0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0\n",
      "# Uncertain Samples1e2\n",
      "# Samples1e3Class 4\n",
      "0.0 2.0 4.0 6.0 8.0\n",
      "# Uncertain Samples1e20.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\n",
      "# Samples1e3Class 5\n",
      "0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0\n",
      "# Uncertain Samples1e2\n",
      "Figure 7. Uncertainty distribution by uncertainty source and class.\n",
      "Besides the visualization applied to the overall classiﬁer’s uncertainty, an alternative\n",
      "# Uncertain Samples1e2\n",
      "Figure 7. Uncertainty distribution by uncertainty source and class.\n",
      "Besides the visualization applied to the overall classiﬁer’s uncertainty, an alternative\n",
      "is to audit the reliability of a given prediction, answering questions such as: Can I trust this\n",
      "prediction? Why did I reject this sample?Electronics 2022 ,11, 396 15 of 20\n",
      "is to audit the reliability of a given prediction, answering questions such as: Can I trust this\n",
      "prediction? Why did I reject this sample?Electronics 2022 ,11, 396 15 of 20\n",
      "For this purpose, using the uncertainty estimations for each type of uncertainty,\n",
      "Figure 8 was obtained. In this visualization, the bar’s size represents how much the\n",
      "For this purpose, using the uncertainty estimations for each type of uncertainty,\n",
      "Figure 8 was obtained. In this visualization, the bar’s size represents how much the\n",
      "model is conﬁdent or uncertain about a prediction by uncertainty type. To make the\n",
      "visualization more intuitive, 0 conﬁdence/uncertainty represents the obtained threshold\n",
      "model is conﬁdent or uncertain about a prediction by uncertainty type. To make the\n",
      "visualization more intuitive, 0 conﬁdence/uncertainty represents the obtained threshold\n",
      "for rejecting a sample. Then, the bars’ sizes where normalized between 0 and 1 by the\n",
      "maximum/minimum theoretical value for each uncertainty.\n",
      "Note that, in the aleatoric uncertainty, we visualize the prediction’s expected data\n",
      "maximum/minimum theoretical value for each uncertainty.\n",
      "Note that, in the aleatoric uncertainty, we visualize the prediction’s expected data\n",
      "entropy, meaning that in Figure 8a, the prediction probability was near 100% (entropy of 0).\n",
      "In the case of Figure 8b, the obtained entropy was greater than the deﬁned threshold for\n",
      "entropy, meaning that in Figure 8a, the prediction probability was near 100% (entropy of 0).\n",
      "In the case of Figure 8b, the obtained entropy was greater than the deﬁned threshold for\n",
      "rejection and its value represents approximately 1/3 of the entropies that range between\n",
      "1 and the rejection threshold. In the case of model uncertainty, we evaluated if a given\n",
      "rejection and its value represents approximately 1/3 of the entropies that range between\n",
      "1 and the rejection threshold. In the case of model uncertainty, we evaluated if a given\n",
      "prediction changes between different bootstrap samples, i.e., the bar’s size represents the\n",
      "normalized variation ratios. In Figure 8a, the prediction was the same in all bootstrap\n",
      "prediction changes between different bootstrap samples, i.e., the bar’s size represents the\n",
      "normalized variation ratios. In Figure 8a, the prediction was the same in all bootstrap\n",
      "samples, obtaining a maximum conﬁdence value, and in Figure 8b, the prediction changed\n",
      "half the total number of possibilities, which are given by the number of bootstrap samples\n",
      "samples, obtaining a maximum conﬁdence value, and in Figure 8b, the prediction changed\n",
      "half the total number of possibilities, which are given by the number of bootstrap samples\n",
      "and the number of classes. For instance, this dataset had 6 classes and 20 bootstrap samples\n",
      "were used, meaning that the maximum variation ratio was 0.8, and the prediction from\n",
      "and the number of classes. For instance, this dataset had 6 classes and 20 bootstrap samples\n",
      "were used, meaning that the maximum variation ratio was 0.8, and the prediction from\n",
      "Figure 8b obtained a variation ratio of 0.4. Finally, the knowledge uncertainty represents\n",
      "how much a prediction is similar to the training dataset, in terms of probability density.\n",
      "Figure 8b obtained a variation ratio of 0.4. Finally, the knowledge uncertainty represents\n",
      "how much a prediction is similar to the training dataset, in terms of probability density.\n",
      "Thus, Figure 8a represents a prediction where the combination of the features density\n",
      "resulted in a KDE value close to the rejection threshold, i.e., few training samples were\n",
      "Thus, Figure 8a represents a prediction where the combination of the features density\n",
      "resulted in a KDE value close to the rejection threshold, i.e., few training samples were\n",
      "similar to this prediction. In the case of Figure 8b, the sample was more similar to the\n",
      "samples in the training dataset.\n",
      "1.0\n",
      " 0.5\n",
      " 0.0 0.5 1.0\n",
      "ConfidenceMore\n",
      "ConfidentMore\n",
      "UncertainAleatoric\n",
      "Model\n",
      "similar to this prediction. In the case of Figure 8b, the sample was more similar to the\n",
      "samples in the training dataset.\n",
      "1.0\n",
      " 0.5\n",
      " 0.0 0.5 1.0\n",
      "ConfidenceMore\n",
      "ConfidentMore\n",
      "UncertainAleatoric\n",
      "Model\n",
      "KnowledgePredicted Class: 0\n",
      "(a)\n",
      "1.0\n",
      " 0.5\n",
      " 0.0 0.5 1.0\n",
      "ConfidenceMore\n",
      "ConfidentMore\n",
      "UncertainAleatoric\n",
      "Model\n",
      "KnowledgePredicted Class: 4 (b)\n",
      "ConfidenceMore\n",
      "ConfidentMore\n",
      "UncertainAleatoric\n",
      "Model\n",
      "KnowledgePredicted Class: 0\n",
      "(a)\n",
      "1.0\n",
      " 0.5\n",
      " 0.0 0.5 1.0\n",
      "ConfidenceMore\n",
      "ConfidentMore\n",
      "UncertainAleatoric\n",
      "Model\n",
      "KnowledgePredicted Class: 4 (b)\n",
      "Figure 8. Prediction uncertainty. A conﬁdence value of 0 represents the obtained threshold for reject-\n",
      "ing a sample by the uncertainty source. Bars’ sizes are normalized between the maximum theoretical\n",
      "ing a sample by the uncertainty source. Bars’ sizes are normalized between the maximum theoretical\n",
      "conﬁdence/uncertainty. ( a) Prediction not rejected by all uncertainty sources. ( b) Prediction rejected\n",
      "by aleatoric and model uncertainty.\n",
      "4.2. Experiments on a Human Activity Recognition Dataset\n",
      "In order to broaden our analysis, we conducted an additional experiment with a\n",
      "by aleatoric and model uncertainty.\n",
      "4.2. Experiments on a Human Activity Recognition Dataset\n",
      "In order to broaden our analysis, we conducted an additional experiment with a\n",
      "benchmark dataset from the UCI repository [ 38]. As a case study, we selected a Human\n",
      "Activity Recognition (HAR) dataset [39] that contains six classes ( walking ,walking upstairs ,\n",
      "benchmark dataset from the UCI repository [ 38]. As a case study, we selected a Human\n",
      "Activity Recognition (HAR) dataset [39] that contains six classes ( walking ,walking upstairs ,\n",
      "walking downstairs ,sitting ,standing , and laying ), recorded with the accelerometer and\n",
      "gyroscope smartphone sensors. Besides the importance of UQ for trustworthy ML systems,\n",
      "walking downstairs ,sitting ,standing , and laying ), recorded with the accelerometer and\n",
      "gyroscope smartphone sensors. Besides the importance of UQ for trustworthy ML systems,\n",
      "the use of uncertainty measures for human movements analysis plays also an important role\n",
      "in the recognition of abnormal human activities or the analysis, diagnosis, and monitoring\n",
      "the use of uncertainty measures for human movements analysis plays also an important role\n",
      "in the recognition of abnormal human activities or the analysis, diagnosis, and monitoring\n",
      "of neurodegenerative conditions [ 40]. Furthermore, the high number of available samples\n",
      "(10,299 samples) in this dataset allowed us to make a similar evaluation to the synthetic\n",
      "of neurodegenerative conditions [ 40]. Furthermore, the high number of available samples\n",
      "(10,299 samples) in this dataset allowed us to make a similar evaluation to the synthetic\n",
      "data. For the data split into training and test sets, we used the available partition in the\n",
      "repository, where 70% of the volunteers were selected for generating the training data and\n",
      "data. For the data split into training and test sets, we used the available partition in the\n",
      "repository, where 70% of the volunteers were selected for generating the training data and\n",
      "30% the test data. Regarding the feature vector, the original 561-feature vector with time\n",
      "and frequency domain variables was reduced using features correlation and the sequential\n",
      "30% the test data. Regarding the feature vector, the original 561-feature vector with time\n",
      "and frequency domain variables was reduced using features correlation and the sequential\n",
      "forward feature selector, resulting in a 17-dimensional feature vector.Electronics 2022 ,11, 396 16 of 20\n",
      "Similar to Section 4.1.1, we applied a training size exponential growth, starting with\n",
      "forward feature selector, resulting in a 17-dimensional feature vector.Electronics 2022 ,11, 396 16 of 20\n",
      "Similar to Section 4.1.1, we applied a training size exponential growth, starting with\n",
      "300 samples (50 per class) until the maximum training size of 7352 samples. For model\n",
      "training, we tested different classiﬁers with 20 bootstrap samples. Table 3 shows the\n",
      "300 samples (50 per class) until the maximum training size of 7352 samples. For model\n",
      "training, we tested different classiﬁers with 20 bootstrap samples. Table 3 shows the\n",
      "obtained baseline accuracy, as well as the nonrejected accuracy and the rejection fraction for\n",
      "each of the tested classiﬁers. To visualize the behavior of accuracy and the corresponding\n",
      "obtained baseline accuracy, as well as the nonrejected accuracy and the rejection fraction for\n",
      "each of the tested classiﬁers. To visualize the behavior of accuracy and the corresponding\n",
      "rejection fraction for each type of uncertainty, we selected the 4 models that obtained higher\n",
      "baseline accuracy. Figure 9 shows these performance measures with the increased number\n",
      "rejection fraction for each type of uncertainty, we selected the 4 models that obtained higher\n",
      "baseline accuracy. Figure 9 shows these performance measures with the increased number\n",
      "of samples used to train the classiﬁers.\n",
      "Table 3. Performance measures for different models using a training size of 7352 samples and the\n",
      "Human Activity Recognition (HAR) dataset.\n",
      "ModelBaseline Nonrejected Rejection\n",
      "Table 3. Performance measures for different models using a training size of 7352 samples and the\n",
      "Human Activity Recognition (HAR) dataset.\n",
      "ModelBaseline Nonrejected Rejection\n",
      "Accuracy Accuracy Fraction\n",
      "Gaussian Naive Bayes 0.89 0.90 0.03\n",
      "KDE Bayes 0.88 0.92 0.12\n",
      "Logistic Regression 0.89 0.92 0.06\n",
      "Decision Tree 0.82 0.92 0.23\n",
      "Random Forest 0.84 0.91 0.16\n",
      "k-Nearest Neighbors 0.87 0.94 0.13\n",
      "Gaussian Naive Bayes 0.89 0.90 0.03\n",
      "KDE Bayes 0.88 0.92 0.12\n",
      "Logistic Regression 0.89 0.92 0.06\n",
      "Decision Tree 0.82 0.92 0.23\n",
      "Random Forest 0.84 0.91 0.16\n",
      "k-Nearest Neighbors 0.87 0.94 0.13\n",
      "Support Vector Machines 0.91 0.93 0.06\n",
      "0.00.10.20.3Rejection Fraction\n",
      "Guassian Naive Bayes\n",
      " KDE Bayes\n",
      " Support Vector Machines\n",
      " Logistic Regression\n",
      "Aleatoric\n",
      "Model\n",
      "Knowledge\n",
      "103104\n",
      "Support Vector Machines 0.91 0.93 0.06\n",
      "0.00.10.20.3Rejection Fraction\n",
      "Guassian Naive Bayes\n",
      " KDE Bayes\n",
      " Support Vector Machines\n",
      " Logistic Regression\n",
      "Aleatoric\n",
      "Model\n",
      "Knowledge\n",
      "103104\n",
      "# train samples0.800.850.900.951.00Accuracy\n",
      "103104\n",
      "# train samples\n",
      "103104\n",
      "# train samples\n",
      "103104\n",
      "# train samples\n",
      "Baseline\n",
      "NRA\n",
      "Logistic Regression\n",
      "Aleatoric\n",
      "Model\n",
      "Knowledge\n",
      "103104\n",
      "# train samples0.800.850.900.951.00Accuracy\n",
      "103104\n",
      "# train samples\n",
      "103104\n",
      "# train samples\n",
      "103104\n",
      "# train samples\n",
      "Baseline\n",
      "NRA\n",
      "Figure 9. Uncertainties’ rejection fraction and obtained accuracies with the increasing number of\n",
      "training samples for the Human Activity Recognition (HAR) dataset.\n",
      "103104\n",
      "# train samples\n",
      "Baseline\n",
      "NRA\n",
      "Figure 9. Uncertainties’ rejection fraction and obtained accuracies with the increasing number of\n",
      "training samples for the Human Activity Recognition (HAR) dataset.\n",
      "For the HAR dataset, the rejection fraction obtained with both the aleatoric and\n",
      "knowledge uncertainty measures presented a low value for all training sizes and classiﬁers\n",
      "For the HAR dataset, the rejection fraction obtained with both the aleatoric and\n",
      "knowledge uncertainty measures presented a low value for all training sizes and classiﬁers\n",
      "being analyzed. As expected, regarding the model uncertainty, the rejection fraction\n",
      "decreased with the increasing number of training samples for all classiﬁers, where more\n",
      "being analyzed. As expected, regarding the model uncertainty, the rejection fraction\n",
      "decreased with the increasing number of training samples for all classiﬁers, where more\n",
      "complex classiﬁers had a higher rejection fraction than simpler classiﬁers. Due to the low\n",
      "obtained uncertainty (rejection fraction < 4%) and satisfactory accuracy (baseline accuracy\n",
      "complex classiﬁers had a higher rejection fraction than simpler classiﬁers. Due to the low\n",
      "obtained uncertainty (rejection fraction < 4%) and satisfactory accuracy (baseline accuracy\n",
      "of 89%), the Gaussian NB classiﬁer was selected.\n",
      "Using the visualization scheme presented in Section 4.1.3, Figure 10 shows the overall\n",
      "of 89%), the Gaussian NB classiﬁer was selected.\n",
      "Using the visualization scheme presented in Section 4.1.3, Figure 10 shows the overall\n",
      "dataset uncertainty and the uncertainty type distribution across the uncertain samples.\n",
      "Although only 4% of the test samples were rejected, we can make some observations about\n",
      "dataset uncertainty and the uncertainty type distribution across the uncertain samples.\n",
      "Although only 4% of the test samples were rejected, we can make some observations about\n",
      "the uncertain samples. The majority of uncertain samples rejected by aleatoric uncertainty\n",
      "were also rejected by model uncertainty. Regions with an overlap between classes (aleatoric\n",
      "the uncertain samples. The majority of uncertain samples rejected by aleatoric uncertainty\n",
      "were also rejected by model uncertainty. Regions with an overlap between classes (aleatoric\n",
      "uncertainty) were also regions where it was expected that the model ﬁt would change\n",
      "between bootstrap samples. In the case of knowledge uncertainty, it was expected that\n",
      "uncertainty) were also regions where it was expected that the model ﬁt would change\n",
      "between bootstrap samples. In the case of knowledge uncertainty, it was expected that\n",
      "samples with knowledge uncertainty would not have aleatoric uncertainty. However, forElectronics 2022 ,11, 396 17 of 20\n",
      "model uncertainty, it is possible that some samples shared both model and knowledge\n",
      "model uncertainty, it is possible that some samples shared both model and knowledge\n",
      "uncertainty, which is also veriﬁed with Figure 10.\n",
      "0.0 0.5 1.0 1.5 2.0 2.5\n",
      "# Samples1e3Uncertain\n",
      "0.0 0.2 0.4 0.6 0.8 1.0\n",
      "# Uncertain Samples1e2Aleatoric\n",
      "Model\n",
      "Knowledge\n",
      "Figure 10. HAR dataset uncertainty overview.\n",
      "Figure 11 shows the uncertainty distribution by class. From it, we can conclude that\n",
      "# Uncertain Samples1e2Aleatoric\n",
      "Model\n",
      "Knowledge\n",
      "Figure 10. HAR dataset uncertainty overview.\n",
      "Figure 11 shows the uncertainty distribution by class. From it, we can conclude that\n",
      "aleatoric uncertainty was presented only in walking ,walking upstairs and walking downstairs ,\n",
      "which makes perfect sense due to the similarity of these three classes. It is also possible to\n",
      "aleatoric uncertainty was presented only in walking ,walking upstairs and walking downstairs ,\n",
      "which makes perfect sense due to the similarity of these three classes. It is also possible to\n",
      "note that laying class did not have aleatoric or model uncertainty. However, it was the class\n",
      "with the highest knowledge uncertainty. Both sitting and standing classes had a similar\n",
      "note that laying class did not have aleatoric or model uncertainty. However, it was the class\n",
      "with the highest knowledge uncertainty. Both sitting and standing classes had a similar\n",
      "pattern in terms of uncertainty, where the sitting class was the one with the highest number\n",
      "of uncertain samples.\n",
      "0.0 1.0 2.0 3.0 4.0\n",
      "# Samples1e2Walking\n",
      "0.0 1.0 2.0 3.0 4.0 5.0\n",
      "# Uncertain Samples0.0 1.0 2.0 3.0 4.0\n",
      "of uncertain samples.\n",
      "0.0 1.0 2.0 3.0 4.0\n",
      "# Samples1e2Walking\n",
      "0.0 1.0 2.0 3.0 4.0 5.0\n",
      "# Uncertain Samples0.0 1.0 2.0 3.0 4.0\n",
      "# Samples1e2Walking Upstairs\n",
      "0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\n",
      "# Uncertain Samples1e10.0 1.0 2.0 3.0 4.0\n",
      "# Samples1e2Walking Downstairs\n",
      "Uncertain\n",
      "0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0\n",
      "# Uncertain SamplesAleatoric\n",
      "Model\n",
      "Knowledge\n",
      "0.0 1.0 2.0 3.0 4.0\n",
      "# Samples1e2Sitting\n",
      "# Samples1e2Walking Downstairs\n",
      "Uncertain\n",
      "0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0\n",
      "# Uncertain SamplesAleatoric\n",
      "Model\n",
      "Knowledge\n",
      "0.0 1.0 2.0 3.0 4.0\n",
      "# Samples1e2Sitting\n",
      "0.0 1.0 2.0 3.0 4.0\n",
      "# Uncertain Samples1e10.0 1.0 2.0 3.0 4.0 5.0\n",
      "# Samples1e2Standing\n",
      "0.0 0.5 1.0 1.5 2.0\n",
      "# Uncertain Samples1e10.0 1.0 2.0 3.0 4.0 5.0\n",
      "# Samples1e2Laying\n",
      "0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8 2.0\n",
      "# Uncertain Samples1e1\n",
      "# Samples1e2Standing\n",
      "0.0 0.5 1.0 1.5 2.0\n",
      "# Uncertain Samples1e10.0 1.0 2.0 3.0 4.0 5.0\n",
      "# Samples1e2Laying\n",
      "0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8 2.0\n",
      "# Uncertain Samples1e1\n",
      "Figure 11. HAR dataset uncertainty overview by class.\n",
      "To validate the combination strategy proposed in Section 4.1.2 using a real dataset,\n",
      "we decided to combine the two models with lower accuracy and higher uncertainty. Thus,\n",
      "To validate the combination strategy proposed in Section 4.1.2 using a real dataset,\n",
      "we decided to combine the two models with lower accuracy and higher uncertainty. Thus,\n",
      "the KDE Bayes model and logistic regression were combined for the different training\n",
      "sizes. To compare the performance of classiﬁers with rejection, we needed to ensure\n",
      "the KDE Bayes model and logistic regression were combined for the different training\n",
      "sizes. To compare the performance of classiﬁers with rejection, we needed to ensure\n",
      "the same rejection fraction for the three classiﬁers. Thus, the obtained rejection fraction\n",
      "for the models’ combination, given by Equation (16), was employed for both the KDE\n",
      "the same rejection fraction for the three classiﬁers. Thus, the obtained rejection fraction\n",
      "for the models’ combination, given by Equation (16), was employed for both the KDE\n",
      "Bayes and logistic regression classiﬁers. Figure 12 shows the performance measures for\n",
      "classiﬁcation with rejection for the individual models and their combination. Observing\n",
      "Bayes and logistic regression classiﬁers. Figure 12 shows the performance measures for\n",
      "classiﬁcation with rejection for the individual models and their combination. Observing\n",
      "the results, we can conclude that the combination strategy outperformed the individual\n",
      "classiﬁers for almost all training sizes and performance measures. It is also interesting\n",
      "the results, we can conclude that the combination strategy outperformed the individual\n",
      "classiﬁers for almost all training sizes and performance measures. It is also interesting\n",
      "to note that the combination strategy resulted always in a lower rejection fraction thanElectronics 2022 ,11, 396 18 of 20\n",
      "the obtained rejection fraction for the individual classiﬁers, which can be conﬁrmed by\n",
      "the obtained rejection fraction for the individual classiﬁers, which can be conﬁrmed by\n",
      "analyzing Figures 9 and 12.\n",
      "103104\n",
      "# train samples0.8000.8250.8500.8750.9000.9250.950Nonrejected Accuracy\n",
      "103104\n",
      "# train samples0.800.820.840.860.880.90Classification Quality\n",
      "103104\n",
      "# train samples2.55.07.510.012.515.0Rejection Quality\n",
      "103104\n",
      "# train samples0.020.040.060.08Rejection Fraction\n",
      "103104\n",
      "# train samples0.800.820.840.860.880.90Classification Quality\n",
      "103104\n",
      "# train samples2.55.07.510.012.515.0Rejection Quality\n",
      "103104\n",
      "# train samples0.020.040.060.08Rejection Fraction\n",
      "KDE Bayes Logistic Regression Models' Combination\n",
      "Figure 12. Performance measures for classiﬁcation with rejection for different training sizes.\n",
      "5. Conclusions\n",
      "KDE Bayes Logistic Regression Models' Combination\n",
      "Figure 12. Performance measures for classiﬁcation with rejection for different training sizes.\n",
      "5. Conclusions\n",
      "As ML models are increasingly being integrated into safety-critical applications, in-\n",
      "corporating uncertainty quantiﬁcation estimates should become a required part of the ML\n",
      "5. Conclusions\n",
      "As ML models are increasingly being integrated into safety-critical applications, in-\n",
      "corporating uncertainty quantiﬁcation estimates should become a required part of the ML\n",
      "methodology. Uncertainty quantiﬁcation can be used for “uncertainty-informed” decisions\n",
      "and to support developers and end-users by increasing the interpretability of and trust in\n",
      "model predictions.\n",
      "methodology. Uncertainty quantiﬁcation can be used for “uncertainty-informed” decisions\n",
      "and to support developers and end-users by increasing the interpretability of and trust in\n",
      "model predictions.\n",
      "We introduced a complete study focused on how uncertainty quantiﬁcation can be\n",
      "used in practice through three research questions: (1) How can UQ contribute to choosing\n",
      "model predictions.\n",
      "We introduced a complete study focused on how uncertainty quantiﬁcation can be\n",
      "used in practice through three research questions: (1) How can UQ contribute to choosing\n",
      "the most suitable model for a given classiﬁcation task? (2) Can UQ be used to combine\n",
      "different models in a principled manner? (3) Can visualization techniques improve UQ’s\n",
      "the most suitable model for a given classiﬁcation task? (2) Can UQ be used to combine\n",
      "different models in a principled manner? (3) Can visualization techniques improve UQ’s\n",
      "interpretability? These questions were answered using a synthetic dataset and a HAR\n",
      "dataset from the UCI repository.\n",
      "Regarding the ﬁrst question, we showed that uncertainty quantiﬁcation in combination\n",
      "dataset from the UCI repository.\n",
      "Regarding the ﬁrst question, we showed that uncertainty quantiﬁcation in combination\n",
      "with the model’s accuracy can give us important elements to choose the most suitable\n",
      "model. For instance, the decision between different classiﬁers with the same accuracy\n",
      "can beneﬁt from the uncertainty quantiﬁcation methods, whereas classiﬁers with lower\n",
      "model. For instance, the decision between different classiﬁers with the same accuracy\n",
      "can beneﬁt from the uncertainty quantiﬁcation methods, whereas classiﬁers with lower\n",
      "degrees of uncertainty can be preferable. Furthermore, if model uncertainty is high and the\n",
      "addition of new samples is possible, the increase of training samples can reduce the model\n",
      "degrees of uncertainty can be preferable. Furthermore, if model uncertainty is high and the\n",
      "addition of new samples is possible, the increase of training samples can reduce the model\n",
      "uncertainty and consequently increase the model’s accuracy. By using uncertainty as a\n",
      "complement of performance measures, we can make more informed decisions in model\n",
      "uncertainty and consequently increase the model’s accuracy. By using uncertainty as a\n",
      "complement of performance measures, we can make more informed decisions in model\n",
      "selection. In future work, we will explore how the UQ measures can be used in the context\n",
      "of active learning. Active learning is the subset of ML in which the learning algorithm\n",
      "selection. In future work, we will explore how the UQ measures can be used in the context\n",
      "of active learning. Active learning is the subset of ML in which the learning algorithm\n",
      "queries users to label training data. The choice of the samples to be labeled is achieved\n",
      "through measures that rank samples based on their potential informativeness. Alternative\n",
      "queries users to label training data. The choice of the samples to be labeled is achieved\n",
      "through measures that rank samples based on their potential informativeness. Alternative\n",
      "or complementary ranking measures based on uncertainty can be explored.\n",
      "Based on two models with different degrees of uncertainty, we proposed a naive\n",
      "or complementary ranking measures based on uncertainty can be explored.\n",
      "Based on two models with different degrees of uncertainty, we proposed a naive\n",
      "uncertainty combination approach for models’ combination to answer the second question.\n",
      "The preliminary results showed that the combination strategy outperformed the individual\n",
      "uncertainty combination approach for models’ combination to answer the second question.\n",
      "The preliminary results showed that the combination strategy outperformed the individual\n",
      "models. Although the proposed naive approach achieved good results, the combination\n",
      "strategy presented some limitations for its application in a scenario with more than two\n",
      "models. Although the proposed naive approach achieved good results, the combination\n",
      "strategy presented some limitations for its application in a scenario with more than two\n",
      "models. A more versatile combination that considers the possibility of adding more\n",
      "models and uses their degree of uncertainty must be developed. Therefore, for future\n",
      "models. A more versatile combination that considers the possibility of adding more\n",
      "models and uses their degree of uncertainty must be developed. Therefore, for future\n",
      "work, we will explore more comprehensive model combination methods to address more\n",
      "complex problems.\n",
      "In the third question, we explored visualization techniques to assist in interpreting\n",
      "work, we will explore more comprehensive model combination methods to address more\n",
      "complex problems.\n",
      "In the third question, we explored visualization techniques to assist in interpreting\n",
      "classiﬁers’ uncertainty during the model’s development and also to audit a given decision.\n",
      "Understanding which type of uncertainty is present during the model’s development can\n",
      "classiﬁers’ uncertainty during the model’s development and also to audit a given decision.\n",
      "Understanding which type of uncertainty is present during the model’s development can\n",
      "give us insights into the limitations of each model and allow us to take actions in accordance.\n",
      "In the context of prediction reliability, the proposed visualization techniques were used to\n",
      "give us insights into the limitations of each model and allow us to take actions in accordance.\n",
      "In the context of prediction reliability, the proposed visualization techniques were used to\n",
      "access the interpretability of the rejection option in which a rejection may correspond to\n",
      "a low prediction probability (aleatoric uncertainty), a poor model ﬁt (model uncertainty),\n",
      "access the interpretability of the rejection option in which a rejection may correspond to\n",
      "a low prediction probability (aleatoric uncertainty), a poor model ﬁt (model uncertainty),\n",
      "or an outlier (knowledge uncertainty). As a limitation of our study, we identify that anElectronics 2022 ,11, 396 19 of 20\n",
      "individual rejection threshold for each source of uncertainty may not be a reliable solution\n",
      "individual rejection threshold for each source of uncertainty may not be a reliable solution\n",
      "for every ML problem. Deﬁning the best rejection threshold is still an open challenge. Our\n",
      "future research on this topic will focus on understanding how optimization techniques\n",
      "can be used to establish the most adequate rejection thresholds, either individually or by\n",
      "future research on this topic will focus on understanding how optimization techniques\n",
      "can be used to establish the most adequate rejection thresholds, either individually or by\n",
      "unifying the three quantiﬁcation measures.\n",
      "We hope this paper might spark future research on how to consider uncertainty\n",
      "quantiﬁcation as a tool to improve the ML model development lifecycle.\n",
      "unifying the three quantiﬁcation measures.\n",
      "We hope this paper might spark future research on how to consider uncertainty\n",
      "quantiﬁcation as a tool to improve the ML model development lifecycle.\n",
      "Author Contributions: Conceptualization, M.B. and H.G.; methodology, M.B., D.F. and H.G.;\n",
      "software, M.B.; validation, M.B., D.F. and H.G.; investigation, M.B., D.F., R.S. (Ricardo Santos),\n",
      "Author Contributions: Conceptualization, M.B. and H.G.; methodology, M.B., D.F. and H.G.;\n",
      "software, M.B.; validation, M.B., D.F. and H.G.; investigation, M.B., D.F., R.S. (Ricardo Santos),\n",
      "R.S. (Raquel Simão) and H.G.; writing—original draft preparation, M.B. and D.F.; writing— review\n",
      "and editing, M.B., D.F., R.S. (Ricardo Santos), R.S. (Raquel Simão) and H.G.; visualization,\n",
      "R.S. (Raquel Simão) and H.G.; writing—original draft preparation, M.B. and D.F.; writing— review\n",
      "and editing, M.B., D.F., R.S. (Ricardo Santos), R.S. (Raquel Simão) and H.G.; visualization,\n",
      "R.S. (Ricardo Santos) and M.B.; supervision, H.G. All authors have read and agreed to the published\n",
      "version of the manuscript.\n",
      "R.S. (Ricardo Santos) and M.B.; supervision, H.G. All authors have read and agreed to the published\n",
      "version of the manuscript.\n",
      "Funding: This research was ﬁnancially supported by the project Geolocation non-Assisted by GPS\n",
      "for Mobile Networks in Indoor and Outdoor Environment (GARMIO), co-funded by Portugal 2020,\n",
      "Funding: This research was ﬁnancially supported by the project Geolocation non-Assisted by GPS\n",
      "for Mobile Networks in Indoor and Outdoor Environment (GARMIO), co-funded by Portugal 2020,\n",
      "framed under the COMPETE 2020 (Operational Programme Competitiveness and Internationaliza-\n",
      "tion) and European Regional Development Fund (ERDF) from European Union (EU), with Operation\n",
      "framed under the COMPETE 2020 (Operational Programme Competitiveness and Internationaliza-\n",
      "tion) and European Regional Development Fund (ERDF) from European Union (EU), with Operation\n",
      "Code POCI-01-0247-FEDER-033479.\n",
      "Institutional Review Board Statement: Not applicable\n",
      "Informed Consent Statement: Not applicable.\n",
      "Code POCI-01-0247-FEDER-033479.\n",
      "Institutional Review Board Statement: Not applicable\n",
      "Informed Consent Statement: Not applicable.\n",
      "Data Availability Statement: Publicly available datasets were analyzed in this study. These data can\n",
      "be found at the UC Irvine Machine Learning Repository, available at https://archive.ics.uci.edu/ml/\n",
      "Data Availability Statement: Publicly available datasets were analyzed in this study. These data can\n",
      "be found at the UC Irvine Machine Learning Repository, available at https://archive.ics.uci.edu/ml/\n",
      "datasets/human+activity+recognition+using+smartphones (accessed on 20 December 2021).\n",
      "Conﬂicts of Interest: The authors declare no conﬂict of interest.\n",
      "References\n",
      "datasets/human+activity+recognition+using+smartphones (accessed on 20 December 2021).\n",
      "Conﬂicts of Interest: The authors declare no conﬂict of interest.\n",
      "References\n",
      "1. Cobb, A.D.; Jalaian, B.; Bastian, N.D.; Russell, S. Toward Safe Decision-Making via Uncertainty Quantiﬁcation in Machine\n",
      "Conﬂicts of Interest: The authors declare no conﬂict of interest.\n",
      "References\n",
      "1. Cobb, A.D.; Jalaian, B.; Bastian, N.D.; Russell, S. Toward Safe Decision-Making via Uncertainty Quantiﬁcation in Machine\n",
      "Learning. In Systems Engineering and Artiﬁcial Intelligence ; Springer: Berlin/Heidelberg, Germany, 2021; pp. 379–399.\n",
      "Learning. In Systems Engineering and Artiﬁcial Intelligence ; Springer: Berlin/Heidelberg, Germany, 2021; pp. 379–399.\n",
      "2. Senge, R.; Bösner, S.; Dembczy´ nski, K.; Haasenritter, J.; Hirsch, O.; Donner-Banzhoff, N.; Hüllermeier, E. Reliable classiﬁcation:\n",
      "Learning classiﬁers that distinguish aleatoric and epistemic uncertainty. Inf. Sci. 2014 ,255, 16–29. [CrossRef]\n",
      "Learning classiﬁers that distinguish aleatoric and epistemic uncertainty. Inf. Sci. 2014 ,255, 16–29. [CrossRef]\n",
      "3. Kompa, B.; Snoek, J.; Beam, A.L. Second opinion needed: Communicating uncertainty in medical machine learning. NPJ Digit.\n",
      "Med. 2021 ,4, 1–6. [CrossRef] [PubMed]\n",
      "4. Hüllermeier, E.; Waegeman, W. Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and\n",
      "Med. 2021 ,4, 1–6. [CrossRef] [PubMed]\n",
      "4. Hüllermeier, E.; Waegeman, W. Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and\n",
      "methods. Mach. Learn. 2021 ,110, 457–506. [CrossRef]\n",
      "5. Huang, Z.; Lam, H.; Zhang, H. Quantifying Epistemic Uncertainty in Deep Learning. arXiv 2021 , arXiv:2110.12122.\n",
      "methods. Mach. Learn. 2021 ,110, 457–506. [CrossRef]\n",
      "5. Huang, Z.; Lam, H.; Zhang, H. Quantifying Epistemic Uncertainty in Deep Learning. arXiv 2021 , arXiv:2110.12122.\n",
      "6. Holzinger, A.; Langs, G.; Denk, H.; Zatloukal, K.; Müller, H. Causability and explainability of artiﬁcial intelligence in medicine.\n",
      "Wiley Interdiscip. Rev. Data Min. Knowl. Discov. 2019 ,9, e1312. [CrossRef] [PubMed]\n",
      "Wiley Interdiscip. Rev. Data Min. Knowl. Discov. 2019 ,9, e1312. [CrossRef] [PubMed]\n",
      "7. Nguyen, V .L.; Shaker, M.H.; Hüllermeier, E. How to measure uncertainty in uncertainty sampling for active learning. Mach.\n",
      "Learn. 2021 , 1–34. [CrossRef]\n",
      "8. Bota, P .; Silva, J.; Folgado, D.; Gamboa, H. A semi-automatic annotation approach for human activity recognition. Sensors 2019 ,\n",
      "Learn. 2021 , 1–34. [CrossRef]\n",
      "8. Bota, P .; Silva, J.; Folgado, D.; Gamboa, H. A semi-automatic annotation approach for human activity recognition. Sensors 2019 ,\n",
      "19, 501. [CrossRef] [PubMed]\n",
      "9. Ghosh, S.; Liao, Q.V .; Ramamurthy, K.N.; Navratil, J.; Sattigeri, P .; Varshney, K.R.; Zhang, Y. Uncertainty Quantiﬁcation 360: A\n",
      "19, 501. [CrossRef] [PubMed]\n",
      "9. Ghosh, S.; Liao, Q.V .; Ramamurthy, K.N.; Navratil, J.; Sattigeri, P .; Varshney, K.R.; Zhang, Y. Uncertainty Quantiﬁcation 360: A\n",
      "Holistic Toolkit for Quantifying and Communicating the Uncertainty of AI. arXiv 2021 , arXiv:2106.01410.\n",
      "Holistic Toolkit for Quantifying and Communicating the Uncertainty of AI. arXiv 2021 , arXiv:2106.01410.\n",
      "10. Chung, Y.; Char, I.; Guo, H.; Schneider, J.; Neiswanger, W. Uncertainty toolbox: An open-source library for assessing, visualizing,\n",
      "and improving uncertainty quantiﬁcation. arXiv 2021 , arXiv:2109.10254.\n",
      "and improving uncertainty quantiﬁcation. arXiv 2021 , arXiv:2109.10254.\n",
      "11. Oala, L.; Murchison, A.G.; Balachandran, P .; Choudhary, S.; Fehr, J.; Leite, A.W.; Goldschmidt, P .G.; Johner, C.; Schörverth, E.D.;\n",
      "Nakasi, R.; et al. Machine Learning for Health: Algorithm Auditing & Quality Control. J. Med. Syst. 2021 ,45, 1–8.\n",
      "Nakasi, R.; et al. Machine Learning for Health: Algorithm Auditing & Quality Control. J. Med. Syst. 2021 ,45, 1–8.\n",
      "12. Bosni´ c, Z.; Kononenko, I. An overview of advances in reliability estimation of individual predictions in machine learning. Intell.\n",
      "Data Anal. 2009 ,13, 385–401. [CrossRef]\n",
      "12. Bosni´ c, Z.; Kononenko, I. An overview of advances in reliability estimation of individual predictions in machine learning. Intell.\n",
      "Data Anal. 2009 ,13, 385–401. [CrossRef]\n",
      "13. Tornede, A.; Gehring, L.; Tornede, T.; Wever, M.; Hüllermeier, E. Algorithm selection on a meta level. arXiv 2021 , arXiv:2107.09414.\n",
      "Data Anal. 2009 ,13, 385–401. [CrossRef]\n",
      "13. Tornede, A.; Gehring, L.; Tornede, T.; Wever, M.; Hüllermeier, E. Algorithm selection on a meta level. arXiv 2021 , arXiv:2107.09414.\n",
      "14. Neto, M.P .; Paulovich, F.V . Explainable Matrix-Visualization for Global and Local Interpretability of Random Forest Classiﬁcation\n",
      "Ensembles. IEEE Trans. Vis. Comput. Graph. 2020 ,27, 1427–1437. [CrossRef] [PubMed]\n",
      "Ensembles. IEEE Trans. Vis. Comput. Graph. 2020 ,27, 1427–1437. [CrossRef] [PubMed]\n",
      "15. Shaker, M.H.; Hüllermeier, E. Ensemble-based Uncertainty Quantification: Bayesian versus Credal Inference. arXiv 2021, arXiv:2107.10384.\n",
      "16. Malinin, A.; Prokhorenkova, L.; Ustimenko, A. Uncertainty in gradient boosting via ensembles. arXiv 2020 , arXiv:2006.10562.Electronics 2022 ,11, 396 20 of 20\n",
      "16. Malinin, A.; Prokhorenkova, L.; Ustimenko, A. Uncertainty in gradient boosting via ensembles. arXiv 2020 , arXiv:2006.10562.Electronics 2022 ,11, 396 20 of 20\n",
      "17. Depeweg, S.; Hernandez-Lobato, J.M.; Doshi-Velez, F.; Udluft, S. Decomposition of uncertainty in Bayesian deep learning for\n",
      "17. Depeweg, S.; Hernandez-Lobato, J.M.; Doshi-Velez, F.; Udluft, S. Decomposition of uncertainty in Bayesian deep learning for\n",
      "efﬁcient and risk-sensitive learning. In Proceedings of the International Conference on Machine Learning, Stockholm, Sweden,\n",
      "10–15 July 2018; pp. 1184–1193.\n",
      "efﬁcient and risk-sensitive learning. In Proceedings of the International Conference on Machine Learning, Stockholm, Sweden,\n",
      "10–15 July 2018; pp. 1184–1193.\n",
      "18. Shaker, M.H.; Hüllermeier, E. Aleatoric and epistemic uncertainty with random forests. arXiv 2020 , arXiv:2001.00893.\n",
      "10–15 July 2018; pp. 1184–1193.\n",
      "18. Shaker, M.H.; Hüllermeier, E. Aleatoric and epistemic uncertainty with random forests. arXiv 2020 , arXiv:2001.00893.\n",
      "19. Efron, B.; Tibshirani, R. Bootstrap methods for standard errors, conﬁdence intervals, and other measures of statistical accuracy.\n",
      "Stat. Sci. 1986 ,1, 54–75. [CrossRef]\n",
      "19. Efron, B.; Tibshirani, R. Bootstrap methods for standard errors, conﬁdence intervals, and other measures of statistical accuracy.\n",
      "Stat. Sci. 1986 ,1, 54–75. [CrossRef]\n",
      "20. Stracuzzi, D.J.; Darling, M.C.; Peterson, M.G.; Chen, M.G. Quantifying Uncertainty to Improve Decision Making in Machine Learning ;\n",
      "Technical Report; Sandia National Lab. (SNL-NM): Albuquerque, NM, USA, 2018.\n",
      "Technical Report; Sandia National Lab. (SNL-NM): Albuquerque, NM, USA, 2018.\n",
      "21. Mena, J.; Pujol, O.; Vitrià, J. Uncertainty-based rejection wrappers for black-box classiﬁers. IEEE Access 2020 ,8, 101721–101746.\n",
      "[CrossRef]\n",
      "22. Geng, C.; Huang, S.j.; Chen, S. Recent advances in open set recognition: A survey. IEEE Trans. Pattern Anal. Mach. Intell. 2020 ,43,\n",
      "3614–3631. [CrossRef]\n",
      "[CrossRef]\n",
      "22. Geng, C.; Huang, S.j.; Chen, S. Recent advances in open set recognition: A survey. IEEE Trans. Pattern Anal. Mach. Intell. 2020 ,43,\n",
      "3614–3631. [CrossRef]\n",
      "23. Perello-Nieto, M.; Telmo De Menezes Filho, E.S.; Kull, M.; Flach, P . Background Check: A general technique to build more reliable\n",
      "3614–3631. [CrossRef]\n",
      "23. Perello-Nieto, M.; Telmo De Menezes Filho, E.S.; Kull, M.; Flach, P . Background Check: A general technique to build more reliable\n",
      "and versatile classiﬁers. In Proceedings of the 2016 IEEE 16th International Conference on Data Mining (ICDM), Barcelona, Spain,\n",
      "12–15 December 2016; pp. 1143–1148.\n",
      "and versatile classiﬁers. In Proceedings of the 2016 IEEE 16th International Conference on Data Mining (ICDM), Barcelona, Spain,\n",
      "12–15 December 2016; pp. 1143–1148.\n",
      "24. Pires, C.; Barandas, M.; Fernandes, L.; Folgado, D.; Gamboa, H. Towards Knowledge Uncertainty Estimation for Open Set\n",
      "Recognition. Mach. Learn. Knowl. Extr. 2020 ,2, 505–532. [CrossRef]\n",
      "24. Pires, C.; Barandas, M.; Fernandes, L.; Folgado, D.; Gamboa, H. Towards Knowledge Uncertainty Estimation for Open Set\n",
      "Recognition. Mach. Learn. Knowl. Extr. 2020 ,2, 505–532. [CrossRef]\n",
      "25. Chow, C. On optimum recognition error and reject tradeoff. IEEE Trans. Inf. Theory 1970 ,16, 41–46. [CrossRef]\n",
      "Recognition. Mach. Learn. Knowl. Extr. 2020 ,2, 505–532. [CrossRef]\n",
      "25. Chow, C. On optimum recognition error and reject tradeoff. IEEE Trans. Inf. Theory 1970 ,16, 41–46. [CrossRef]\n",
      "26. Tax, D.M.; Duin, R.P . Growing a multi-class classiﬁer with a reject option. Pattern Recognit. Lett. 2008 ,29, 1565–1570. [CrossRef]\n",
      "26. Tax, D.M.; Duin, R.P . Growing a multi-class classiﬁer with a reject option. Pattern Recognit. Lett. 2008 ,29, 1565–1570. [CrossRef]\n",
      "27. Fumera, G.; Roli, F.; Giacinto, G. Reject option with multiple thresholds. Pattern Recognit. 2000 ,33, 2099–2101. [CrossRef]\n",
      "27. Fumera, G.; Roli, F.; Giacinto, G. Reject option with multiple thresholds. Pattern Recognit. 2000 ,33, 2099–2101. [CrossRef]\n",
      "28. Hanczar, B. Performance visualization spaces for classiﬁcation with rejection option. Pattern Recognit. 2019 ,96, 106984. [CrossRef]\n",
      "29. Franc, V .; Prusa, D.; Voracek, V . Optimal strategies for reject option classiﬁers. arXiv 2021 , arXiv:2101.12523.\n",
      "29. Franc, V .; Prusa, D.; Voracek, V . Optimal strategies for reject option classiﬁers. arXiv 2021 , arXiv:2101.12523.\n",
      "30. Charoenphakdee, N.; Cui, Z.; Zhang, Y.; Sugiyama, M. Classiﬁcation with rejection based on cost-sensitive classiﬁcation.\n",
      "In Proceedings of the International Conference on Machine Learning, Virtual, 13–15 April 2021; pp. 1507–1517.\n",
      "In Proceedings of the International Conference on Machine Learning, Virtual, 13–15 April 2021; pp. 1507–1517.\n",
      "31. Gal, Y. Uncertainty in Deep Learning. Ph.D. Dissertation, University of Cambridge, Cambridge, UK, 2016.\n",
      "32. Nadeem, M.S.A.; Zucker, J.D.; Hanczar, B. Accuracy-rejection curves (ARCs) for comparing classiﬁcation methods with a\n",
      "32. Nadeem, M.S.A.; Zucker, J.D.; Hanczar, B. Accuracy-rejection curves (ARCs) for comparing classiﬁcation methods with a\n",
      "reject option. In Proceedings of the third International Workshop on Machine Learning in Systems Biology, Ljubljana, Slovenia,\n",
      "5–6 September 2009; pp. 65–81.\n",
      "reject option. In Proceedings of the third International Workshop on Machine Learning in Systems Biology, Ljubljana, Slovenia,\n",
      "5–6 September 2009; pp. 65–81.\n",
      "33. Condessa, F.; Bioucas-Dias, J.; Kovaˇ cevi´ c, J. Performance measures for classiﬁcation systems with rejection. Pattern Recognit. 2017 ,\n",
      "63, 437–450. [CrossRef]\n",
      "5–6 September 2009; pp. 65–81.\n",
      "33. Condessa, F.; Bioucas-Dias, J.; Kovaˇ cevi´ c, J. Performance measures for classiﬁcation systems with rejection. Pattern Recognit. 2017 ,\n",
      "63, 437–450. [CrossRef]\n",
      "34. Kläs, M. Towards identifying and managing sources of uncertainty in AI and machine learning models-an overview. arXiv 2018 ,\n",
      "arXiv:1811.11669.\n",
      "63, 437–450. [CrossRef]\n",
      "34. Kläs, M. Towards identifying and managing sources of uncertainty in AI and machine learning models-an overview. arXiv 2018 ,\n",
      "arXiv:1811.11669.\n",
      "35. Campagner, A.; Cabitza, F.; Ciucci, D. Three-way decision for handling uncertainty in machine learning: A narrative review.\n",
      "arXiv:1811.11669.\n",
      "35. Campagner, A.; Cabitza, F.; Ciucci, D. Three-way decision for handling uncertainty in machine learning: A narrative review.\n",
      "InInternational Joint Conference on Rough Sets ; Springer: Berlin/Heidelberg, Germany, 2020; pp. 137–152.\n",
      "36. Sambyal, A.S.; Krishnan, N.C.; Bathula, D.R. Towards Reducing Aleatoric Uncertainty for Medical Imaging Tasks. arXiv 2021 ,\n",
      "arXiv:2110.11012.\n",
      "36. Sambyal, A.S.; Krishnan, N.C.; Bathula, D.R. Towards Reducing Aleatoric Uncertainty for Medical Imaging Tasks. arXiv 2021 ,\n",
      "arXiv:2110.11012.\n",
      "37. Fischer, L.; Hammer, B.; Wersing, H. Optimal local rejection for classiﬁers. Neurocomputing 2016 ,214, 445–457. [CrossRef]\n",
      "arXiv:2110.11012.\n",
      "37. Fischer, L.; Hammer, B.; Wersing, H. Optimal local rejection for classiﬁers. Neurocomputing 2016 ,214, 445–457. [CrossRef]\n",
      "38. Dua, D.; Graff, C. UCI Machine Learning Repository ; University of California, School of Information and Computer Science: Irvine,\n",
      "CA, USA, 2019. Available online: http://archive.ics.uci.edu/ml (accessed on 20 December 2021).\n",
      "CA, USA, 2019. Available online: http://archive.ics.uci.edu/ml (accessed on 20 December 2021).\n",
      "39. Anguita, D.; Ghio, A.; Oneto, L.; Parra, X.; Reyes-Ortiz, J.L. A public domain dataset for human activity recognition using\n",
      "smartphones. Esann 2013 ,3, 3.\n",
      "40. Buckley, C.; Alcock, L.; McArdle, R.; Rehman, R.Z.U.; Del Din, S.; Mazzà, C.; Yarnall, A.J.; Rochester, L. The role of movement\n",
      "smartphones. Esann 2013 ,3, 3.\n",
      "40. Buckley, C.; Alcock, L.; McArdle, R.; Rehman, R.Z.U.; Del Din, S.; Mazzà, C.; Yarnall, A.J.; Rochester, L. The role of movement\n",
      "analysis in diagnosing and monitoring neurodegenerative conditions: Insights from gait and postural control. Brain Sci. 2019 ,\n",
      "9, 34. [CrossRef] [PubMed]\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 400,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)\n",
    "for text_chunk in range(len(texts)):\n",
    "    print(texts[text_chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex_summary(text,numsent):\n",
    "    doc=nlp(text)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    vector= TfidfVectorizer()\n",
    "    top=vector.fit_transform(sentences)\n",
    "    sentence_scores = np.sum(top.toarray(), axis=1)\n",
    "    print(sentence_scores)\n",
    "    summary = [sentences[i] for i in sentence_scores.argsort()[-numsent:][::-1]]\n",
    "    return ' ' .join(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=\"\"\"Artificial intelligence (AI) is a rapidly evolving field that aims to create systems capable of performing tasks that typically require human intelligence. These tasks include learning, reasoning, problem-solving, perception, and language understanding. AI technologies are driven by advances in machine learning, deep learning, and neural networks, enabling computers to learn from data and improve over time. AI applications span various sectors, including healthcare, finance, transportation, and entertainment.\n",
    "\n",
    "In healthcare, AI assists in diagnosing diseases, personalizing treatment plans, and predicting patient outcomes. Financial institutions leverage AI for fraud detection, risk assessment, and algorithmic trading. Autonomous vehicles rely on AI to navigate and make real-time decisions. In the realm of entertainment, AI powers recommendation engines for platforms like Netflix and Spotify.\n",
    "\n",
    "Despite its potential, AI also raises ethical concerns. Issues such as data privacy, algorithmic bias, and job displacement need to be addressed to ensure responsible AI development and deployment. Researchers and policymakers are working on frameworks to balance innovation with ethical considerations.\n",
    "\n",
    "AI continues to transform industries and improve daily life, making it a crucial area of study and development. As AI systems become more sophisticated, they hold the promise of solving complex problems and creating new opportunities, fundamentally changing how we interact with technology and the world around us.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.37587202 2.         1.        ]\n",
      "[3.86744535 1.97099145 4.87787798 1.96891082]\n",
      "[4.33966858 4.45098551 1.         1.97948731 1.99337319 2.33333333]\n",
      "[3.45969238 1.         1.99029143 2.         4.69717179 1.40734857]\n",
      "[3.94418506 4.88216518]\n",
      "[3.7237493  3.65847957]\n",
      "[4.89897949]\n",
      "[5.66996389 3.5911305  1.        ]\n",
      "[3.43387572 4.32698421 4.04147202]\n",
      "[3.5124581  5.00710209 3.80855593]\n",
      "[3.54317925 4.4223345  3.40970754 2.40307647 1.40619668]\n",
      "[2.23606798 3.44780345 2.4379652  4.68850912 2.22887766]\n",
      "[4.43305306 3.42373543 3.5602457 ]\n",
      "[3.58435139 4.45808457]\n",
      "[0.         4.59733174 4.31783023 2.44134811]\n",
      "[4.28618575 3.35821314 2.98287383 3.13041704]\n",
      "[2.61463224 2.97390196 4.54190491 3.96153893]\n",
      "[3.24582056 4.29993062 4.9532357 ]\n",
      "[1.72216301 4.97478862 4.28678034 1.70362687]\n",
      "[1.38095532 4.28611099 3.73870295 3.4327805 ]\n",
      "[3.37765892 3.58782502 3.81537526 2.40470597]\n",
      "[1.         3.77649191 4.20932471 3.70836287]\n",
      "[3.42059198 4.48065173 1.69360614]\n",
      "[4.51739547 2.62116157 3.855384  ]\n",
      "[1.98421271 5.94843344 3.30844189]\n",
      "[2.88675135 5.48482756]\n",
      "[4.8099603  4.35959457 1.71663079]\n",
      "[4.34451383 3.13718203 4.00683905 1.70362687]\n",
      "[2.63216456 3.96962638 4.05152032 2.61457861]\n",
      "[1.70362687 3.39766926 4.584301   3.42511546]\n",
      "[1.97613206 1.         3.8364072  4.32654393 3.51109466]\n",
      "[3.41025357 3.80857715 4.52077101 2.41988511]\n",
      "[1.40619668 4.53204609 2.42517291 3.69065521 3.27232065]\n",
      "[1.41421356 3.69593217 3.27694836 2.40470647 3.34674116 1.40919853]\n",
      "[2.42466932 3.25897481 3.41077994 3.83847048]\n",
      "[3.29150453 3.98624005 4.36800747 1.        ]\n",
      "[1.         5.08385023 3.9189769  1.        ]\n",
      "[2.94162039 3.96186258 4.48682627 2.78419445]\n",
      "[4.44431189 3.95313174 3.70770531]\n",
      "[2.81467327 5.4201483 ]\n",
      "[4.23951206 4.88637337 3.30016361 1.72216301]\n",
      "[3.56726283 3.28625222 3.31174505 3.12150716 1.41421356 1.        ]\n",
      "[3.01207616 3.13531633 3.72892705 3.29661335 1.40619668]\n",
      "[3.30474322 3.28025172 3.96153893 3.42223434]\n",
      "[3.71667979 5.24931027 2.62808949]\n",
      "[4.07439554 2.97006366 4.12442861 1.70362687]\n",
      "[1.41421356 4.23651335 2.44134811 4.79129006]\n",
      "[1.73205081 4.97929441 5.07191917]\n",
      "[4.44359513 3.59964375 2.97006366 2.20536841]\n",
      "[1.73205081 2.96518183 3.11646939 3.43714904 3.89725909]\n",
      "[2.62249554 3.8256744  3.81766354 2.79644911]\n",
      "[3.90797394 4.4083675  3.52203128]\n",
      "[3.55622874 4.5264312  4.04460914]\n",
      "[2.78612023 4.16557374 3.909748  ]\n",
      "[1.         3.90724511 3.44432601 3.58981896]\n",
      "[3.44074622 4.87430701 0.         3.43097926]\n",
      "[3.30016361 0.         4.16879669 3.95660847]\n",
      "[3.         4.41631538 2.85046107]\n",
      "[2.87556532 3.67555691 3.57868372 2.44134811]\n",
      "[2.23606798 3.58312481 3.82853266 2.80883714]\n",
      "[3.41752888 4.64044361]\n",
      "[4.70188098 3.42788383]\n",
      "[3.58015618 3.72438721 3.7094497 ]\n",
      "[1.87028597 4.67296179 3.16130914]\n",
      "[3.30126754 3.23158353 3.93678331]\n",
      "[1.71663079 3.76643719 4.74964111]\n",
      "[1.         4.84173178 4.24730733]\n",
      "[1.         4.78920075]\n",
      "[3.74616759 4.59094307]\n",
      "[4.78665546 3.29053061 3.1463938 ]\n",
      "[2.1981903  3.28076395 3.73264642 4.64796729 1.73205081]\n",
      "[1.990707   4.64693231 4.31631175 3.42223434]\n",
      "[3.95827781 3.42511546 2.22186728 3.8512789 ]\n",
      "[2.23606798 4.17085413 3.06507393]\n",
      "[3.79520687 4.0103167  3.39328958 1.67872567]\n",
      "[2.95779538 3.41471393 4.07494402 3.08176822]\n",
      "[3.8311049  4.24157197 3.29463144]\n",
      "[3.19155584 5.32327106 0.        ]\n",
      "[4.17643104 2.63463781 3.28321738]\n",
      "[2.5584086  3.94464668 3.57525675]\n",
      "[2.19563554 3.53601166 4.64505932]\n",
      "[4.65017758 4.23788286]\n",
      "[4.80897026 4.19985927]\n",
      "[4.21111396 3.27607347 3.28100904]\n",
      "[3.26112872 3.91420318 3.38488873 3.39997739]\n",
      "[2.80378446 5.77324548]\n",
      "[6.17341973]\n",
      "[4.55600205 3.97588813 4.64994332]\n",
      "[1.73205081 4.58530244 4.22853896 2.63807373]\n",
      "[4.22415098 5.62830276]\n",
      "[5.24272522 4.53162738]\n",
      "[4.45977299 3.2924405  1.         3.10617343]\n",
      "[1.97470398 3.29323298 1.         4.07098497 3.83852602]\n",
      "[3.00837113 4.09323949 4.21795388]\n",
      "[4.31943145 0.         5.2831333 ]\n",
      "[5.27444405 3.94993636 2.76999908]\n",
      "[1.38095532 3.95530297 4.92722145 2.19283679]\n",
      "[4.73323625 4.12678748 1.73205081 2.61737034]\n",
      "[3.93248062 1.73205081 4.21735056 3.44131859 2.21094217]\n",
      "[3.28529436 3.42059198 5.0291137 ]\n",
      "[4.71210347 5.154002  ]\n",
      "[5.40169365 3.69556662]\n",
      "[2.82884836 4.85984226 3.27287299]\n",
      "[3.2071349  3.65801671 3.85087355 2.22738675]\n",
      "[2.19563554 3.83508012 4.90320251]\n",
      "[4.33212936 4.14229116 1.         1.40441857]\n",
      "[4.26707966 1.         2.22887766 3.53865799 2.80128845]\n",
      "[1.73205081 3.49745092 2.95490658 4.13728399]\n",
      "[2.17353359 4.70415686 4.07530933]\n",
      "[2.96986032 4.14162588 5.15978748]\n",
      "[4.63577691 4.44483085]\n",
      "[3.90186987 3.33035357]\n",
      "[4.42653396]\n",
      "[2.72631595 5.3216241 ]\n",
      "[4.90708065 5.09650402]\n",
      "[5.36436381 1.         3.00770869 3.55166156]\n",
      "[2.23606798 1.         3.0027947  4.22527018 2.68865024 0.\n",
      " 1.        ]\n",
      "[2.23606798 2.74121155 0.         3.59901355 4.24475586]\n",
      "[1.41421356 4.43455037 3.71246895]\n",
      "[1.98175026 5.11654182 2.21748122]\n",
      "[4.76800588 3.61633866]\n",
      "[3.29715328 3.67415495 3.45996465]\n",
      "[3.72152473 3.43688353 2.5847942  4.26307123]\n",
      "[1.         2.6283828  5.87027871 2.6283828 ]\n",
      "[4.44798285 4.02470629 3.42373543]\n",
      "[3.22858548 5.66524401]\n",
      "[5.10082389 3.70228255 2.19563554]\n",
      "[1.         3.64772008 4.71249416 1.        ]\n",
      "[4.41249722 4.74021395 1.        ]\n",
      "[4.6073244  4.52105864]\n",
      "[5.42147074 3.95183209]\n",
      "[2.77483773 4.98551515 3.42725848]\n",
      "[3.42821673 3.84745705 4.37255238]\n",
      "[1.73205081 4.54832751 1.         3.54196289]\n",
      "[2.94420933 4.5436148  3.61622834]\n",
      "[2.81137746 4.60592227 1.        ]\n",
      "[4.21945143 3.86851316]\n",
      "[4.25169877 3.57632823 3.99902138]\n",
      "[4.79206244 4.31647828]\n",
      "[1.98794406 4.4235789  3.87940058]\n",
      "[4.68842934 3.39467941]\n",
      "[3.12267427 4.3955713 ]\n",
      "[4.86811723 3.67710777 1.73205081]\n",
      "[2.4442424  3.66191181 4.97047286]\n",
      "[5.35157886 2.62034549]\n",
      "[5.44444444]\n",
      "[3.70152064 3.69909298 3.64300759 2.99306834]\n",
      "[1.         3.66328049 4.54462133 3.27304226]\n",
      "[3.40664425 3.25865051 4.11613548]\n",
      "[4.4115432  3.19797658 2.94876053]\n",
      "[4.65433268 3.12294292]\n",
      "[3.086067   3.29150453 4.0106202  2.2061094 ]\n",
      "[1.         3.93039584 4.02168038 2.66344801]\n",
      "[3.73216364 3.53652375 3.41295511]\n",
      "[3.42189541 4.37524949 3.06818058]\n",
      "[2.96311164 2.98508165 4.53983267]\n",
      "[4.68741651 3.99919348]\n",
      "[2.2248364  4.17211555 4.0949902 ]\n",
      "[1.40441857 5.30468862 4.08098282 2.61457861]\n",
      "[1.         4.07536636 4.77917884 3.26350761]\n",
      "[2.22738675 4.14135505 4.22537738 1.        ]\n",
      "[4.23573754 3.84338642 4.08664398 2.22336179 1.        ]\n",
      "[1.41421356 4.10526213 2.22336179 1.         4.57245115]\n",
      "[4.22753882 4.51026478]\n",
      "[5.09901951]\n",
      "[2.82403927 4.71517426 2.        ]\n",
      "[5.27652276 3.79613748]\n",
      "[3.1242424  4.24990823 3.25643263]\n",
      "[2.43897483 4.79817502 3.1537462 ]\n",
      "[3.99565472 5.08682255 2.61457861 2.2093569 ]\n",
      "[3.97143922 2.61737034 3.84212829 2.98730052]\n",
      "[3.4365019  2.97006366 4.03361385 3.59964375]\n",
      "[2.82884836 3.83508012 3.37968773]\n",
      "[1.40316247 3.93997482 3.70331055]\n",
      "[2.76999908 4.47885929 3.86226819]\n",
      "[2.81137746 3.95299513 4.39550711]\n",
      "[4.27444642 3.73673948 0.         3.42511546]\n",
      "[2.82238324 0.         4.89628143 2.62238294 3.44893946]\n",
      "[1.73205081 2.64024048 3.84512234 2.97008098 2.41811093 3.63803438]\n",
      "[1.         2.44134811 4.50794403 3.97720319]\n",
      "[2.94420933 4.5054121  3.81459066]\n",
      "[1.98614779 4.0016908  0.         3.98720771]\n",
      "[0.         4.73407026 3.45079408 3.25384401 1.40619668]\n",
      "[2.78612023 3.23255771 4.38781993]\n",
      "[4.76043009 3.93045035]\n",
      "[2.44134811 3.90797284 3.92985901 2.81528484]\n",
      "[3.86614778 4.23078396 2.42713847]\n",
      "[3.53052292 4.71446174 2.57650237]\n",
      "[4.11735103 4.22903905 2.94475489]\n",
      "[3.70447719 3.76137073]\n",
      "[3.87926265 3.32780808 3.30844189]\n",
      "[1.41421356 3.34440806 4.22129626 3.59661128]\n",
      "[2.63807373 3.60341018 3.89679705 3.67358793]\n",
      "[2.60871143 4.51216669 3.44302357]\n",
      "[3.96774864 3.82190694 4.42727234]\n",
      "[1.98614779 4.39088445 3.60658124 3.69322939]\n",
      "[1.70362687 4.66924703 3.82996788 3.71548314]\n",
      "[3.57829767 4.59762278 3.6427353 ]\n",
      "[3.298831   4.17270165 3.89887704]\n",
      "[2.63099353 4.21345571 3.59303293]\n",
      "[3.26464733 5.64588344]\n",
      "[5.04673973 5.14496351]\n",
      "[4.30175479 1.         3.71548314 4.06515152]\n",
      "[2.         3.88574598 3.70770362 1.95398642]\n",
      "[3.72496282 4.33968735 2.81528484 2.2093569 ]\n",
      "[3.15315042 2.80684599 2.78434142 2.63992868 2.94875851 3.40513316]\n",
      "[1.73205081 2.98354996 4.69091456]\n",
      "[3.93982078 4.46590935 2.        ]\n",
      "[1.         4.44373456 3.71935621 3.3582118 ]\n",
      "[3.15564931 3.98499129 4.78300593 1.72216301]\n",
      "[2.99107318 3.97420806 3.58860135]\n",
      "[2.60288209 4.41782476 3.95196451 1.41421356]\n",
      "[2.60119875 3.96596828 3.69751134 3.23627785]\n",
      "[3.65757996 4.10930297 4.04996094]\n",
      "[3.24545985 4.26329017 4.20386707]\n",
      "[2.61457861 4.1063377  3.93090296 1.        ]\n",
      "[1.70362687 3.96609625 4.71940268 2.22186728]\n",
      "[3.44923129 4.15447622 3.80780699]\n",
      "[2.97767527 4.35921082 3.96146638]\n",
      "[2.81137746 5.3440198  3.30126754]\n",
      "[3.56764707 3.41871146 3.93119282 2.2061094 ]\n",
      "[1.98175026 3.9369247  4.19270994]\n",
      "[4.78258621 3.27746649]\n",
      "[3.62681332 4.71795564 2.96085187]\n",
      "[3.42301272 5.17164266 1.        ]\n",
      "[4.39477755 3.39197495]\n",
      "[3.48077262 3.95660847 2.05105169 0.        ]\n",
      "[2.23606798 2.09713178 4.54945354]\n",
      "[4.32241028 4.32856373 1.        ]\n",
      "[4.30055944 1.         3.97422717]\n",
      "[4.07102854 3.71530899 3.69902423]\n",
      "[1.41421356 4.9763193  3.19155584]\n",
      "[2.67371286 4.25758512 3.14040313]\n",
      "[3.28205129 4.69806871 3.31662479]\n",
      "[3.71667979 4.61064046 3.44322012]\n",
      "[3.7094497  5.29647038 1.41421356]\n",
      "[4.28458343 3.90382398 1.         2.94751269]\n",
      "[3.60168203 1.         3.43721203 3.81170174 2.099325  ]\n",
      "[1.98614779 3.82841382 4.13388657 1.73205081]\n",
      "[4.1576092  4.41486957 2.2248364 ]\n",
      "[4.10058489 3.81812639 3.81812639]\n",
      "[3.10509756 5.01225583 3.26056669]\n",
      "[3.8243518  3.5851632  3.98673526]\n",
      "[1.41421356 4.19860409 4.06071268 3.25954062]\n",
      "[3.27617767 3.13410984 3.67776516 2.92677061]\n",
      "[3.68655846 3.55523174 4.16381914]\n",
      "[2.41829447 4.5023912  3.17003166 1.40441857]\n",
      "[2.96085187 3.17049919 4.74014301]\n",
      "[3.3532334  3.74803961]\n",
      "[2.22738675 3.791198   3.14546402 3.61573039]\n",
      "[3.13312352 3.97529772 2.93219113 3.56764707]\n",
      "[1.41421356 2.92418586 4.52669804 1.72216301]\n",
      "[1.         1.72296836 1.40644868 2.21961154]\n",
      "[2.22844503 1.71893928 1.93790203]\n",
      "[2.11057941 2.41130472 3.0340365 ]\n",
      "[1.73205081 2.40370125 4.40248175 3.45258761]\n",
      "[3.70362608 4.61339352 2.96641999]\n",
      "[3.43044284 4.31319989 3.26531533]\n",
      "[3.11797389 3.69464444 3.95080087 3.26350761]\n",
      "[2.62808949 4.1867449  3.49676977]\n",
      "[3.47481976 4.4447403  3.08996341]\n",
      "[3.39662563 4.58951612 2.93645877]\n",
      "[3.54561558 4.58359587]\n",
      "[4.19973976 4.49750032]\n",
      "[2.19133211 4.78893784 4.20641822]\n",
      "[2.41071121 4.15150958 4.56863679]\n",
      "[4.74552816 3.85189063]\n",
      "[1.972179  3.9669484]\n",
      "[2.6        1.40441857 3.69581103 2.82114898]\n",
      "[2.40581372 3.13351654 2.60453995 2.60453995 2.23606798 3.60555128]\n",
      "[2.23606798 2.22336179 4.31515225 3.14435138 2.52982213]\n",
      "[2.61737034 3.15564931 3.99019837 2.97917839]\n",
      "[3.57063853 4.810521  ]\n",
      "[4.72503706 4.16608621]\n",
      "[1.96210658 4.24502374 4.12297347]\n",
      "[1.         4.14210724 4.01288416]\n",
      "[1.98794406 4.23276941 4.23609951]\n",
      "[2.7136021  4.99256409 3.29431884 1.72216301]\n",
      "[3.3715656  3.29431884 3.79207004 2.77655765]\n",
      "[3.61636715 4.42529189 2.97311406]\n",
      "[3.96605958 3.82982758 1.         4.20638766 1.72390172]\n",
      "[1.         4.24264069 5.28571429]\n",
      "[5.77595898]\n",
      "[4.77777778]\n",
      "[3.39431042 4.25047603]\n",
      "[2.43897483 4.26857897 4.33976206]\n",
      "[4.51946965 4.25182661]\n",
      "[1.41421356 4.63284147 3.30030916]\n",
      "[2.67371286 4.22802865 3.28321738]\n",
      "[2.79302678 4.1299     3.70770531]\n",
      "[2.89718728 3.81862696 3.20400325 2.63807373]\n",
      "[1.70811465 3.1374818  4.39512658 3.10986213]\n",
      "[4.04102082 3.78960154 4.35427167]\n",
      "[4.21286615 1.97099145 2.80123104 2.43550628]\n",
      "[2.44273845 1.97613206 2.8032713  4.95972868 2.22439557]\n",
      "[4.29399153 3.96839328 2.8992682  2.63216456]\n",
      "[3.28025172 2.87604472 4.35202026 1.72216301]\n",
      "[1.71277082 2.76369005]\n",
      "[2.65964146 2.18318122]\n",
      "[2.52982213 2.43550628 4.517065   1.        ]\n",
      "[4.64037222 3.72959516 3.23255771]\n",
      "[3.57012396 3.64899531 3.9065874 ]\n",
      "[2.570349   4.44763222 3.81862696 1.        ]\n",
      "[2.20536841 3.75207808 4.23323185 2.        ]\n",
      "[4.14500183 5.36492805]\n",
      "[5.81556256 1.        ]\n",
      "[4.1174614  3.         2.88675135 0.         1.        ]\n",
      "[2.82114898 2.88675135 0.         4.69961608]\n",
      "[0.         4.77084221 4.43844177]\n",
      "[1.         4.4130705  4.52834384]\n",
      "[1.40441857 5.34996216 3.27304226 2.18957051]\n",
      "[2.81024528 3.30302677 2.4379652  3.47789129 3.29661335]\n",
      "[2.19563554 4.62054222 4.0396255 ]\n",
      "[1.         4.44659707 3.8714645 ]\n",
      "[2.37218096 3.83834115 3.93704338]\n",
      "[2.61457861 4.07861355 4.0620797  3.0532665 ]\n",
      "[1.         4.03367422 3.90791272 4.09352946 1.        ]\n",
      "[2.44134811 3.99326906 3.27271872 3.42223434]\n",
      "[3.14040313 4.3201834  2.80860967]\n",
      "[3.10908099 3.01619816 4.64743789]\n",
      "[1.         4.73323625 4.08742811 1.72216301]\n",
      "[1.         4.09936441 3.94248669 3.16867174]\n",
      "[3.44262478 4.39789826 3.42059198]\n",
      "[3.40651844 4.81847366 3.42037392]\n",
      "[3.82638362 4.78709552]\n",
      "[4.55073877 4.9577547 ]\n",
      "[3.85080625 3.1242424  4.97879037]\n",
      "[5.30497657 4.61238386]\n",
      "[2.21748122 4.58214652 2.82842712]\n",
      "[3.31294578]\n",
      "[3.98862018]\n",
      "[1.97099145 3.40178794 1.         4.66950882]\n",
      "[1.         6.06339063]\n",
      "[5.04825202 2.66789188]\n",
      "[2.44948974 2.68769764 3.30016361 4.24749029]\n",
      "[3.30016361 5.37376325 1.72048941 2.81108079]\n",
      "[3.31662479 1.72266251 2.63453323 1.         3.60555128]\n",
      "[1.72405607 2.6360848  1.         3.73753908 3.45969238 1.41421356]\n",
      "[1.         3.46054258 1.41421356 0.         3.31662479 2.82090596\n",
      " 2.44948974 1.        ]\n",
      "[2.80806919 2.44948974 1.         1.73205081 1.73205081 2.43004683\n",
      " 2.         1.40922262 3.50601185]\n",
      "[1.39423091 1.40815731 3.60768079 1.         2.21924741 3.14873546\n",
      " 1.84674203]\n",
      "[1.         1.         2.23230134 3.15695082 1.87188353 0.\n",
      " 3.60294603 1.41421356 2.         1.         1.41421356 1.41015158]\n",
      "[1.41421356 2.         1.         1.40875787 3.62349377 2.\n",
      " 3.59909721 1.40875787]\n",
      "[1.73205081 3.60063772 2.         1.40619668 3.16227766]\n",
      "[1.41421356 1.41421356 4.26401433 1.88982237]\n",
      "[3.14840278 1.92837145 1.         4.07118537 1.92837145]\n",
      "[2.         1.86878145 1.         1.73205081 3.         2.82842712\n",
      " 1.         1.72644021]\n",
      "[1.73205081 2.82152233 1.         2.         1.41421356 3.13082996\n",
      " 1.         2.44948974 1.        ]\n",
      "[1.         1.41421356 3.15296313 1.         2.44479257 1.40875787\n",
      " 2.88675135 1.88982237]\n",
      "[2.4461212  1.41421356 2.88675135 1.88982237 1.         1.\n",
      " 1.         3.60555128 1.41421356 1.         1.         2.23606798\n",
      " 1.41036721]\n",
      "[1.         1.41421356 1.         1.         2.23207621 1.73205081\n",
      " 3.15919138 1.93519792 1.         2.99417742 3.02102408]\n",
      "[1.         2.98730052 3.13675273 3.72627955]\n",
      "[1.         4.1946924  3.98529044 1.41421356]\n",
      "[2.22604233 3.9961225  1.41421356 1.         2.99501534 1.88982237]\n",
      "[2.23606798 1.41421356 1.         2.9965629  1.88982237 1.\n",
      " 3.87022357 1.         2.         1.        ]\n",
      "[1.         3.87298335 1.         2.         4.47213595 2.12132034]\n",
      "[2.23606798 2.12132034 1.         3.31662479 2.23039689 1.41036721\n",
      " 3.16227766 1.41036721 1.41421356 1.         1.         1.99620122\n",
      " 1.        ]\n",
      "[1.4095938  3.16227766 1.41421356 1.41421356 1.         1.\n",
      " 2.         1.4095938  2.82842712 2.82842712]\n",
      "[1.41421356 1.41421356 2.82842712 3.31662479 4.26401433 1.41421356]\n",
      "[1.73205081 4.26401433 1.41421356 1.         3.60555128 1.\n",
      " 1.         1.         2.         1.        ]\n",
      "[1.         3.60294603 1.         1.         1.         2.\n",
      " 1.41015158 2.82523733 1.41421356 1.         2.23606798 1.        ]\n",
      "[1.         1.         1.         1.         2.         1.4038763\n",
      " 2.82388964 1.41421356 1.         2.23606798 1.4038763  1.41421356\n",
      " 2.64305326 1.41421356 1.         2.         1.        ]\n",
      "[1.         1.41421356 2.6380144  1.41421356 1.         2.\n",
      " 1.4098977  2.82063916 1.41421356 2.         1.        ]\n",
      "[1.         2.81479834 1.41421356 1.99575486 3.30259122 1.41421356\n",
      " 1.73205081 1.4098977  1.73205081 2.43593964 1.87128754]\n",
      "[1.         1.73205081 2.44948974 1.86878145 1.         3.19803548\n",
      " 3.86686905 1.41421356]\n",
      "[3.86343306 1.41421356 1.         2.2272031  2.51551026 1.\n",
      " 3.46410162]\n",
      "[1.         3.74165739 4.02492236 1.41421356]\n",
      "[1.41421356 4.01872947 1.41421356 1.         3.46054258 1.41421356\n",
      " 2.         1.        ]\n",
      "[1.73205081 1.41421356 1.         3.46410162 1.41421356 2.\n",
      " 4.02492236 1.88982237]\n",
      "[1.73205081 3.9940621  1.88982237 1.         3.72579263]\n",
      "[1.72644021 1.         3.7353792  3.46410162 1.41421356 1.\n",
      " 3.30977978 1.94008005]\n",
      "[1.         3.31255042 1.88982237 1.         2.82377698 2.23606798\n",
      " 1.        ]\n",
      "[1.73205081 1.         2.82842712 2.23606798 1.41421356 4.13982616\n",
      " 3.60176303]\n",
      "[1.73205081 3.60555128 1.         2.44948974 3.         1.73205081\n",
      " 3.         2.        ]\n",
      "[1.         1.73205081 3.         3.90006748 2.         1.41421356]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045 /gid00001\\n/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046Citation: Barandas, M.; Folgado, D.;\\nSantos, R.; Simão, R.; Gamboa, H.\\nUncertainty-Based Rejection in Machine\\nLearning: Implications for Model\\nDevelopment and Interpretability.\\n Electronics 2022 ,11, 396. https://',\n",
       " 'https://\\ndoi.org/10.3390/electronics11030396\\nAcademic Editors: Christian\\nMorbidoni, Francesco Di Nardo and\\nAlessandro Cucchiarelli\\nReceived: 20 December 2021\\nAccepted: 26 January 2022\\n Santos, R.; Simão, R.; Gamboa, H.\\nUncertainty-Based Rejection in Machine\\nLearning: Implications for Model\\nDevelopment and Interpretability.\\n Electronics 2022 ,11, 396. Published: 28 January 2022',\n",
       " '28 January 2022\\nPublisher’s Note: MDPI stays neutral\\nwith regard to jurisdictional claims in\\npublished maps and institutional afﬁl-\\niations.\\n Academic Editors: Christian\\nMorbidoni, Francesco Di Nardo and\\nAlessandro Cucchiarelli\\nReceived: 20 December 2021\\nAccepted: 26 January 2022\\nPublished: This article is an open access article Licensee MDPI, Basel, Switzerland.\\n © 2022 by the authors.\\n',\n",
       " 'This article is an open access article\\ndistributed under the terms and\\nconditions of the Creative Commons\\nAttribution (CC BY) license (https://\\ncreativecommons.org/licenses/by/\\n4.0/).\\n with regard to jurisdictional claims in\\npublished maps and institutional afﬁl-\\niations.\\n Licensee MDPI, Basel, Switzerland.\\n © 2022 by the authors.\\n electronics\\nArticle',\n",
       " 'electronics\\nArticle\\nUncertainty-Based Rejection in Machine Learning: Implications\\nfor Model Development and Interpretability\\nMarília Barandas1,2,*\\n, Duarte Folgado1,2\\n, Ricardo Santos1,2\\n, Raquel Simão2\\nand Hugo Gamboa1,2 distributed under the terms and\\nconditions of the Creative Commons\\nAttribution (CC BY) license (https://\\ncreativecommons.org/licenses/by/\\n4.0/).\\n',\n",
       " 'for Model Development and Interpretability\\nMarília Barandas1,2,*\\n, Duarte Folgado1,2\\n, Ricardo Santos1,2\\n, Raquel Simão2\\nand Hugo Gamboa1,2\\n 1Associação Fraunhofer Portugal Research, Rua Alfredo Allen 455/461, 4200-135 Porto, Portugal;\\nduarte.folgado@fraunhofer.pt (D.F.); ricardo.santos@fraunhofer.pt (R.S.); hugo.gamboa@fraunhofer.pt (H.G.)',\n",
       " 'duarte.folgado@fraunhofer.pt (D.F.); ricardo.santos@fraunhofer.pt (R.S.); hugo.gamboa@fraunhofer.pt (H.G.)\\n2Laboratório de Instrumentação, Engenharia Biomédica e Física da Radiação (LIBPhys-UNL),\\nDepartamento de Física, Faculdade de Ciências e Tecnologia, Universidade Nova de Lisboa,\\n2829-516 Caparica, Portugal; rf.simao@campus.fct.unl.pt\\n*Correspondence: marilia.barandas@fraunhofer.pt',\n",
       " 'Departamento de Física, Faculdade de Ciências e Tecnologia, Universidade Nova de Lisboa,\\n2829-516 Caparica, Portugal; rf.simao@campus.fct.unl.pt\\n*Correspondence: marilia.barandas@fraunhofer.pt\\nAbstract: Uncertainty is present in every single prediction of Machine Learning (ML) models. Uncer-\\ntainty Quantiﬁcation (UQ) is arguably relevant, in particular for safety-critical applications. Prior',\n",
       " 'Prior\\nresearch focused on the development of methods to quantify uncertainty; however, less attention has\\nbeen given to how to leverage the knowledge of uncertainty in the process of model development.\\n This work focused on applying UQ into practice, closing the gap of its utility in the ML pipeline tainty Quantiﬁcation (UQ) is arguably relevant, in particular for safety-critical applications.',\n",
       " 'This work focused on applying UQ into practice, closing the gap of its utility in the ML pipeline\\nand giving insights into how UQ is used to improve model development and its interpretability. We\\nidentiﬁed three main research questions: (1) How can UQ contribute to choosing the most suitable been given to how to leverage the knowledge of uncertainty in the process of model development.\\n',\n",
       " 'We\\nidentiﬁed three main research questions: (1) How can UQ contribute to choosing the most suitable\\nmodel for a given classiﬁcation task? and giving insights into how UQ is used to improve model development and its interpretability. (2) Can UQ be used to combine different models in a prin-\\ncipled manner? (3) Can visualization techniques improve UQ’s interpretability? These questions',\n",
       " 'These questions\\nare answered by applying several methods to quantify uncertainty in both a simulated dataset and\\na real-world dataset of Human Activity Recognition (HAR). (2) Can UQ be used to combine different models in a prin-\\ncipled manner? (3) Can visualization techniques improve UQ’s interpretability? model for a given classiﬁcation task? Our results showed that uncertainty',\n",
       " 'are answered by applying several methods to quantify uncertainty in both a simulated dataset and\\na real-world dataset of Human Activity Recognition (HAR). Keywords: artiﬁcial intelligence; uncertainty quantiﬁcation; machine learning; rejection option;\\ninterpretability; human activity recognition Our results showed that uncertainty\\nquantiﬁcation can increase model robustness and interpretability.\\n',\n",
       " 'Introduction\\nMachine Learning (ML) has continuously attracted the interest of the research com-\\nmunity, motivated by the promising results obtained in many decision-critical domains. Keywords: artiﬁcial intelligence; uncertainty quantiﬁcation; machine learning; rejection option;\\ninterpretability; human activity recognition\\n1.',\n",
       " 'Introduction\\nMachine Learning (ML) has continuously attracted the interest of the research com-\\nmunity, motivated by the promising results obtained in many decision-critical domains.\\n However, we argue that approaches that are safe to use in decision-critical domains must\\naccount for the inherent uncertainty in the process [ 1]. ML models learn from data and 1.',\n",
       " 'However, we argue that approaches that are safe to use in decision-critical domains must\\naccount for the inherent uncertainty in the process [ 1]. ML models learn from data and\\nuse the extracted models to make predictions. Thus, the predictions made by ML models have an associated Learning from data is inseparably con-\\nnected with uncertainty [ 2].',\n",
       " 'Thus, the predictions made by ML models have an associated\\nuncertainty, as they are susceptible to noise and suboptimal model inference. It is highly de-\\nsirable to take into account uncertainty as a path towards trustworthy Artiﬁcial Intelligence Learning from data is inseparably con-\\nnected with uncertainty [ 2]. use the extracted models to make predictions.',\n",
       " 'As such, ML models should have the ability to quantify uncertainty in\\ntheir predictions and abstain from providing a decision when a large amount of uncertainty\\nis present [3]. It is highly de-\\nsirable to take into account uncertainty as a path towards trustworthy Artiﬁcial Intelligence\\n(AI)-based systems. uncertainty, as they are susceptible to noise and suboptimal model inference.',\n",
       " 'As such, ML models should have the ability to quantify uncertainty in\\ntheir predictions and abstain from providing a decision when a large amount of uncertainty\\nis present [3].\\n Based on the origin of uncertainty, a distinction between two different sources of uncer-\\ntainty is commonly made: aleatoric and epistemic uncertainty. (AI)-based systems. Aleatoric uncertainty refers',\n",
       " 'Based on the origin of uncertainty, a distinction between two different sources of uncer-\\ntainty is commonly made: aleatoric and epistemic uncertainty. Aleatoric uncertainty refers\\nto the notion of randomness, and it is related to the data-measurement process. Epistemic\\nuncertainty refers to the uncertainty associated with the model and by the lack of knowl- is present [3].\\n',\n",
       " 'In principle, epistemic uncertainty can be reduced by extending the training data,\\nbetter modeling, or better data analysis. Epistemic\\nuncertainty refers to the uncertainty associated with the model and by the lack of knowl-\\nedge. to the notion of randomness, and it is related to the data-measurement process. Although different types of uncertainty should',\n",
       " 'Although different types of uncertainty should\\nbe measured differently, this distinction in ML has only received attention recently [ 4].\\n In principle, epistemic uncertainty can be reduced by extending the training data,\\nbetter modeling, or better data analysis. In particular, in the literature on deep learning, this distinction has been studied due to edge.',\n",
       " 'In particular, in the literature on deep learning, this distinction has been studied due to\\nthe limited awareness of neural networks of their own conﬁdence. be measured differently, this distinction in ML has only received attention recently [ 4].\\n Recently there has',\n",
       " 'In particular, in the literature on deep learning, this distinction has been studied due to\\nthe limited awareness of neural networks of their own conﬁdence. https://doi.org/10.3390/electronics11030396 https://www.mdpi.com/journal/electronicsElectronics 2022 ,11, 396 2 of 20 Recently there has\\nElectronics 2022 ,11, 396.',\n",
       " 'https://doi.org/10.3390/electronics11030396 https://www.mdpi.com/journal/electronicsElectronics 2022 ,11, 396 2 of 20\\nbeen more focus on epistemic uncertainty since deep learning models are known as being\\noverconﬁdent with out-of-distribution examples or even adversarial examples [5].\\n Although Uncertainty Quantiﬁcation (UQ) plays an important role in AI deployment Electronics 2022 ,11, 396.',\n",
       " 'Although Uncertainty Quantiﬁcation (UQ) plays an important role in AI deployment\\nscenarios for cost-sensitive decision-making domains, such as medicine [ 6], it is also an\\nimportant concept within the ML methodology itself, as for instance, in active learning [ 7,8]. overconﬁdent with out-of-distribution examples or even adversarial examples [5].\\n',\n",
       " 'scenarios for cost-sensitive decision-making domains, such as medicine [ 6], it is also an\\nimportant concept within the ML methodology itself, as for instance, in active learning [ 7,8].\\n Recent uncertainty frameworks have been proposed that provide different capabilities to\\nquantify and evaluate uncertainty in the AI development lifecycle [ 9,10]. UQ is important',\n",
       " 'Recent uncertainty frameworks have been proposed that provide different capabilities to\\nquantify and evaluate uncertainty in the AI development lifecycle [ 9,10]. It helps developers debug their models,\\nin understanding their ﬂaws so they can be used for model improvement. UQ is important\\nacross several stakeholders of the ML lifecycle. For the users',\n",
       " 'For the users\\nof AI systems, UQ increases interpretability and trust in model predictions, answering\\nthe question: Can I trust this model? It helps developers debug their models,\\nin understanding their ﬂaws so they can be used for model improvement. across several stakeholders of the ML lifecycle. For regulators and certiﬁcation bodies, it contributes',\n",
       " 'For regulators and certiﬁcation bodies, it contributes\\nto algorithm auditing and quality control as a path towards the effective and reliable\\napplication of ML systems [11].\\n Previous research has been focused on the development of techniques to characterize , UQ increases interpretability and trust in model predictions, answering\\nthe question: Can I trust this model? of AI systems',\n",
       " 'However, few studies addressed a comprehensive analysis of\\nhow UQ can be used to improve model performance and its interpretability. Previous research has been focused on the development of techniques to characterize\\nand quantify uncertainty. This work\\nfocused on leveraging the outcome from uncertainty quantiﬁcation to improve the model application of ML systems [11].\\n',\n",
       " 'We applied the UQ concept in practice, giving insights into why it\\ncan be an effective procedure to improve model development. This work\\nfocused on leveraging the outcome from uncertainty quantiﬁcation to improve the model\\ndevelopment process. how UQ can be used to improve model performance and its interpretability. We identiﬁed the following\\nresearch questions:',\n",
       " 'We applied the UQ concept in practice, giving insights into why it\\ncan be an effective procedure to improve model development. How can UQ contribute to choosing the most suitable model for a given classification task?\\n2. Can UQ be used to combine different models in a principled manner? We identiﬁed the following\\nresearch questions:\\n1. development process.',\n",
       " 'How can UQ contribute to choosing the most suitable model for a given classification task?\\n2. In ML, various criteria can be used in the problem of model selection. Can UQ be used to combine different models in a principled manner?\\n3. Can visualization techniques improve UQ’s interpretability?\\n research questions:\\n1.',\n",
       " 'It\\ncan be applied either to different types of models or the same type conﬁgured with different Model selection\\nconsists of selecting a ﬁnal model among a collection of candidates for a training dataset. In ML, various criteria can be used in the problem of model selection. 3. Can visualization techniques improve UQ’s interpretability?\\n',\n",
       " 'The main goal of model selection is to achieve the best predictive\\nperformance for modeling learning data and for making predictions for new examples It\\ncan be applied either to different types of models or the same type conﬁgured with different\\nhyperparameters. consists of selecting a ﬁnal model among a collection of candidates for a training dataset. that',\n",
       " 'The main goal of model selection is to achieve the best predictive\\nperformance for modeling learning data and for making predictions for new examples that\\nwere not included in the learning process [ 12,13]. In supervised learning, the predictive\\naccuracy is usually considered as the most important criterion for model selection. However, hyperparameters.',\n",
       " 'However,\\nvarious criteria for the predictive model quality, such as interpretability or computational\\ncost, can also play a key role in model selection. In supervised learning, the predictive\\naccuracy is usually considered as the most important criterion for model selection. were not included in the learning process [ 12,13]. To the best of our knowledge, uncertainty is',\n",
       " 'various criteria for the predictive model quality, such as interpretability or computational\\ncost, can also play a key role in model selection. To the best of our knowledge, uncertainty is\\nnot being considered as criterion for model selection. Question 1 addresses how uncertainty\\nmight contribute to model characterization with valuable quantitative information, either',\n",
       " 'Question 1 addresses how uncertainty\\nmight contribute to model characterization with valuable quantitative information, either\\nby describing the quality of the model’s ﬁt or evaluating if sufﬁcient training data were\\nprovided to calculate trustworthy predictions. not being considered as criterion for model selection.',\n",
       " 'It is often found that, in particularly complex classiﬁcation problems, performance\\ncan be improved by combining multiple models, instead of just using a single one. by describing the quality of the model’s ﬁt or evaluating if sufﬁcient training data were\\nprovided to calculate trustworthy predictions.\\n There\\nare several combination rules to train and combine different models. Some rules address',\n",
       " 'can be improved by combining multiple models, instead of just using a single one. Some rules address\\nmodels’ combination using the average of the predictions or the class probabilities. There\\nare several combination rules to train and combine different models. Nev-\\nertheless, the uncertainty of multiple models is seldom considered. With Question 2,',\n",
       " 'With Question 2, we\\naddress how uncertainty can be taken into account for model combination.\\n In ordinary classiﬁcation, the classiﬁer is usually forced to predict a label. Nev-\\nertheless, the uncertainty of multiple models is seldom considered. models’ combination using the average of the predictions or the class probabilities. For difﬁcult',\n",
       " 'For difﬁcult\\nsamples, it might lead to misclassiﬁcation, which may cause problems in risk-sensitive\\napplications. In these scenarios, it will be more appropriate to avoid making decisions address how uncertainty can be taken into account for model combination.\\n In ordinary classiﬁcation, the classiﬁer is usually forced to predict a label.',\n",
       " 'In these scenarios, it will be more appropriate to avoid making decisions\\non the difﬁcult cases in anticipation of a lower error rate on those examples for which\\na classiﬁcation decision is made [ 3]. samples, it might lead to misclassiﬁcation, which may cause problems in risk-sensitive\\napplications. This approach is known as classiﬁcation with a',\n",
       " 'In addition to quantitative methods for sample rejection, it is important\\nto provide the interpretability of why a particular sample was rejected. on the difﬁcult cases in anticipation of a lower error rate on those examples for which\\na classiﬁcation decision is made [ 3]. This approach is known as classiﬁcation with a\\nrejecting option. In this context,',\n",
       " '[14] proposed a visualization explainable matrix applied to random forests\\nwith a focus on global and local explanations where conﬁdence scores were used as an In addition to quantitative methods for sample rejection, it is important\\nto provide the interpretability of why a particular sample was rejected. In this context,\\nNeto et al. rejecting option.',\n",
       " 'However, with regard to uncertainty visualization for a given\\nprediction or applied to the model itself, few or no studies have considered this in theElectronics 2022 ,11, 396 3 of 20 [14] proposed a visualization explainable matrix applied to random forests\\nwith a focus on global and local explanations where conﬁdence scores were used as an\\ninterpretability measure. Neto et al.',\n",
       " 'prediction or applied to the model itself, few or no studies have considered this in theElectronics 2022 ,11, 396 3 of 20\\nliterature. Therefore, Question 3 addresses how visualization techniques might be used to\\nimprove UQ’s interpretability.\\n The remainder of this paper is organized as follows: In Section 2, we introduce the',\n",
       " 'Section 4 contains experimental results,\\nand in Section 5, we detail the conclusions and discuss possible directions for future work. Section 3 contains a thorough description of the\\nmethods used to answer the research questions. In Section 2, we introduce the\\nbackground concepts and related work. The remainder of this paper is organized as follows: improve UQ’s interpretability.\\n',\n",
       " 'Section 4 contains experimental results,\\nand in Section 5, we detail the conclusions and discuss possible directions for future work.\\n 2. Background and Related Work\\nThe awareness of uncertainty is of major importance in ML and constitutes a key\\nelement of its methodology. Traditionally, uncertainty in ML is modeled using probability methods used to answer the research questions.',\n",
       " 'Traditionally, uncertainty in ML is modeled using probability\\ntheory, which has always been perceived as the reference tool for uncertainty handling [ 4].\\n 2. Background and Related Work\\nThe awareness of uncertainty is of major importance in ML and constitutes a key\\nelement of its methodology. In the recent ML literature, two inherently different sources of uncertainty are commonly',\n",
       " 'In the recent ML literature, two inherently different sources of uncertainty are commonly\\ndistinguished, referred to as aleatoric and epistemic [ 15]. Aleatoric uncertainty refers to\\nthe notion of randomness and cannot be reduced by adding more samples to the training theory, which has always been perceived as the reference tool for uncertainty handling [ 4].\\n',\n",
       " 'Aleatoric uncertainty refers to\\nthe notion of randomness and cannot be reduced by adding more samples to the training\\nprocess. On the other hand, epistemic uncertainty refers to the uncertainty caused by a lack\\nof knowledge, either due to the uncertainty associated with the model or the lack of data. distinguished, referred to as aleatoric and epistemic [ 15].',\n",
       " 'On the other hand, epistemic uncertainty refers to the uncertainty caused by a lack\\nof knowledge, either due to the uncertainty associated with the model or the lack of data.\\n In the following subsections, we present an overview of previous works that have In principle, this uncertainty can be reduced by adding more training data.\\n process.',\n",
       " 'In the following subsections, we present an overview of previous works that have\\nexplored different strategies for UQ and methods about classiﬁcation with rejection.\\n In principle, this uncertainty can be reduced by adding more training data.\\n Uncertainty Quantiﬁcation\\nIn standard probabilistic modeling and Bayesian inference, the representation of 2.1.',\n",
       " 'Uncertainty Quantiﬁcation\\nIn standard probabilistic modeling and Bayesian inference, the representation of\\nuncertainty about a prediction is given by the posterior distribution. Let us consider a ﬁnite\\ntraining dataset, D=f(xi,wi)gN\\ni, with Nsamples, composed of pairs of input features explored different strategies for UQ and methods about classiﬁcation with rejection.\\n 2.1.',\n",
       " 'Let us consider a ﬁnite\\ntraining dataset, D=f(xi,wi)gN\\ni, with Nsamples, composed of pairs of input features\\nxand labels w, where wk2fw1, ...,wKgconsists of a ﬁnite set of Kclass labels. uncertainty about a prediction is given by the posterior distribution. Suppose\\na hypothesis space of probabilistic predictors, where a hypothesis hmaps instances x',\n",
       " 'Suppose\\na hypothesis space of probabilistic predictors, where a hypothesis hmaps instances x\\nto probability distributions on outcomes w. Each hypothesis can be considered as an\\nexplanation of how the world works. xand labels w, where wk2fw1, ...,wKgconsists of a ﬁnite set of Kclass labels. Samples from the posterior distribution should',\n",
       " 'Samples from the posterior distribution should\\nyield explanations consistent with the observations of the world contained within the\\ntraining data, D[16]. Each hypothesis can be considered as an\\nexplanation of how the world works. From a Bayesian perspective, each hypothesis is equipped with a to probability distributions on outcomes w.',\n",
       " 'From a Bayesian perspective, each hypothesis is equipped with a\\nprior distribution p(h), and the posterior distribution, p(hjD), can be computed via the\\nBayes rule:\\np(hjD) =p(Djh)p(h)\\np(D)(1)\\nwhere p(Djh)is the probability of the data given h, i.e., the likelihood of the parameters h. yield explanations consistent with the observations of the world contained within the\\ntraining data, D[16].',\n",
       " 'Bayes rule:\\np(hjD) =p(Djh)p(h)\\np(D)(1)\\nwhere p(Djh)is the probability of the data given h, i.e., the likelihood of the parameters h.\\nFor a given instance x, the predictive uncertainty of a classiﬁcation model depends\\non how the uncertainty is represented as a basis for prediction and decision-making. In\\nBayesian inference, the belief about the outcome wkis represented by a second-order',\n",
       " 'In\\nBayesian inference, the belief about the outcome wkis represented by a second-order\\nprobability: a probability distribution of probability distributions [ 15]. In this type of\\nBayesian inference, a given prediction is obtained through model averaging, i.e., different on how the uncertainty is represented as a basis for prediction and decision-making.',\n",
       " 'In this type of\\nBayesian inference, a given prediction is obtained through model averaging, i.e., different\\nhypotheses hprovide predictions, which are aggregated in terms of a weighted average.\\n Thus, the predictive posterior distribution is given by:\\np(wjx) =Z\\np(wjx,h)dP(hjD) (2) probability: a probability distribution of probability distributions [ 15].',\n",
       " 'Thus, the predicted probability of an outcome wis the expected probability p(wjx,h),\\nwhere the expectation over the hypotheses is taken with respect to the posterior distribution, hypotheses hprovide predictions, which are aggregated in terms of a weighted average.\\n Thus, the predictive posterior distribution is given by:\\np(wjx) =Z\\np(wjx,h)dP(hjD) (2)\\n',\n",
       " 'However, since model averaging is often difﬁcult and computationally costly, in\\nML, it is common to make predictions considering a single probability distribution for each Thus, the predicted probability of an outcome wis the expected probability p(wjx,h),\\nwhere the expectation over the hypotheses is taken with respect to the posterior distribution,\\nP(hjD). p(wjx,h)dP(hjD) (2)\\n',\n",
       " 'However, since model averaging is often difﬁcult and computationally costly, in\\nML, it is common to make predictions considering a single probability distribution for each\\nclass. The most well-known measure of uncertainty of a single probability distribution, p,\\nis the (Shannon) entropy, which for discrete class labels is given as:\\nH(p) =\\x00K\\nå P(hjD).',\n",
       " 'The most well-known measure of uncertainty of a single probability distribution, p,\\nis the (Shannon) entropy, which for discrete class labels is given as:\\nH(p) =\\x00K\\nå\\nk=1p(w)log2p(w) (3)Electronics 2022 ,11, 396 4 of 20\\nThis measure of uncertainty primarily captures the shape of the distribution and,\\nhence, is mostly concerned with the aleatoric part of the overall uncertainty. class.',\n",
       " 'In order to account for both aleatoric and epistemic uncertainty, the Bayesian per-\\nspective is quite common in ML, where the (total) uncertainty is quantiﬁed on the basis This measure of uncertainty primarily captures the shape of the distribution and,\\nhence, is mostly concerned with the aleatoric part of the overall uncertainty.\\n',\n",
       " 'In order to account for both aleatoric and epistemic uncertainty, the Bayesian per-\\nspective is quite common in ML, where the (total) uncertainty is quantiﬁed on the basis\\nof the predictive posterior distribution. In the context of neural networks for regression,\\nDepeweg et al. [ 17] proposed an approach to quantify and separate uncertainties with',\n",
       " 'The authors’ idea was more general and can\\nalso be applied to other settings, such as in the work of Shaker et al. [ 17] proposed an approach to quantify and separate uncertainties with\\nclassical information-theoretic measures. In the context of neural networks for regression,\\nDepeweg et al. of the predictive posterior distribution. [ 18], where mea-',\n",
       " 'The authors’ idea was more general and can\\nalso be applied to other settings, such as in the work of Shaker et al. [ 18], where mea-\\nsures of entropy were applied using a random forest classiﬁer, or the work of Andrey\\nMalinin et al. [16], who adopted these measures in the context of gradient boosting models. classical information-theoretic measures.',\n",
       " 'sures of entropy were applied using a random forest classiﬁer, or the work of Andrey\\nMalinin et al. [ 17] proposed to measure the total uncertainty in terms of\\nthe entropy of the predictive posterior distribution, H[p(wjx)], and measure the aleatoric [16], who adopted these measures in the context of gradient boosting models.\\n More speciﬁcally, Depeweg et al.',\n",
       " '[ 17] proposed to measure the total uncertainty in terms of\\nthe entropy of the predictive posterior distribution, H[p(wjx)], and measure the aleatoric\\nuncertainty in terms of the expectation of entropy with regard to the posterior probability,\\nEp(hjD)H[p(wjx,h)]. The aleatoric uncertainty is measured in terms of the expectation over More speciﬁcally, Depeweg et al.',\n",
       " 'The aleatoric uncertainty is measured in terms of the expectation over\\nthe entropies of distributions, since his not precisely known. uncertainty in terms of the expectation of entropy with regard to the posterior probability,\\nEp(hjD)H[p(wjx,h)]. However, the idea is that by\\nﬁxing a hypothesis h, the epistemic uncertainty is essentially removed. Then, the epistemic',\n",
       " 'Then, the epistemic\\nuncertainty is measured in terms of the mutual information between hypotheses and out-\\ncomes, I(w,hjx,D). However, the idea is that by\\nﬁxing a hypothesis h, the epistemic uncertainty is essentially removed. Epistemic uncertainty is high if the distribution p(wjx,h)varies greatly the entropies of distributions, since his not precisely known.',\n",
       " 'Epistemic uncertainty is high if the distribution p(wjx,h)varies greatly\\nfor different hypotheses hwith high probability, but leading to quite different predictions.\\n uncertainty is measured in terms of the mutual information between hypotheses and out-\\ncomes, I(w,hjx,D). Due to the computational complexity of these measures, which involve the integration',\n",
       " 'Due to the computational complexity of these measures, which involve the integration\\nover the hypothesis space, an approximation by means of ensemble techniques, based on\\nan ensemble of Mhypotheses, can be obtained using the following equations:\\nualeat(x) =Ep(hjD)H[p(wjx,h)]\\x191\\nMM\\nå\\ni=1H[p(wjx,hi)] for different hypotheses hwith high probability, but leading to quite different predictions.\\n (4)',\n",
       " 'an ensemble of Mhypotheses, can be obtained using the following equations:\\nualeat(x) =Ep(hjD)H[p(wjx,h)]\\x191\\nMM\\nå\\ni=1H[p(wjx,hi)] (6)\\nBesides the classical information-theoretic measures, the bootstrap method [ 19] is also (4)\\nutotal(x) =H[Ep(hjD)p(wjx,h)]\\x19H\"\\n1\\nMM\\nå\\ni=1P(wjx,hi)#\\n(5)\\nuepist(x) =I(w,hjx,D) =H[Ep(hjD)p(wjx,h)]\\x00Ep(hjD)H[p(wjx,h)]',\n",
       " '(6)\\nBesides the classical information-theoretic measures, the bootstrap method [ 19] is also\\na common approach to estimate uncertainty. In order to quantify the uncertainty in the\\nresults of a given algorithm, the sampling distribution of a parameter of interest is required. 1\\nMM\\nå\\ni=1P(wjx,hi)#\\n(5)\\nuepist(x) =I(w,hjx,D) =H[Ep(hjD)p(wjx,h)]\\x00Ep(hjD)H[p(wjx,h)]',\n",
       " 'Because data represent one collection of observable data, resampling methods that generate\\nadditional representative samples in order to obtain a sampling distribution are used [ 20]. In order to quantify the uncertainty in the\\nresults of a given algorithm, the sampling distribution of a parameter of interest is required.\\n a common approach to estimate uncertainty.',\n",
       " 'Because data represent one collection of observable data, resampling methods that generate\\nadditional representative samples in order to obtain a sampling distribution are used [ 20].\\n The bootstrap method uses Monte Carlo simulation to approximate the sampling\\ndistribution by repeatedly simulating bootstrap samples, which are new datasets created',\n",
       " 'The bootstrap method uses Monte Carlo simulation to approximate the sampling\\ndistribution by repeatedly simulating bootstrap samples, which are new datasets created\\nby sampling with replacement from the uniform distribution over the original dataset. To\\nbootstrap a supervised learning algorithm, one would need to sample Sbootstrap datasets\\nand run the learning procedure from scratch each time.',\n",
       " 'bootstrap a supervised learning algorithm, one would need to sample Sbootstrap datasets\\nand run the learning procedure from scratch each time.\\n Variation ratios measure the variability of the predictions obtained from sampling by A measure to quantify uncertainty using the bootstrap method is the variation ratios.\\n',\n",
       " 'Variation ratios measure the variability of the predictions obtained from sampling by\\ncomputing the fraction of samples with the correct output. For a given instance x, the variation\\nratios are computed as follows:\\nVR=1\\x00fw\\x03 This heuristic is a measure of\\nthe dispersion of the predictions around its mode [ 21]. A measure to quantify uncertainty using the bootstrap method is the variation ratios.\\n',\n",
       " 'For a given instance x, the variation\\nratios are computed as follows:\\nVR=1\\x00fw\\x03\\nS(7)\\nwhere fwk=åS\\ni=11[wi=w\\x03]andw\\x03corresponds to the sampled majority class,\\nw\\x03=arg max\\nw=w1,...,wKS\\nå\\ni=11[wi=w] (8)\\nAdditionally, measures for novelty, anomaly, or outlier detection, where testing sam- the dispersion of the predictions around its mode [ 21].',\n",
       " 'where fwk=åS\\ni=11[wi=w\\x03]andw\\x03corresponds to the sampled majority class,\\nw\\x03=arg max\\nw=w1,...,wKS\\nå\\ni=11[wi=w] (8)\\nAdditionally, measures for novelty, anomaly, or outlier detection, where testing sam-\\nples come from a different population than the training set, can also be used to quantifyElectronics 2022 ,11, 396 5 of 20',\n",
       " 'Approaches based on generative models typically use densities\\nto decide whether to reject a test input that is located in a region without training inputs. ples come from a different population than the training set, can also be used to quantifyElectronics 2022 ,11, 396 5 of 20\\nuncertainty. In this scenario, the open set recognition and out-of-distribution problems are\\ncommonly mentioned [ 22].',\n",
       " 'Approaches based on generative models typically use densities\\nto decide whether to reject a test input that is located in a region without training inputs.\\n These low-density regions, where no training inputs have been encountered so far, repre-\\nsent a high knowledge uncertainty. Traditional methods, such as Kernel Density Estimation commonly mentioned [ 22].',\n",
       " 'Traditional methods, such as Kernel Density Estimation\\n(KDE), can be used to estimate densities, and often, threshold-based methods are applied\\non top of the density where a classiﬁer can refuse to predict a test input in that region [ 23]. These low-density regions, where no training inputs have been encountered so far, repre-\\nsent a high knowledge uncertainty.',\n",
       " '(KDE), can be used to estimate densities, and often, threshold-based methods are applied\\non top of the density where a classiﬁer can refuse to predict a test input in that region [ 23].\\n In this context, Knowledge Uncertainty Estimation (KUE) [ 24] learns the feature density\\nestimation from the training data, to reject test inputs that represent a density different',\n",
       " 'In this context, Knowledge Uncertainty Estimation (KUE) [ 24] learns the feature density\\nestimation from the training data, to reject test inputs that represent a density different\\nfrom the training dataset. For a test input xi, represented by P-dimensional feature vectors,\\nwhere fj2ff1,. . the feature vector in a bounded area of the feature space and wk .,fPgis',\n",
       " 'the feature vector in a bounded area of the feature space and wk\\nis the predicted class, the KUE measure is calculated as follows:\\nKUE(xijwk) =1\\x00 \\nP\\nÕ\\nj=1dunc(fjjwk,xi)!1\\nP\\n(9)\\nwhere duncis an uncertainty distance obtained from the feature density, assuming values For a test input xi, represented by P-dimensional feature vectors,\\nwhere fj2ff1,. . from the training dataset. .,fPgis',\n",
       " '[0, 1], where one represents the maximum density seen in training and\\nnear-zero values represent low-density regions where no training inputs were observed\\nduring training. =1\\x00 \\nP\\nÕ\\nj=1dunc(fjjwk,xi)!1\\nP\\n(9)\\nwhere duncis an uncertainty distance obtained from the feature density, assuming values\\nin the interval is the predicted class, the KUE measure is calculated as follows:\\nKUE(xijwk)',\n",
       " 'Classiﬁcation with the Rejection Option\\nThe process of abstaining from producing an answer or discarding a prediction when\\nthe system is not conﬁdent enough is more than 60 years old and was introduced by in the interval [0, 1], where one represents the maximum density seen in training and\\nnear-zero values represent low-density regions where no training inputs were observed\\nduring training.\\n 2.2.',\n",
       " 'The process of abstaining from producing an answer or discarding a prediction when\\nthe system is not conﬁdent enough is more than 60 years old and was introduced by\\nChow [ 25]. Chow’s theory suggests that objects are rejected for which the maximum\\nposterior probability is below a threshold. If the classiﬁer is not sufﬁciently accurate for',\n",
       " 'If the classiﬁer is not sufﬁciently accurate for\\nthe task at hand, then one can take the approach not to classify all examples, but only\\nthose whose posterior probability is sufﬁciently high. Chow’s theory suggests that objects are rejected for which the maximum\\nposterior probability is below a threshold. Chow’s theory is suitable when a Chow [ 25].',\n",
       " 'the task at hand, then one can take the approach not to classify all examples, but only\\nthose whose posterior probability is sufﬁciently high. Chow’s theory is suitable when a\\nsufﬁciently large training sample is available for all classes and when the training sample\\nis not contaminated by outliers [ 26]. [ 27] showed that Chow’s rule does not Fumera et al.',\n",
       " '[ 27] showed that Chow’s rule does not\\nperform well if a signiﬁcant error in the probability estimation is present. sufﬁciently large training sample is available for all classes and when the training sample\\nis not contaminated by outliers [ 26]. In that case, a\\ndifferent rejection threshold per class has to be used. In classiﬁers with a rejection option, Fumera et al.',\n",
       " 'In classiﬁers with a rejection option,\\nthe key parameters are the thresholds that deﬁne the rejection area, which may be hard to\\ndeﬁne and may vary signiﬁcantly in value, especially when classes have a large spread. In that case, a\\ndifferent rejection threshold per class has to be used. perform well if a signiﬁcant error in the probability estimation is present.',\n",
       " 'In these kinds of methods, the rejection is mostly applied to samples with high\\naleatoric uncertainty, since it has been argued that probability distributions are less suitable the key parameters are the thresholds that deﬁne the rejection area, which may be hard to\\ndeﬁne and may vary signiﬁcantly in value, especially when classes have a large spread.\\n',\n",
       " 'In these kinds of methods, the rejection is mostly applied to samples with high\\naleatoric uncertainty, since it has been argued that probability distributions are less suitable\\nfor representing ignorance in the sense of a lack of knowledge [ 4]. Alternatively, more\\nrecent works [ 15,18,21] included the classiﬁcation with rejection with a distinction between',\n",
       " 'Alternatively, more\\nrecent works [ 15,18,21] included the classiﬁcation with rejection with a distinction between\\naleatoric and epistemic uncertainty using ensemble techniques and/or deep learning\\napproaches. For the classiﬁcation with rejection, a conﬁdence threshold value needs to be for representing ignorance in the sense of a lack of knowledge [ 4].',\n",
       " 'Different cost-based rejection methods have been\\nproposed to minimize the classiﬁcation risk [ 28–30]. For the classiﬁcation with rejection, a conﬁdence threshold value needs to be\\ndeﬁned indicating the rejection point. aleatoric and epistemic uncertainty using ensemble techniques and/or deep learning\\napproaches. In probabilistic classiﬁers, risk can',\n",
       " 'In probabilistic classiﬁers, risk can\\nderive from the observation of the output probabilities employing different metrics, such\\nas the least conﬁdence, margin of conﬁdence, variation ratios, and predictive entropy [ 31]. Different cost-based rejection methods have been\\nproposed to minimize the classiﬁcation risk [ 28–30]. deﬁned indicating the rejection point.',\n",
       " 'derive from the observation of the output probabilities employing different metrics, such\\nas the least conﬁdence, margin of conﬁdence, variation ratios, and predictive entropy [ 31].\\n The evaluation of the performance of classiﬁers with rejection usually uses standard\\nmetrics, such as accuracy, to obtain an Accuracy-Rejection Curve (ARC) According to [ 32].',\n",
       " 'The evaluation of the performance of classiﬁers with rejection usually uses standard\\nmetrics, such as accuracy, to obtain an Accuracy-Rejection Curve (ARC) [ 32], an ARC is a function representing the accuracy of a classiﬁer as a function\\nof its rejection rate. Therefore, the ARCs plot the rejection rate of the metrics (from 0–1) According to\\nNadeem et al. [ 32].',\n",
       " 'Since the accuracy is always 100% when the rejection\\nrate is one, all curves converge to the point (1, 1), and they start from the point (0,a), where [ 32], an ARC is a function representing the accuracy of a classiﬁer as a function\\nof its rejection rate. Therefore, the ARCs plot the rejection rate of the metrics (from 0–1)\\nagainst the accuracy of the classiﬁer. Nadeem et al.',\n",
       " 'Since the accuracy is always 100% when the rejection\\nrate is one, all curves converge to the point (1, 1), and they start from the point (0,a), where\\nais the initial accuracy of the classiﬁer, with 0% of rejected samples. Using this approach, it\\nis not possible to determine the optimal rejection rate by comparing the performance of against the accuracy of the classiﬁer.',\n",
       " 'Although there are other metrics for evaluating classiﬁers with rejection,\\nthey are centered only on the nonrejected accuracy as a core component of ARCs [ 33].Electronics 2022 ,11, 396 6 of 20 Using this approach, it\\nis not possible to determine the optimal rejection rate by comparing the performance of\\nthe classiﬁers. ais the initial accuracy of the classiﬁer, with 0% of rejected samples.',\n",
       " 'they are centered only on the nonrejected accuracy as a core component of ARCs [ 33].Electronics 2022 ,11, 396 6 of 20\\nCondessa et al. [ 33] expanded the set of performance measures for classiﬁcation with\\nrejection and, besides the nonrejected accuracy, proposed two novel performance measures\\nto evaluate the best rejection point, namely classiﬁcation quality and rejection quality.',\n",
       " 'rejection and, besides the nonrejected accuracy, proposed two novel performance measures\\nto evaluate the best rejection point, namely classiﬁcation quality and rejection quality.\\n Considering a partition of a set of samples in subsets A,M,N, and R, where Ais a\\nsubset of accurately classiﬁed samples, Mis a subset of misclassiﬁed samples, Nis a subset',\n",
       " 'Considering a partition of a set of samples in subsets A,M,N, and R, where Ais a\\nsubset of accurately classiﬁed samples, Mis a subset of misclassiﬁed samples, Nis a subset\\nof nonrejected samples, and Ris a subset of the rejected samples, each metric can be derived\\nas follows:\\n• Nonrejected accuracy measures the ability of the classiﬁer to accurately classify nonre-',\n",
       " ', each metric can be derived\\nas follows:\\n• Nonrejected accuracy measures the ability of the classiﬁer to accurately classify nonre-\\njected samples, and it is computed as,\\nNRA =jA\\\\Nj\\njNj; (10)\\n• Classiﬁcation quality measures the ability of the classiﬁer with rejection to accurately of nonrejected samples, and Ris a subset of the rejected samples',\n",
       " 'It is computed as,\\nCQ=jA\\\\Nj+jM\\\\Rj\\njNj+jRj; (11)\\n• Rejection quality measures the ability of the classiﬁer with rejection to make errors on\\nrejected samples only, and it is computed as, jected samples, and it is computed as,\\nNRA =jA\\\\Nj\\njNj; (10)\\n• Classiﬁcation quality measures the ability of the classiﬁer with rejection to accurately\\nclassify nonrejected samples and to reject misclassiﬁed samples.',\n",
       " 'CQ=jA\\\\Nj+jM\\\\Rj\\njNj+jRj; (11)\\n• Rejection quality measures the ability of the classiﬁer with rejection to make errors on\\nrejected samples only, and it is computed as,\\nRQ=jM\\\\RjjAj\\njA\\\\RjjMj. Unlike these measures, the rejection quality has a minimum value of zero, and its The nonrejected accuracy and the classiﬁcation quality are bounded in the interval\\n[0, 1]. (12)\\n',\n",
       " 'Unlike these measures, the rejection quality has a minimum value of zero, and its\\nmaximum is unbounded by construction. The nonrejected accuracy and the classiﬁcation quality are bounded in the interval\\n[0, 1]. Nonetheless, the higher the values, the better the\\nmetric performs for rejection.\\n RQ=jM\\\\RjjAj\\njA\\\\RjjMj. Methods',\n",
       " 'Besides the common division between aleatoric and epistemic uncer-\\ntainty, we further divided the epistemic uncertainty into two additional categories, namely Methods\\nIn this work, we considered the uncertainty estimation problem in a traditional ML\\nclassiﬁcation setting. Nonetheless, the higher the values, the better the\\nmetric performs for rejection.\\n maximum is unbounded by construction. 3.',\n",
       " 'Besides the common division between aleatoric and epistemic uncer-\\ntainty, we further divided the epistemic uncertainty into two additional categories, namely\\nknowledge and model uncertainty. Although these terms are commonly used to refer to the\\nbroad view of epistemic uncertainty, we refer to knowledge uncertainty as the uncertainty classiﬁcation setting.',\n",
       " 'Although these terms are commonly used to refer to the\\nbroad view of epistemic uncertainty, we refer to knowledge uncertainty as the uncertainty\\nrelated to the lack of data, i.e., to the regions in space where there is little or no evidence of\\nany class regardless of being far from/near the decision boundary. On the other hand, we knowledge and model uncertainty.',\n",
       " 'related to the lack of data, i.e., to the regions in space where there is little or no evidence of\\nany class regardless of being far from/near the decision boundary. On the other hand, we\\nrefer to model uncertainty as the uncertainty related to the model itself, i.e., the quality of\\nthe model ﬁt on known data or uncertainty about the model parameters.',\n",
       " 'ML systems share a set of core components comprising data, an ML model, and\\nits outputs. Uncertainties are present in all ML components under different sources, as\\nvisualized in Figure 1. refer to model uncertainty as the uncertainty related to the model itself, i.e., the quality of\\nthe model ﬁt on known data or uncertainty about the model parameters.\\n',\n",
       " 'Electronics 2022 ,11, 396 7 of 20\\n• Data: Data used to feed ML models are limited in their accuracy and potentially ML systems share a set of core components comprising data, an ML model, and\\nits outputs. Uncertainties are present in all ML components under different sources, as\\nvisualized in Figure 1.\\nFigure 1. Uncertainty in Machine Learning (ML) classiﬁcation settings.',\n",
       " 'Electronics 2022 ,11, 396 7 of 20\\n• Data: Data used to feed ML models are limited in their accuracy and potentially\\naffected by various kinds of quality issues, which limits the models from being ap-\\nplied under optimal conditions [ 34,35]. For example, the uncertainty caused due to Uncertainty in Machine Learning (ML) classiﬁcation settings. Figure 1.',\n",
       " 'affected by various kinds of quality issues, which limits the models from being ap-\\nplied under optimal conditions [ 34,35]. For example, the uncertainty caused due to\\nerrors in the measurement might affect the performance of a given classiﬁcation task.\\n Although the aleatoric uncertainty is supposed to be irreducible for a speciﬁc dataset,',\n",
       " 'Although the aleatoric uncertainty is supposed to be irreducible for a speciﬁc dataset,\\nincorporating additional features or improving the quality of the existing features can\\nassist in its reduction [36];\\n• Model: For a given classiﬁcation task, several ML models can be applied and de- errors in the measurement might affect the performance of a given classiﬁcation task.\\n',\n",
       " 'incorporating additional features or improving the quality of the existing features can\\nassist in its reduction [36];\\n• Model: For a given classiﬁcation task, several ML models can be applied and de-\\nveloped. The choice of a model is arguably important and is often based on the\\ndegree of error in the model’s outcomes. However, besides models’ accuracy, the',\n",
       " 'However, besides models’ accuracy, the\\nuse of uncertainty quantiﬁcation methods during model development can provide\\nimportant elements to choose the right model for the problem at hand. The choice of a model is arguably important and is often based on the\\ndegree of error in the model’s outcomes. Moreover, veloped.',\n",
       " 'Moreover,\\nunderstanding the model’s uncertainty during training can give us insights about the\\nspeciﬁc limitations of each model and help in developing more robust models. use of uncertainty quantiﬁcation methods during model development can provide\\nimportant elements to choose the right model for the problem at hand. The',\n",
       " 'understanding the model’s uncertainty during training can give us insights about the\\nspeciﬁc limitations of each model and help in developing more robust models. The\\nestimation of model uncertainty increases model interpretability, by allowing the user\\nto interpret how conﬁdent the model is for a given prediction;\\n• Output: After the model’s training, estimating and quantifying uncertainty in a',\n",
       " 'to interpret how conﬁdent the model is for a given prediction;\\n• Output: After the model’s training, estimating and quantifying uncertainty in a\\ntransductive way, in the sense of tailoring it to individual instances, are arguably\\nrelevant, all the more in safety-critical applications. For instance, in the context of\\ncomputer-aided diagnosis systems, a prediction with high uncertainty shall justify',\n",
       " 'For instance, in the context of\\ncomputer-aided diagnosis systems, a prediction with high uncertainty shall justify\\neither disregarding its output or conducting further medical examinations of the\\npatient. In the latter, the goal is to retrieve additional evidence that supports or relevant, all the more in safety-critical applications.',\n",
       " 'In the former, it is the case of classiﬁcation with\\nrejection, which is a viable option, where the presence and cost of errors can be In the latter, the goal is to retrieve additional evidence that supports or\\ncontradicts a given hypothesis. either disregarding its output or conducting further medical examinations of the\\npatient.',\n",
       " 'In the former, it is the case of classiﬁcation with\\nrejection, which is a viable option, where the presence and cost of errors can be\\ndetrimental to the performance of automated classiﬁcation systems To illustrate the different sources of uncertainty and the methods for UQ, we introduce contradicts a given hypothesis. [33].\\n',\n",
       " 'To illustrate the different sources of uncertainty and the methods for UQ, we introduce\\na scenario using a simulated small dataset shown in Figure 2. The scenario consists of a\\ntwo-dimensional dataset with two classes, where features from class A were modeled with detrimental to the performance of automated classiﬁcation systems [33].\\n',\n",
       " 'The scenario consists of a\\ntwo-dimensional dataset with two classes, where features from class A were modeled with\\nan unimodal Gaussian distribution and features from class B were modeled as a bimodal\\ndistribution with a mixture of two Gaussian distributions with highly unequal mass. a scenario using a simulated small dataset shown in Figure 2. The',\n",
       " 'an unimodal Gaussian distribution and features from class B were modeled as a bimodal\\ndistribution with a mixture of two Gaussian distributions with highly unequal mass. The\\nminor mode is approximately 5.5% of the mass of the major mode.\\n0.4\\n 0.2\\n 0.0 0.2 0.4 0.6\\nFeature 10.40.60.81.01.21.4Feature 2Class A\\nClass B',\n",
       " 'minor mode is approximately 5.5% of the mass of the major mode.\\n0.4\\n 0.2\\n 0.0 0.2 0.4 0.6\\nFeature 10.40.60.81.01.21.4Feature 2Class A\\nClass B\\nFigure 2. Electronics 2022 ,11, 396 8 of 20\\nFor model training, a Naive Bayes (NB) classiﬁer using KDE was applied using a Synthetic dataset used to illustrate the different sources of uncertainty in a toy scenario.',\n",
       " 'For model training, a Naive Bayes (NB) classiﬁer using KDE was applied using a\\nbootstrap approach with 50 bootstrap samples to estimate the sampling distribution of\\narbitrary functions of a dataset. Using this approach, it is possible to access the amount\\nthat a prediction changes when the model is ﬁt on slightly different data.',\n",
       " 'Using this approach, it is possible to access the amount\\nthat a prediction changes when the model is ﬁt on slightly different data.\\n The selected uncertainty quantiﬁcation methods for each source of uncertainty were\\nthe following:\\n• Aleatoric uncertainty: The (Shannon) entropy is the most notable measure of uncer- arbitrary functions of a dataset.',\n",
       " 'The selected uncertainty quantiﬁcation methods for each source of uncertainty were\\nthe following:\\n• Aleatoric uncertainty: The (Shannon) entropy is the most notable measure of uncer-\\ntainty for probability distributions being more akin to aleatoric uncertainty. Equation (4) ,\\nwhich measures the aleatoric uncertainty in terms of expectation over the entropies of',\n",
       " 'Equation (4) ,\\nwhich measures the aleatoric uncertainty in terms of expectation over the entropies of\\ndistributions, was used for the rest of the analysis;\\n• Model uncertainty: Variation ratios (Equation (7)) were selected as a primary uncer- tainty for probability distributions being more akin to aleatoric uncertainty.',\n",
       " 'distributions, was used for the rest of the analysis;\\n• Model uncertainty: Variation ratios (Equation (7)) were selected as a primary uncer-\\ntainty quantiﬁcation method, to estimate model uncertainty, as we were interested in\\nevaluating the quality of the model ﬁt. In this sense, changes in the predicted label\\nhave a signiﬁcant impact on the variation ratio measure. Contrarily, measures based',\n",
       " 'Contrarily, measures based\\non entropies (Equation (6) is commonly used) can also be used, but the impact on the\\nmeasure is lower, since in variation ratios, we are merely counting changes in the pre- In this sense, changes in the predicted label\\nhave a signiﬁcant impact on the variation ratio measure. evaluating the quality of the model ﬁt.',\n",
       " 'on entropies (Equation (6) is commonly used) can also be used, but the impact on the\\nmeasure is lower, since in variation ratios, we are merely counting changes in the pre-\\ndictions, and in entropy measures, we are averaging the prediction probabilities [ 21];\\n• Knowledge uncertainty: Although the majority of works addressed the quantiﬁcation',\n",
       " 'dictions, and in entropy measures, we are averaging the prediction probabilities [ 21];\\n• Knowledge uncertainty: Although the majority of works addressed the quantiﬁcation\\nof knowledge uncertainty with measures such as the mutual information using ensem-\\nbles (Equation (6)), we argue that these kinds of measures are more akin to model un-',\n",
       " 'of knowledge uncertainty with measures such as the mutual information using ensem-\\nbles (Equation (6)) , we argue that these kinds of measures are more akin to model un-\\ncertainty. The uncertainty related to the lack of data might be poorly modeled by these\\nmeasures. In this perspective, we considered density estimation methods, commonly',\n",
       " 'In this perspective, we considered density estimation methods, commonly\\nused for outlier or novelty detection, more prone to model knowledge uncertainty.\\n The uncertainty related to the lack of data might be poorly modeled by these\\nmeasures. Thus, the KUE measure (Equation (9)) was used to model knowledge uncertainty. certainty.',\n",
       " 'In order to visualize the uncertainty estimations in the whole region presented in\\nFigure 2, we applied the uncertainty quantiﬁcation measures to a new set of points that used for outlier or novelty detection, more prone to model knowledge uncertainty.\\n Thus, the KUE measure (Equation (9)) was used to model knowledge uncertainty.\\n',\n",
       " 'In order to visualize the uncertainty estimations in the whole region presented in\\nFigure 2, we applied the uncertainty quantiﬁcation measures to a new set of points that\\nincluded all combinations of feature values in the deﬁned region. Figure 3 shows the\\nuncertainty values for each point of the feature space.\\n 0.5\\n 0.0 0.5\\nFeature 10.500.751.001.251.50Feature 2Aleatoric Uncertainty\\n0.5\\n 0.0 0.5',\n",
       " 'uncertainty values for each point of the feature space.\\n0.5\\n 0.0 0.5\\nFeature 10.500.751.001.251.50Feature 2Aleatoric Uncertainty\\n0.5\\n 0.0 0.5\\nFeature 1Model Uncertainty\\n0.5\\n 0.0 0.5\\nFeature 1Knowledge Uncertainty\\n0.00.20.40.60.81.0\\nentropy\\n0.00.10.20.30.40.5\\nvariation ratios\\n0.00.20.40.60.81.0\\nKUE\\nFigure 3. Toy dataset uncertainty measures for aleatoric, model, and knowledge uncertainty (from',\n",
       " 'Observing the uncertainty regions for each source of uncertainty, one can see com-\\npletely different behaviors depending on the uncertainty. Toy dataset uncertainty measures for aleatoric, model, and knowledge uncertainty (from\\nlefttoright ).\\n 0.00.20.40.60.81.0\\nentropy\\n0.00.10.20.30.40.5\\nvariation ratios\\n0.00.20.40.60.81.0\\nKUE\\nFigure 3. The aleatoric uncertainty is high',\n",
       " 'The aleatoric uncertainty is high\\nin the middle of the two major clusters (Feature 1 equals to 0.15 approximately), due to\\nthe overlap between the classes. Observing the uncertainty regions for each source of uncertainty, one can see com-\\npletely different behaviors depending on the uncertainty. The overlap between the cluster of class A and the minor lefttoright ).\\n',\n",
       " 'in the middle of the two major clusters (Feature 1 equals to 0.15 approximately), due to\\nthe overlap between the classes. The overlap between the cluster of class A and the minor\\ncluster of class B also presents a higher uncertainty compared to the rest of the region.\\n However, it does not produce an uncertainty as high as the overlap between the two',\n",
       " 'However, it does not produce an uncertainty as high as the overlap between the two\\nmajor clusters due to the differences in the masses of both clusters. cluster of class B also presents a higher uncertainty compared to the rest of the region.\\n The entropy value is\\nnormalized to the maximum entropy, i.e., the logarithm of the number of classes.',\n",
       " 'Regarding the model uncertainty and referring to this toy scenario with two classes,\\nthe maximum possible value occurs when the frequency of both classes is equal, i.e., the The entropy value is\\nnormalized to the maximum entropy, i.e., the logarithm of the number of classes.\\n major clusters due to the differences in the masses of both clusters.',\n",
       " 'Regarding the model uncertainty and referring to this toy scenario with two classes,\\nthe maximum possible value occurs when the frequency of both classes is equal, i.e., the\\nvariation ratios have a value of 0.5. The regions with higher uncertainty values are the\\nones with little evidence, since the model ﬁt in these regions is highly dependent on the',\n",
       " 'The regions with higher uncertainty values are the\\nones with little evidence, since the model ﬁt in these regions is highly dependent on the\\navailable data. Therefore, it is expected that slight differences in the training data, especiallyElectronics 2022 ,11, 396 9 of 20 variation ratios have a value of 0.5.',\n",
       " 'Therefore, it is expected that slight differences in the training data, especiallyElectronics 2022 ,11, 396 9 of 20\\nin regions with little evidence, have a high impact on the model ﬁt and produce high model\\nuncertainty. Observing the ﬁgure, it is possible to see that the minor cluster of class B\\nproduces a high model uncertainty. Additionally, the upper and lower regions between available data.',\n",
       " 'Additionally, the upper and lower regions between\\nthe major clusters also produce a high uncertainty, due to slight differences in the decision\\nboundary on different bootstrap samples.\\n Observing the ﬁgure, it is possible to see that the minor cluster of class B\\nproduces a high model uncertainty. Finally, knowledge uncertainty was modeled using the feature density on the training uncertainty.',\n",
       " 'For the classiﬁcation with rejection, we deﬁne a rejection rule for each type of uncer-\\ntainty, using the previously uncertainty measures to deﬁne the conﬁdence threshold. Finally, knowledge uncertainty was modeled using the feature density on the training\\ndata, which produces a high uncertainty in all the feature space without data.\\n boundary on different bootstrap samples.\\n The',\n",
       " 'For the classiﬁcation with rejection, we deﬁne a rejection rule for each type of uncer-\\ntainty, using the previously uncertainty measures to deﬁne the conﬁdence threshold. There are several works entirely dedicated to this topic, such as the work of\\nCondessa et al. The\\nproblem of choosing the optimal rejection point is not trivial and was not addressed in\\nthis work. [33] and Fisher et al. [37].',\n",
       " 'In our classiﬁcation setting, the ﬁnal prediction is given by the following rejection rule:\\nˆw=(\\nreject ifF(x)>0\\nf(x) otherwise(13)\\nwhere f(x)is the classiﬁer without rejection and F(x)is a function on the input that There are several works entirely dedicated to this topic, such as the work of\\nCondessa et al. [33] and Fisher et al. this work. [37].\\n',\n",
       " 'This uncertainty function is given\\nby the set of uncertainties—aleatoric ( a), model ( m), and knowledge ( k)—through the\\nfollowing equation:\\nF(x) =å\\nu2U1[fu(x)>tu] (14) ˆw=(\\nreject ifF(x)>0\\nf(x) otherwise(13)\\nwhere f(x)is the classiﬁer without rejection and F(x)is a function on the input that\\nevaluates the uncertainty of the prediction model.',\n",
       " 'by the set of uncertainties—aleatoric ( a), model ( m), and knowledge ( k)—through the\\nfollowing equation:\\nF(x) =å\\nu2U1[fu(x)>tu] (14)\\nwhere U2[a,m,k]is the set of available uncertainties, fuis an uncertainty function that\\nevaluates uncertainty u, and tuis a threshold for the rejection point for uncertainty u.\\nRegarding aleatoric uncertainty, fais equal to Equation (4) and the optimal threshold,',\n",
       " 'Regarding aleatoric uncertainty, fais equal to Equation (4) and the optimal threshold,\\nta, was obtained using the following equation:\\nta=argmax\\nq\\x12\\njM\\\\Rqj\\x00b\\n1\\x00b\\x01jA\\\\Rqj\\x13\\n(15)\\nwhere qis a threshold in the interval evaluates uncertainty u, and tuis a threshold for the rejection point for uncertainty u.\\n [0, 1], representing a normalized entropy value',\n",
       " 'ta, was obtained using the following equation:\\nta=argmax\\nq\\x12\\njM\\\\Rqj\\x00b\\n1\\x00b\\x01jA\\\\Rqj\\x13\\n(15)\\nwhere qis a threshold in the interval [0, 1], representing a normalized entropy value\\nmeasured with Equation (4), and bis a rejection cost, here set to 0.5. For jM\\\\Rqjand\\njA\\\\Rqj, the notation from Section 2.2 was used, and the subsets represent the true rejections',\n",
       " 'For jM\\\\Rqjand\\njA\\\\Rqj, the notation from Section 2.2 was used, and the subsets represent the true rejections\\nand false rejections using threshold q, respectively.\\n The uncertainty function used for model uncertainty, fm, is equal to Equation (7), and measured with Equation (4), and bis a rejection cost, here set to 0.5.',\n",
       " 'The uncertainty function used for model uncertainty, fm, is equal to Equation (7), and\\ntmwas set to zero, which means that a prediction must be equal in all bootstraps samples\\nto not be rejected. This assumption was made because if a sample is predicted differently and false rejections using threshold q, respectively.\\n',\n",
       " 'This assumption was made because if a sample is predicted differently\\nusing slightly different datasets, the model in that particular region will still have some\\nuncertainty associated.\\n tmwas set to zero, which means that a prediction must be equal in all bootstraps samples\\nto not be rejected. For knowledge uncertainty, fkis equal to Equation (9). To deﬁne tk, we used a',\n",
       " 'using slightly different datasets, the model in that particular region will still have some\\nuncertainty associated.\\n To deﬁne tk, we used a\\n95% value of the training uncertainty values, meaning that tk=P95%[KUE]. A detailed\\ndescription of this approach is available in [24]. For knowledge uncertainty, fkis equal to Equation (9).',\n",
       " 'In summary, our proposed approach was developed in the context of classiﬁcation\\nwith rejection where rejection was obtained through measures of uncertainty. These un-\\ncertainty measures were distinguished by three different sources: aleatoric, model, and 95% value of the training uncertainty values, meaning that tk=P95%[KUE]. A detailed\\ndescription of this approach is available in [24].\\n',\n",
       " 'These un-\\ncertainty measures were distinguished by three different sources: aleatoric, model, and\\nknowledge uncertainty. For the uncertainty quantiﬁcation, we used an entropy measure\\nfor aleatoric uncertainty (Equation (4)), the variation ratio measure for model uncertainty with rejection where rejection was obtained through measures of uncertainty.',\n",
       " 'For the uncertainty quantiﬁcation, we used an entropy measure\\nfor aleatoric uncertainty (Equation (4)), the variation ratio measure for model uncertainty\\n(Equation (7)), and KUE to quantify the knowledge uncertainty. Regarding the rejection\\nsetting, we applied the rejection rule from Equation (13), where each source of uncertainty knowledge uncertainty.',\n",
       " 'Regarding the rejection\\nsetting, we applied the rejection rule from Equation (13), where each source of uncertainty\\nhas an uncertainty function given by Equation (14). For the training procedure, a bootstrap\\napproach with 20 bootstrap samples was used, and the uncertainty measures were calcu- (Equation (7)), and KUE to quantify the knowledge uncertainty.',\n",
       " 'The evaluation of the selected models was performed through the accuracy and the\\nnonrejection accuracy followed by the rejection fraction for each individual measure andElectronics 2022 ,11, 396 10 of 20 For the training procedure, a bootstrap\\napproach with 20 bootstrap samples was used, and the uncertainty measures were calcu-\\nlated. has an uncertainty function given by Equation (14).',\n",
       " 'nonrejection accuracy followed by the rejection fraction for each individual measure andElectronics 2022 ,11, 396 10 of 20\\nalso the total rejection fraction. In the case of the models’ combination, the performance\\nmeasures from Equations (10)–(12) were also employed.\\n Experiments\\nIn this section, we demonstrate the usefulness of uncertainty quantiﬁcation using 4.',\n",
       " 'Experiments\\nIn this section, we demonstrate the usefulness of uncertainty quantiﬁcation using\\nsynthetic datasets and a benchmark dataset from the University of California Irvine (UCI)\\nML repository [38]. How can UQ contribute to choosing the most suitable model for a given measures from Equations (10)–(12) were also employed.\\n Speciﬁcally, we answer the following questions:\\n• Q1. 4.',\n",
       " 'How can UQ contribute to choosing the most suitable model for a given\\nclassiﬁcation task?\\n• Q2. Analysis on Synthetic Data\\nPredicted uncertainties are often evaluated indirectly, since normally, data do not Can UQ be use to combine different models?\\n• Q3. Speciﬁcally, we answer the following questions:\\n• Q1. Can visualization techniques improve UQ’s interpretability?\\n4.1.',\n",
       " 'Analysis on Synthetic Data\\nPredicted uncertainties are often evaluated indirectly, since normally, data do not\\ncontain information about any sort of “ground truth” uncertainties. For this reason, the\\nuse of a synthetic dataset can more easily provide an intuition about the different types of Can visualization techniques improve UQ’s interpretability?\\n4.1. • Q3.',\n",
       " 'For this reason, the\\nuse of a synthetic dataset can more easily provide an intuition about the different types of\\nuncertainties and their quantiﬁcation. Furthermore, in a controllable setting, we can alter\\nthe size of the datasets, evaluate the models’ performance and uncertainties in different contain information about any sort of “ground truth” uncertainties.',\n",
       " 'Furthermore, in a controllable setting, we can alter\\nthe size of the datasets, evaluate the models’ performance and uncertainties in different\\nconditions, and introduce noise in the data to check the models’ robustness.\\n Uncertainty for Model Selection (Q1)\\nTo answer Q1, we generated a dataset composed of a total of 150,000 ten-dimensional uncertainties and their quantiﬁcation. 4.1.1.',\n",
       " 'Uncertainty for Model Selection (Q1)\\nTo answer Q1, we generated a dataset composed of a total of 150,000 ten-dimensional\\npoints corresponding to six different classes equally distributed. Features from each class\\nwere modeled using Gaussian, exponential, and uniform distributions. The distributions\\nwere randomly selected and could be unimodal or bimodal distributions. To evaluate 4.1.1.',\n",
       " 'To evaluate\\nthe behavior of uncertainty estimations with the increasing number of training samples,\\nthe models were trained for different training sizes using a k-fold cross-validation as the The distributions\\nwere randomly selected and could be unimodal or bimodal distributions. were modeled using Gaussian, exponential, and uniform distributions.',\n",
       " 'the behavior of uncertainty estimations with the increasing number of training samples,\\nthe models were trained for different training sizes using a k-fold cross-validation as the\\nvalidation strategy where k was set to 5. An exponential growth of the training samples\\nwas applied, starting with 50 samples per class (training size equals 300 samples).',\n",
       " 'For model training, different classiﬁers using a training size of 7692 samples were\\ntested as presented in Table 1. An exponential growth of the training samples\\nwas applied, starting with 50 samples per class (training size equals 300 samples).\\n Since features data were simulated using Gaussian, expo- validation strategy where k was set to 5.',\n",
       " 'Since features data were simulated using Gaussian, expo-\\nnential, and uniform distributions, a focus on Bayesian models using Gaussian, KDE, and\\nexponential distributions was employed. For model training, different classiﬁers using a training size of 7692 samples were\\ntested as presented in Table 1. As expected, Bayesian models obtained higher',\n",
       " 'As expected, Bayesian models obtained higher\\nbaseline accuracies than the other tested classiﬁers, since part of the features likelihood\\nwas modeled with the true data distribution. nential, and uniform distributions, a focus on Bayesian models using Gaussian, KDE, and\\nexponential distributions was employed. With the purpose of answering Q1, the three',\n",
       " 'With the purpose of answering Q1, the three\\nclassiﬁers highlighted in Table 1, with a similar baseline accuracy, were selected to continue\\nthe analysis. baseline accuracies than the other tested classiﬁers, since part of the features likelihood\\nwas modeled with the true data distribution. These classiﬁers were: (1) the NB classiﬁer where the features likelihood',\n",
       " 'These classiﬁers were: (1) the NB classiﬁer where the features likelihood\\nwas assumed to be Gaussian; (2) the NB classiﬁer where the features likelihood was as-\\nsumed to be exponential; (3) the Bayes classiﬁer where the features likelihood was based classiﬁers highlighted in Table 1, with a similar baseline accuracy, were selected to continue\\nthe analysis.',\n",
       " 'was assumed to be Gaussian; (2) the NB classiﬁer where the features likelihood was as-\\nsumed to be exponential; (3) the Bayes classiﬁer where the features likelihood was based\\non KDE. Additionally, the selected classiﬁers were trained using a bootstrap procedure\\nwith 20 bootstrap samples.\\n For this analysis, only aleatoric and model uncertainty measures were considered,',\n",
       " 'For this analysis, only aleatoric and model uncertainty measures were considered,\\nsince a synthetic dataset without outliers was used. Therefore, KUE would be near zero\\nand would not bring relevant information for this analysis. Additionally, the selected classiﬁers were trained using a bootstrap procedure\\nwith 20 bootstrap samples.\\n on KDE.',\n",
       " 'Figure 4 shows the rejection fraction and accuracy with the increasing number of\\ntraining samples for the different tested models. The rejection fraction was obtained\\nusing both aleatoric and model uncertainty measures independently, and the nonrejected Therefore, KUE would be near zero\\nand would not bring relevant information for this analysis.\\n since a synthetic dataset without outliers was used.',\n",
       " 'The rejection fraction was obtained\\nusing both aleatoric and model uncertainty measures independently, and the nonrejected\\naccuracy was obtained by rejecting all samples with aleatoric and/or model uncertainty\\n(see Equation (13)).\\n As previously mentioned, the model’s accuracy is often one of the most important training samples for the different tested models.',\n",
       " 'However, we argue that uncertainty quantiﬁcation methods\\nshould also be evaluated during the model’s training, to help us choose the right model. accuracy was obtained by rejecting all samples with aleatoric and/or model uncertainty\\n(see Equation (13)).\\n As previously mentioned, the model’s accuracy is often one of the most important\\nelements to model selection.',\n",
       " 'However, we argue that uncertainty quantiﬁcation methods\\nshould also be evaluated during the model’s training, to help us choose the right model.\\n For example, for a training size of 7692 samples (dashed gray line inElectronics 2022 ,11, 396 11 of 20 Observing Figure 4, different models can achieve the same accuracy, but with different\\ndegrees of uncertainty. elements to model selection.',\n",
       " 'For example, for a training size of 7692 samples (dashed gray line inElectronics 2022 ,11, 396 11 of 20\\nFigure 4), the three models obtained a baseline accuracy of 84%, approximately. Seen only\\nfrom this point of view, the decision between the three models would be equal. However,\\nobserving the rejection fraction from uncertainty measures, it is easy to understand that degrees of uncertainty.',\n",
       " 'However,\\nobserving the rejection fraction from uncertainty measures, it is easy to understand that\\nthe KDE model had higher model uncertainty compared with the other two models. The\\nreason for this difference is that the KDE model is more complex, which means that it from this point of view, the decision between the three models would be equal.',\n",
       " 'The\\nreason for this difference is that the KDE model is more complex, which means that it\\nneeds more data to correctly model the data distribution. Therefore, the differences in the\\nbootstrap samples have a high impact on the model ﬁt, meaning that the same sample is the KDE model had higher model uncertainty compared with the other two models.',\n",
       " 'Therefore, the differences in the\\nbootstrap samples have a high impact on the model ﬁt, meaning that the same sample is\\nclassiﬁed differently depending on the bootstrap sample used to ﬁt the model. Additionally,\\nobserving the standard deviation with the increasing number of training samples, we can needs more data to correctly model the data distribution.',\n",
       " 'Additionally,\\nobserving the standard deviation with the increasing number of training samples, we can\\nnote a slight decrease in both the rejection fraction and accuracy values, except from the\\nexponential model, which seemed to have an almost constant value across the different classiﬁed differently depending on the bootstrap sample used to ﬁt the model.',\n",
       " 'Using this information and since the accuracy was approximately equal for\\nthe three models, the choice of a Gaussian NB would be probably preferable due to its low\\naleatoric and model uncertainty. note a slight decrease in both the rejection fraction and accuracy values, except from the\\nexponential model, which seemed to have an almost constant value across the different\\ntraining sizes.',\n",
       " 'the three models, the choice of a Gaussian NB would be probably preferable due to its low\\naleatoric and model uncertainty.\\n The highlighted baseline accuracies represent the selected models that were\\nconsidered for further analysis, since the models attained similar accuracy values. Performance measures (mean \\x06standard deviation) for different models using a training\\nsize of 7692 samples. Table 1.',\n",
       " 'The highlighted baseline accuracies represent the selected models that were\\nconsidered for further analysis, since the models attained similar accuracy values.\\n ModelBaseline Nonrejected Rejection\\nAccuracy Accuracy Fraction\\nGaussian Naive Bayes 0.838\\x060.004 0.861\\x060.004 0.056\\x060.006\\nKDE Naive Bayes 0.918 size of 7692 samples. \\x060.004 0.929\\x060.004 0.050\\x060.007',\n",
       " '\\x060.004 0.929\\x060.004 0.050\\x060.007\\nExponential Naive Bayes 0.848\\x060.012 0.894\\x060.011 0.109\\x060.041\\nKDE Bayes 0.845\\x060.003 0.914\\x060.004 0.178\\x060.004\\nLogistic Regression 0.717 ModelBaseline Nonrejected Rejection\\nAccuracy Accuracy Fraction\\nGaussian Naive Bayes 0.838\\x060.004 0.861\\x060.004 0.056\\x060.006\\nKDE Naive Bayes 0.918 \\x060.003 0.788\\x060.005 0.198\\x060.006\\nDecision Tree 0.764 \\x060.024 0.884\\x060.004 0.328\\x060.111',\n",
       " '\\x060.004 0.806\\x060.005 0.173\\x060.010\\n0.00.20.4Rejection Fraction\\nGuassian Naive Bayes\\n Exponential Naive Bayes KDE Bayes 0.845\\x060.003 0.914\\x060.004 0.178\\x060.004\\nLogistic Regression 0.717 \\x060.004 0.902\\x060.007 0.202\\x060.005\\nSupport Vector Machines 0.744 \\x060.003 0.788\\x060.005 0.198\\x060.006\\nDecision Tree 0.764 \\x060.024 0.884\\x060.004 0.328\\x060.111\\nRandom Forest 0.806',\n",
       " '\\x060.004 0.806\\x060.005 0.173\\x060.010\\n0.00.20.4Rejection Fraction\\nGuassian Naive Bayes\\n Exponential Naive Bayes\\n KDE Model\\nAleatoric\\nModel\\n103104105\\n# train samples0.60.70.80.91.0Accuracy\\n103104105\\n# train samples\\n103104105\\n# train samples\\nBaseline\\nNRA \\x060.004 0.902\\x060.007 0.202\\x060.005\\nSupport Vector Machines 0.744 k-Nearest Neighbors 0.820',\n",
       " 'Uncertainties’ rejection fraction and obtained accuracies using a k-fold cross-validation\\nwith an increasing number of training samples for 3 different models. Guassian Naive Bayes\\n Exponential Naive Bayes\\n KDE Model\\nAleatoric\\nModel\\n103104105\\n# train samples0.60.70.80.91.0Accuracy\\n103104105\\n# train samples\\n103104105\\n# train samples\\nBaseline\\nNRA\\nFigure 4. The vertical line represents a',\n",
       " 'Uncertainties’ rejection fraction and obtained accuracies using a k-fold cross-validation\\nwith an increasing number of training samples for 3 different models. The vertical line represents a\\ntraining size that obtained a similar baseline accuracy for all models.\\n Nonetheless, if the rejection of samples or the addition of new samples is an option, a Figure 4.',\n",
       " 'By deﬁnition, aleatoric uncertainty is irreducible for theElectronics 2022 ,11, 396 12 of 20\\nsame dataset, which was veriﬁed with these experimental results. Nonetheless, if the rejection of samples or the addition of new samples is an option, a\\ndifferent analysis can be performed. training size that obtained a similar baseline accuracy for all models.\\n Increasing the number',\n",
       " 'Increasing the number\\nof training samples did not change the aleatoric uncertainty, making the rejection fraction\\nmostly constant across the different training sizes. Contrarily, model uncertainty decreased\\nwith the increase of the number of training samples, tending towards zero when the model same dataset, which was veriﬁed with these experimental results.',\n",
       " 'Contrarily, model uncertainty decreased\\nwith the increase of the number of training samples, tending towards zero when the model\\nﬁt was equal for all bootstrap samples. Thus, the analysis of model uncertainty can give us\\ninsights about the usefulness of adding more samples for the model’s training. mostly constant across the different training sizes. In Gaussian',\n",
       " 'Thus, the analysis of model uncertainty can give us\\ninsights about the usefulness of adding more samples for the model’s training. In Gaussian\\nand KDE models, the decrease of model uncertainty had a clear increase in the baseline\\naccuracy. For the Gaussian NB model, from 103training samples, the baseline accuracy was ﬁt was equal for all bootstrap samples.',\n",
       " 'For the Gaussian NB model, from 103training samples, the baseline accuracy was\\nmostly constant and the decrease of model uncertainty was not signiﬁcant. This means that\\nthe model ﬁt did not change using different bootstrap samples, and the addition of new and KDE models, the decrease of model uncertainty had a clear increase in the baseline\\naccuracy.',\n",
       " 'This means that\\nthe model ﬁt did not change using different bootstrap samples, and the addition of new\\ndata did not improve the model’s performance. However, observing the KDE model, due to\\nits high rejection fraction of model uncertainty, the addition of new samples still increased mostly constant and the decrease of model uncertainty was not signiﬁcant.',\n",
       " 'However, observing the KDE model, due to\\nits high rejection fraction of model uncertainty, the addition of new samples still increased\\nthe model’s performance. Furthermore, the nonrejected accuracy was always higher than\\nthe baseline accuracy, and it was mostly constant across the different training sizes. data did not improve the model’s performance. This',\n",
       " 'This\\nmeans that the model uncertainty measure was in fact detecting the regions in the feature\\nspace responsible for a high number of misclassiﬁcations due to a poor model ﬁt.\\n4.1.2. Furthermore, the nonrejected accuracy was always higher than\\nthe baseline accuracy, and it was mostly constant across the different training sizes. Uncertainty for Models’ Combination (Q2) the model’s performance.',\n",
       " 'Uncertainty for Models’ Combination (Q2)\\nFrom the analysis of the previous question, we observed that different models had\\ndifferent degrees of uncertainty for the same training size. Since different models were\\nbased on different assumptions, we hypothesized that uncertainty measures can be used space responsible for a high number of misclassiﬁcations due to a poor model ﬁt.\\n4.1.2.',\n",
       " 'Since different models were\\nbased on different assumptions, we hypothesized that uncertainty measures can be used\\nto combine different models, producing a more robust model. In order to validate this\\nhypothesis, a new dataset composed of 150,000 ten-dimensional points corresponding to different degrees of uncertainty for the same training size.',\n",
       " 'In order to validate this\\nhypothesis, a new dataset composed of 150,000 ten-dimensional points corresponding to\\nsix different classes equally distributed and modeled as a bimodal Gaussian distribution\\nwas generated.\\n A Gaussian NB and a KDE Bayes classiﬁer were trained with a bootstrap approach to combine different models, producing a more robust model.',\n",
       " 'Figure 5 shows the rejection fraction and accuracy with the\\nincreasing number of training samples for both models. six different classes equally distributed and modeled as a bimodal Gaussian distribution\\nwas generated.\\n A Gaussian NB and a KDE Bayes classiﬁer were trained with a bootstrap approach\\nwith 20 bootstrap samples. As the Gaussian model uses',\n",
       " 'As the Gaussian model uses\\nunimodal distributions to ﬁt the features data and the dataset was composed of features\\nmodeled as bimodal Gaussian distributions, the Gaussian NB classiﬁer presented a high Figure 5 shows the rejection fraction and accuracy with the\\nincreasing number of training samples for both models. with 20 bootstrap samples.',\n",
       " 'unimodal distributions to ﬁt the features data and the dataset was composed of features\\nmodeled as bimodal Gaussian distributions, the Gaussian NB classiﬁer presented a high\\nrejection fraction due to aleatoric uncertainty, since the overlap between the ﬁt distributions\\nwas high. Contrarily, the KDE Bayes classiﬁer deals well with bimodal distributions, which',\n",
       " 'Contrarily, the KDE Bayes classiﬁer deals well with bimodal distributions, which\\nresulted in a low overlap between classes, obtaining a low rejection fraction due to aleatoric\\nuncertainty. rejection fraction due to aleatoric uncertainty, since the overlap between the ﬁt distributions\\nwas high. Regarding model uncertainty, although both models started with a high',\n",
       " 'Regarding model uncertainty, although both models started with a high\\nrejection fraction, the Gaussian NB reached 105training samples with almost zero rejection,\\nand the KDE model, due to its complexity, still had a 10% rejection rate, approximately. resulted in a low overlap between classes, obtaining a low rejection fraction due to aleatoric\\nuncertainty. In',\n",
       " 'rejection fraction, the Gaussian NB reached 105training samples with almost zero rejection,\\nand the KDE model, due to its complexity, still had a 10% rejection rate, approximately. In\\nsummary, the Gaussian NB had high aleatoric uncertainty and low model uncertainty, and\\nthe KDE Bayes classiﬁer had low aleatoric uncertainty and high model uncertainty.',\n",
       " 'To verify the potential for combining both models using uncertainty measures, the\\nfollowing combination rules were applied:\\n summary, the Gaussian NB had high aleatoric uncertainty and low model uncertainty, and\\nthe KDE Bayes classiﬁer had low aleatoric uncertainty and high model uncertainty.\\n ˆw=8\\n>>>><\\n>>>>:fc1(x) ifFc1(x) =0 and Fc2(x)>0\\nfc2(x) ifFc1(x)>0 and Fc2(x) =0',\n",
       " '=0\\nfc1(x) ifFc1(x) =0 and Fc2(x) =0 and fc1(x) = fc2(x)\\nreject otherwise(16)\\nwhere c1and c2represent the Gaussian NB and KDE Bayes classiﬁer and Fcis the uncer-\\ntainty function deﬁned in Equation (14). following combination rules were applied:\\n ˆw=8\\n>>>><\\n>>>>:fc1(x) ifFc1(x) =0 and Fc2(x)>0\\nfc2(x) ifFc1(x)>0 and Fc2(x)',\n",
       " 'To validate that the proposed combination strategy performed better than the individual\\nmodels, we applied the performance measures proposed in the work of Condessa et al. fc1(x) ifFc1(x) =0 and Fc2(x) =0 and fc1(x) = fc2(x)\\nreject otherwise(16)\\nwhere c1and c2represent the Gaussian NB and KDE Bayes classiﬁer and Fcis the uncer-\\ntainty function deﬁned in Equation (14).\\n [33] .',\n",
       " 'To validate that the proposed combination strategy performed better than the individual\\nmodels, we applied the performance measures proposed in the work of Condessa et al. To compare the performance of the classifiers with rejection, 10% of the rejected samples were\\nused with the highest training size available ( \\x1890,000 training samples). [33] .\\n',\n",
       " 'To compare the performance of the classifiers with rejection, 10% of the rejected samples were\\nused with the highest training size available ( \\x1890,000 training samples).\\n In Table 2, the obtained results for the three models using a 10% rejection fraction\\nare shown. The combination strategy using the uncertainties of both individual modelsElectronics 2022 ,11, 396 13 of 20',\n",
       " 'The combination strategy using the uncertainties of both individual modelsElectronics 2022 ,11, 396 13 of 20\\nresulted in higher values for the three performance measures for classiﬁers with rejection,\\nnamely the nonrejected accuracy, classiﬁcation quality, and rejection quality.\\n 0.00.20.4Rejection Fraction\\nGuassian Naive Bayes\\n KDE Model\\nAleatoric\\nModel\\n103104105 are shown.',\n",
       " '0.00.20.4Rejection Fraction\\nGuassian Naive Bayes\\n KDE Model\\nAleatoric\\nModel\\n103104105\\n# train samples0.70.80.9Accuracy\\n103104105\\n# train samples\\nBaseline\\nNRA\\nFigure 5. Uncertainties’ rejection fraction and obtained accuracies using a k-fold cross-validation namely the nonrejected accuracy, classiﬁcation quality, and rejection quality.\\n',\n",
       " 'Uncertainties’ rejection fraction and obtained accuracies using a k-fold cross-validation\\nwith an increasing number of training samples for Gaussian NB and KDE Bayes models.\\n These preliminary results showed that the access to uncertainty estimations during Aleatoric\\nModel\\n103104105\\n# train samples0.70.80.9Accuracy\\n103104105\\n# train samples\\nBaseline\\nNRA\\nFigure 5.',\n",
       " 'These preliminary results showed that the access to uncertainty estimations during\\nthe model’s development might be a useful source of information to develop more robust\\nmodels. with an increasing number of training samples for Gaussian NB and KDE Bayes models.\\n Although a simpler model, such as an NB classiﬁer, can have a lower performance',\n",
       " 'Although a simpler model, such as an NB classiﬁer, can have a lower performance\\nin comparison with more complex models, the use of uncertainty estimations can provide\\ninformation about the speciﬁc regions where the model has low uncertainty. the model’s development might be a useful source of information to develop more robust\\nmodels. Using this',\n",
       " 'in comparison with more complex models, the use of uncertainty estimations can provide\\ninformation about the speciﬁc regions where the model has low uncertainty. Using this\\ninformation in combination with more powerful models can in fact increase the overall\\nmodel performance.\\n Performance measures for individual models (Gaussian naive Bayes and KDE Bayes) and Table 2.',\n",
       " 'The results were obtained using a rejection fraction of 10% and a\\ntraining size of 90,000 samples.\\n information in combination with more powerful models can in fact increase the overall\\nmodel performance.\\n Performance measures for individual models (Gaussian naive Bayes and KDE Bayes) and\\na combination of both models. ModelNonrejected Classiﬁcation Rejection\\nAccuracy Quality Quality Table 2.',\n",
       " 'ModelNonrejected Classiﬁcation Rejection\\nAccuracy Quality Quality\\nGaussian Naive Bayes 0.72 0.72 2.60\\nKDE Bayes 0.85 0.82 5.84\\nModel’s Combination 0.86 0.83 6.89\\n4.1.3. The results were obtained using a rejection fraction of 10% and a\\ntraining size of 90,000 samples.\\n a combination of both models. Uncertainty Visualization (Q3)',\n",
       " 'Uncertainty Visualization (Q3)\\nTo use ML in high-stakes applications, we need auditing tools to build conﬁdence in\\nthe models and their decisions. ModelNonrejected Classiﬁcation Rejection\\nAccuracy Quality Quality\\nGaussian Naive Bayes 0.72 0.72 2.60\\nKDE Bayes 0.85 0.82 5.84\\nModel’s Combination 0.86 0.83 6.89\\n4.1.3. Besides quantiﬁcation metrics, visualization techniques',\n",
       " 'To use ML in high-stakes applications, we need auditing tools to build conﬁdence in\\nthe models and their decisions. Therefore, to answer\\nthis question, we quantiﬁed the different sources of uncertainty using visualization methods Besides quantiﬁcation metrics, visualization techniques\\nhave been used to support the interpretability of classiﬁcation models.',\n",
       " 'Therefore, to answer\\nthis question, we quantiﬁed the different sources of uncertainty using visualization methods\\nto assist in interpreting the models’ uncertainty during model development and also to\\naudit a given decision.\\n For uncertainty visualization, the dataset from Section 4.1.2 with a training size of have been used to support the interpretability of classiﬁcation models.',\n",
       " 'To simulate a realistic real-world setting, some outliers were addedElectronics 2022 ,11, 396 14 of 20 to assist in interpreting the models’ uncertainty during model development and also to\\naudit a given decision.\\n For uncertainty visualization, the dataset from Section 4.1.2 with a training size of\\n2.6\\x02104was used.',\n",
       " 'To simulate a realistic real-world setting, some outliers were addedElectronics 2022 ,11, 396 14 of 20\\nto the test set. These outliers were generated from a Gaussian distribution that had a\\ncovariance matrix that is four-times larger than that of the dataset itself. Fifty outliers per\\nclass were generated, resulting in a total of 300 outliers. 2.6\\x02104was used.',\n",
       " 'In Figure 6, an overview of the uncertainty estimation obtained during the model’s\\ndevelopment is shown. covariance matrix that is four-times larger than that of the dataset itself. Fifty outliers per\\nclass were generated, resulting in a total of 300 outliers.\\n In this visualization, the x-axis represents the number of samples',\n",
       " 'Using this ordering scheme, it was possible\\nto interpret the overall dataset uncertainty (upper bar), as well as the proportion of the In Figure 6, an overview of the uncertainty estimation obtained during the model’s\\ndevelopment is shown. In this visualization, the x-axis represents the number of samples\\nwhere samples are ordered by uncertainty.',\n",
       " 'Using this ordering scheme, it was possible\\nto interpret the overall dataset uncertainty (upper bar), as well as the proportion of the\\ndifferent sources of uncertainty across the dataset (lower bars). The size of each bar\\nrepresents the number of samples rejected by each type of uncertainty. where samples are ordered by uncertainty. Furthermore, this',\n",
       " 'Furthermore, this\\nvisualization allowed us to make some observations, such as noting that all rejected samples\\nby model uncertainty were also rejected by aleatoric uncertainty.\\n0.0 0.2 0.4 0.6 0.8 1.0\\n# Samples1e4Uncertain The size of each bar\\nrepresents the number of samples rejected by each type of uncertainty. different sources of uncertainty across the dataset (lower bars).',\n",
       " 'Overview of the overall dataset uncertainty ( upper bar ) and uncertainties distribution by\\nthe uncertainty source ( lower bars ). by model uncertainty were also rejected by aleatoric uncertainty.\\n0.0 0.2 0.4 0.6 0.8 1.0\\n# Samples1e4Uncertain\\n0.0 1.0 2.0 3.0 4.0 5.0\\n# Uncertain Samples1e3Aleatoric\\nModel\\nKnowledge\\nFigure 6.',\n",
       " 'Overview of the overall dataset uncertainty ( upper bar ) and uncertainties distribution by\\nthe uncertainty source ( lower bars ).\\n Analyzing the\\nuncertainty by each class can give us insights about the particular limitations of the model Similarly, this representation can be applied to each individual class. # Uncertain Samples1e3Aleatoric\\nModel\\nKnowledge\\nFigure 6.',\n",
       " 'Analyzing the\\nuncertainty by each class can give us insights about the particular limitations of the model\\nbeing used. Note that almost all samples with knowledge uncertainty from Figure 6 were the generated Similarly, this representation can be applied to each individual class. Figure 7 presents the obtained uncertainty by uncertainty source and class.\\n',\n",
       " 'Note that almost all samples with knowledge uncertainty from Figure 6 were the generated\\noutliers and do not have a representation in Figure 7.\\n0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Samples1e3Class 0\\n0.0 1.0 2.0 3.0 4.0 5.0 6.0\\n# Figure 7 presents the obtained uncertainty by uncertainty source and class.\\n Uncertain Samples1e20.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Samples1e3Class 1 being used.',\n",
       " 'Samples1e3Class 2\\nUncertain\\n0.0 2.0 4.0 6.0 8.0\\n# Uncertain Samples1e2Aleatoric\\nModel\\nKnowledge\\n0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Samples1e3Class 3 Uncertain Samples1e20.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Samples1e3Class 1\\n0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0\\n# Uncertain Samples1e20.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# 0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Samples1e3Class 0\\n0.0 1.0 2.0 3.0 4.0 5.0 6.0\\n#',\n",
       " '# Samples1e3Class 2\\nUncertain\\n0.0 2.0 4.0 6.0 8.0\\n# Uncertain Samples1e2Aleatoric\\nModel\\nKnowledge\\n0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Samples1e3Class 3\\n Uncertain Samples1e20.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Samples1e3Class 5\\n0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0\\n# Uncertain Samples1e2 0.0 2.0 4.0 6.0 8.0\\n# Uncertain Samples1e20.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Samples1e3Class 4\\n0.0 2.0 4.0 6.0 8.0\\n#',\n",
       " 'Besides the visualization applied to the overall classiﬁer’s uncertainty, an alternative Uncertainty distribution by uncertainty source and class.\\n # Samples1e3Class 4\\n0.0 2.0 4.0 6.0 8.0\\n# Uncertain Samples1e20.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Samples1e3Class 5\\n0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0\\n# Uncertain Samples1e2\\nFigure 7.',\n",
       " 'Besides the visualization applied to the overall classiﬁer’s uncertainty, an alternative\\nis to audit the reliability of a given prediction, answering questions such as: Can I trust this\\nprediction? Why did I reject this sample?Electronics 2022 ,11, 396 15 of 20 Uncertainty distribution by uncertainty source and class.\\n # Uncertain Samples1e2\\nFigure 7.',\n",
       " 'Why did I reject this sample?Electronics 2022 ,11, 396 15 of 20\\nFor this purpose, using the uncertainty estimations for each type of uncertainty,\\nFigure 8 was obtained. is to audit the reliability of a given prediction, answering questions such as: Can I trust this\\nprediction? In this visualization, the bar’s size represents how much the',\n",
       " 'In this visualization, the bar’s size represents how much the\\nmodel is conﬁdent or uncertain about a prediction by uncertainty type. For this purpose, using the uncertainty estimations for each type of uncertainty,\\nFigure 8 was obtained. To make the\\nvisualization more intuitive, 0 conﬁdence/uncertainty represents the obtained threshold',\n",
       " 'Then, the bars’ sizes where normalized between 0 and 1 by the\\nmaximum/minimum theoretical value for each uncertainty.\\n To make the\\nvisualization more intuitive, 0 conﬁdence/uncertainty represents the obtained threshold\\nfor rejecting a sample. Note that, in the aleatoric uncertainty, we visualize the prediction’s expected data model is conﬁdent or uncertain about a prediction by uncertainty type.',\n",
       " 'Note that, in the aleatoric uncertainty, we visualize the prediction’s expected data\\nentropy, meaning that in Figure 8a, the prediction probability was near 100% (entropy of 0).\\n In the case of Figure 8b, the obtained entropy was greater than the deﬁned threshold for maximum/minimum theoretical value for each uncertainty.\\n',\n",
       " 'In the case of Figure 8b, the obtained entropy was greater than the deﬁned threshold for\\nrejection and its value represents approximately 1/3 of the entropies that range between\\n1 and the rejection threshold. entropy, meaning that in Figure 8a, the prediction probability was near 100% (entropy of 0).\\n In the case of model uncertainty, we evaluated if a given',\n",
       " 'In the case of model uncertainty, we evaluated if a given\\nprediction changes between different bootstrap samples, i.e., the bar’s size represents the\\nnormalized variation ratios. rejection and its value represents approximately 1/3 of the entropies that range between\\n1 and the rejection threshold. In Figure 8a, the prediction was the same in all bootstrap',\n",
       " 'In Figure 8a, the prediction was the same in all bootstrap\\nsamples, obtaining a maximum conﬁdence value, and in Figure 8b, the prediction changed\\nhalf the total number of possibilities, which are given by the number of bootstrap samples prediction changes between different bootstrap samples, i.e., the bar’s size represents the\\nnormalized variation ratios.',\n",
       " 'For instance, this dataset had 6 classes and 20 bootstrap samples\\nwere used, meaning that the maximum variation ratio was 0.8, and the prediction from samples, obtaining a maximum conﬁdence value, and in Figure 8b, the prediction changed\\nhalf the total number of possibilities, which are given by the number of bootstrap samples\\nand the number of classes.',\n",
       " 'For instance, this dataset had 6 classes and 20 bootstrap samples\\nwere used, meaning that the maximum variation ratio was 0.8, and the prediction from\\nFigure 8b obtained a variation ratio of 0.4. Finally, the knowledge uncertainty represents\\nhow much a prediction is similar to the training dataset, in terms of probability density. and the number of classes.',\n",
       " 'Thus, Figure 8a represents a prediction where the combination of the features density\\nresulted in a KDE value close to the rejection threshold, i.e., few training samples were Finally, the knowledge uncertainty represents\\nhow much a prediction is similar to the training dataset, in terms of probability density.\\n Figure 8b obtained a variation ratio of 0.4.',\n",
       " 'Thus, Figure 8a represents a prediction where the combination of the features density\\nresulted in a KDE value close to the rejection threshold, i.e., few training samples were\\nsimilar to this prediction. In the case of Figure 8b, the sample was more similar to the\\nsamples in the training dataset.\\n1.0\\n 0.5\\n 0.0 0.5 1.0\\nConfidenceMore\\nConfidentMore\\nUncertainAleatoric\\nModel',\n",
       " 'In the case of Figure 8b, the sample was more similar to the\\nsamples in the training dataset.\\n1.0\\n 0.5\\n 0.0 0.5 1.0\\nConfidenceMore\\nConfidentMore\\nUncertainAleatoric\\nModel\\nKnowledgePredicted Class: 0\\n(a)\\n1.0\\n 0.5\\n 0.0 0.5 1.0\\nConfidenceMore\\nConfidentMore\\nUncertainAleatoric\\nModel\\nKnowledgePredicted Class: 4 (b) similar to this prediction.',\n",
       " 'A conﬁdence value of 0 represents the obtained threshold for reject-\\ning a sample by the uncertainty source. Bars’ sizes are normalized between the maximum theoretical ConfidenceMore\\nConfidentMore\\nUncertainAleatoric\\nModel\\nKnowledgePredicted Class: 0\\n(a)\\n1.0\\n 0.5\\n 0.0 0.5 1.0\\nConfidenceMore\\nConfidentMore\\nUncertainAleatoric\\nModel\\nKnowledgePredicted Class: 4 (b)\\nFigure 8. Prediction uncertainty.',\n",
       " 'Dataset\\nIn order to broaden our analysis, we conducted an additional experiment with a Bars’ sizes are normalized between the maximum theoretical\\nconﬁdence/uncertainty. ( a) Prediction not rejected by all uncertainty sources. ( b) Prediction rejected\\nby aleatoric and model uncertainty.\\n4.2. ing a sample by the uncertainty source.',\n",
       " 'Dataset\\nIn order to broaden our analysis, we conducted an additional experiment with a\\nbenchmark dataset from the UCI repository [ 38]. As a case study, we selected a Human\\nActivity Recognition (HAR) dataset [39] that contains six classes ( walking ,walking upstairs , by aleatoric and model uncertainty.\\n4.2. Experiments on a Human Activity Recognition',\n",
       " '[39] that contains six classes ( walking ,walking upstairs ,\\nwalking downstairs ,sitting ,standing , and laying ), recorded with the accelerometer and\\ngyroscope smartphone sensors. As a case study, we selected a Human\\nActivity Recognition (HAR) dataset Besides the importance of UQ for trustworthy ML systems, benchmark dataset from the UCI repository [ 38].',\n",
       " 'Besides the importance of UQ for trustworthy ML systems,\\nthe use of uncertainty measures for human movements analysis plays also an important role\\nin the recognition of abnormal human activities or the analysis, diagnosis, and monitoring walking downstairs ,sitting ,standing , and laying ), recorded with the accelerometer and\\ngyroscope smartphone sensors.',\n",
       " 'the use of uncertainty measures for human movements analysis plays also an important role\\nin the recognition of abnormal human activities or the analysis, diagnosis, and monitoring\\nof neurodegenerative conditions [ 40]. Furthermore, the high number of available samples\\n(10,299 samples) in this dataset allowed us to make a similar evaluation to the synthetic',\n",
       " 'Furthermore, the high number of available samples\\n(10,299 samples) in this dataset allowed us to make a similar evaluation to the synthetic\\ndata. For the data split into training and test sets, we used the available partition in the\\nrepository, where 70% of the volunteers were selected for generating the training data and of neurodegenerative conditions [ 40].',\n",
       " 'For the data split into training and test sets, we used the available partition in the\\nrepository, where 70% of the volunteers were selected for generating the training data and\\n30% the test data. Regarding the feature vector, the original 561-feature vector with time\\nand frequency domain variables was reduced using features correlation and the sequential data.',\n",
       " 'Electronics 2022 ,11, 396 16 of 20\\nSimilar to Section 4.1.1, we applied a training size exponential growth, starting with Regarding the feature vector, the original 561-feature vector with time\\nand frequency domain variables was reduced using features correlation and the sequential\\nforward feature selector, resulting in a 17-dimensional feature vector. 30% the test data.',\n",
       " 'Electronics 2022 ,11, 396 16 of 20\\nSimilar to Section 4.1.1, we applied a training size exponential growth, starting with\\n300 samples (50 per class) until the maximum training size of 7352 samples. For model\\ntraining, we tested different classiﬁers with 20 bootstrap samples. forward feature selector, resulting in a 17-dimensional feature vector. Table 3 shows the',\n",
       " 'Table 3 shows the\\nobtained baseline accuracy, as well as the nonrejected accuracy and the rejection fraction for\\neach of the tested classiﬁers. 300 samples (50 per class) until the maximum training size of 7352 samples. For model\\ntraining, we tested different classiﬁers with 20 bootstrap samples. To visualize the behavior of accuracy and the corresponding',\n",
       " 'To visualize the behavior of accuracy and the corresponding\\nrejection fraction for each type of uncertainty, we selected the 4 models that obtained higher\\nbaseline accuracy. obtained baseline accuracy, as well as the nonrejected accuracy and the rejection fraction for\\neach of the tested classiﬁers. Figure 9 shows these performance measures with the increased number',\n",
       " 'Performance measures for different models using a training size of 7352 samples and the\\nHuman Activity Recognition (HAR) dataset.\\n rejection fraction for each type of uncertainty, we selected the 4 models that obtained higher\\nbaseline accuracy. Figure 9 shows these performance measures with the increased number\\nof samples used to train the classiﬁers.\\n ModelBaseline Nonrejected Rejection Table 3.',\n",
       " 'ModelBaseline Nonrejected Rejection\\nAccuracy Accuracy Fraction\\nGaussian Naive Bayes 0.89 0.90 0.03\\nKDE Bayes 0.88 0.92 0.12\\nLogistic Regression 0.89 0.92 0.06\\nDecision Tree 0.82 0.92 0.23\\nRandom Forest 0.84 0.91 0.16\\nk-Nearest Neighbors 0.87 0.94 0.13 Performance measures for different models using a training size of 7352 samples and the\\nHuman Activity Recognition (HAR) dataset.\\n Table 3.',\n",
       " 'Gaussian Naive Bayes 0.89 0.90 0.03\\nKDE Bayes 0.88 0.92 0.12\\nLogistic Regression 0.89 0.92 0.06\\nDecision Tree 0.82 0.92 0.23\\nRandom Forest 0.84 0.91 0.16\\nk-Nearest Neighbors 0.87 0.94 0.13\\nSupport Vector Machines 0.91 0.93 0.06\\n0.00.10.20.3Rejection Fraction\\nGuassian Naive Bayes\\n KDE Bayes\\n Support Vector Machines\\n Logistic Regression\\nAleatoric\\nModel\\nKnowledge\\n103104',\n",
       " 'Support Vector Machines 0.91 0.93 0.06\\n0.00.10.20.3Rejection Fraction\\nGuassian Naive Bayes\\n KDE Bayes\\n Support Vector Machines\\n Logistic Regression\\nAleatoric\\nModel\\nKnowledge\\n103104\\n# train samples0.800.850.900.951.00Accuracy\\n103104\\n# train samples\\n103104\\n# train samples\\n103104\\n# train samples\\nBaseline\\nNRA',\n",
       " 'Uncertainties’ rejection fraction and obtained accuracies with the increasing number of\\ntraining samples for the Human Activity Recognition (HAR) dataset. Logistic Regression\\nAleatoric\\nModel\\nKnowledge\\n103104\\n# train samples0.800.850.900.951.00Accuracy\\n103104\\n# train samples\\n103104\\n# train samples\\n103104\\n# train samples\\nBaseline\\nNRA\\nFigure 9.',\n",
       " 'For the HAR dataset, the rejection fraction obtained with both the aleatoric and\\nknowledge uncertainty measures presented a low value for all training sizes and classiﬁers Uncertainties’ rejection fraction and obtained accuracies with the increasing number of\\ntraining samples for the Human Activity Recognition (HAR) dataset.\\n 103104\\n# train samples\\nBaseline\\nNRA\\nFigure 9.',\n",
       " 'For the HAR dataset, the rejection fraction obtained with both the aleatoric and\\nknowledge uncertainty measures presented a low value for all training sizes and classiﬁers\\nbeing analyzed. As expected, regarding the model uncertainty, the rejection fraction\\ndecreased with the increasing number of training samples for all classiﬁers, where more',\n",
       " 'As expected, regarding the model uncertainty, the rejection fraction\\ndecreased with the increasing number of training samples for all classiﬁers, where more\\ncomplex classiﬁers had a higher rejection fraction than simpler classiﬁers. Due to the low\\nobtained uncertainty (rejection fraction < 4%) and satisfactory accuracy (baseline accuracy being analyzed.',\n",
       " 'Due to the low\\nobtained uncertainty (rejection fraction < 4%) and satisfactory accuracy (baseline accuracy\\nof 89%), the Gaussian NB classiﬁer was selected.\\n Using the visualization scheme presented in Section 4.1.3, Figure 10 shows the overall complex classiﬁers had a higher rejection fraction than simpler classiﬁers.',\n",
       " 'Using the visualization scheme presented in Section 4.1.3, Figure 10 shows the overall\\ndataset uncertainty and the uncertainty type distribution across the uncertain samples.\\n Although only 4% of the test samples were rejected, we can make some observations about of 89%), the Gaussian NB classiﬁer was selected.\\n',\n",
       " 'Although only 4% of the test samples were rejected, we can make some observations about\\nthe uncertain samples. The majority of uncertain samples rejected by aleatoric uncertainty\\nwere also rejected by model uncertainty. dataset uncertainty and the uncertainty type distribution across the uncertain samples.\\n Regions with an overlap between classes (aleatoric',\n",
       " 'Regions with an overlap between classes (aleatoric\\nuncertainty) were also regions where it was expected that the model ﬁt would change\\nbetween bootstrap samples. The majority of uncertain samples rejected by aleatoric uncertainty\\nwere also rejected by model uncertainty. In the case of knowledge uncertainty, it was expected that the uncertain samples.',\n",
       " 'However, forElectronics 2022 ,11, 396 17 of 20\\nmodel uncertainty, it is possible that some samples shared both model and knowledge uncertainty) were also regions where it was expected that the model ﬁt would change\\nbetween bootstrap samples. In the case of knowledge uncertainty, it was expected that\\nsamples with knowledge uncertainty would not have aleatoric uncertainty.',\n",
       " 'model uncertainty, it is possible that some samples shared both model and knowledge\\nuncertainty, which is also veriﬁed with Figure 10.\\n0.0 0.5 1.0 1.5 2.0 2.5\\n# Samples1e3Uncertain\\n0.0 0.2 0.4 0.6 0.8 1.0\\n# Uncertain Samples1e2Aleatoric\\nModel\\nKnowledge\\nFigure 10. Figure 11 shows the uncertainty distribution by class. From it, we can conclude that HAR dataset uncertainty overview.\\n',\n",
       " 'From it, we can conclude that\\naleatoric uncertainty was presented only in walking ,walking upstairs and walking downstairs ,\\nwhich makes perfect sense due to the similarity of these three classes. Figure 11 shows the uncertainty distribution by class. # Uncertain Samples1e2Aleatoric\\nModel\\nKnowledge\\nFigure 10. It is also possible to HAR dataset uncertainty overview.\\n',\n",
       " 'aleatoric uncertainty was presented only in walking ,walking upstairs and walking downstairs ,\\nwhich makes perfect sense due to the similarity of these three classes. It is also possible to\\nnote that laying class did not have aleatoric or model uncertainty. However, it was the class\\nwith the highest knowledge uncertainty. Both sitting and standing classes had a similar',\n",
       " 'Both sitting and standing classes had a similar\\npattern in terms of uncertainty, where the sitting class was the one with the highest number\\nof uncertain samples.\\n note that laying class did not have aleatoric or model uncertainty. However, it was the class\\nwith the highest knowledge uncertainty. 0.0 1.0 2.0 3.0 4.0\\n# Samples1e2Walking\\n0.0 1.0 2.0 3.0 4.0 5.0\\n# Uncertain Samples0.0 1.0 2.0 3.0 4.0',\n",
       " '0.0 1.0 2.0 3.0 4.0\\n# Samples1e2Walking\\n0.0 1.0 2.0 3.0 4.0 5.0\\n# Uncertain Samples0.0 1.0 2.0 3.0 4.0\\n# Samples1e2Walking Upstairs\\n0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Uncertain Samples1e10.0 1.0 2.0 3.0 4.0\\n# Samples1e2Walking Downstairs\\nUncertain\\n0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0\\n# Uncertain SamplesAleatoric\\nModel\\nKnowledge\\n0.0 1.0 2.0 3.0 4.0\\n# Samples1e2Sitting of uncertain samples.\\n',\n",
       " '# Samples1e2Walking Downstairs\\nUncertain\\n0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0\\n# Uncertain SamplesAleatoric\\nModel\\nKnowledge\\n0.0 1.0 2.0 3.0 4.0\\n# Samples1e2Sitting\\n0.0 1.0 2.0 3.0 4.0\\n# Uncertain Samples1e10.0 1.0 2.0 3.0 4.0 5.0\\n# Samples1e2Standing\\n0.0 0.5 1.0 1.5 2.0\\n# Uncertain Samples1e10.0 1.0 2.0 3.0 4.0 5.0\\n# Samples1e2Laying\\n0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8 2.0\\n# Uncertain Samples1e1',\n",
       " 'To validate the combination strategy proposed in Section 4.1.2 using a real dataset,\\nwe decided to combine the two models with lower accuracy and higher uncertainty. # Samples1e2Standing\\n0.0 0.5 1.0 1.5 2.0\\n# Uncertain Samples1e10.0 1.0 2.0 3.0 4.0 5.0\\n# Samples1e2Laying\\n0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8 2.0\\n# Uncertain Samples1e1\\nFigure 11. HAR dataset uncertainty overview by class.\\n Thus,',\n",
       " 'To validate the combination strategy proposed in Section 4.1.2 using a real dataset,\\nwe decided to combine the two models with lower accuracy and higher uncertainty. Thus,\\nthe KDE Bayes model and logistic regression were combined for the different training\\nsizes. To compare the performance of classiﬁers with rejection, we needed to ensure',\n",
       " 'Thus, the obtained rejection fraction\\nfor the models’ combination, given by Equation (16), was employed for both the KDE To compare the performance of classiﬁers with rejection, we needed to ensure\\nthe same rejection fraction for the three classiﬁers. the KDE Bayes model and logistic regression were combined for the different training\\nsizes.',\n",
       " 'Thus, the obtained rejection fraction\\nfor the models’ combination, given by Equation (16), was employed for both the KDE\\nBayes and logistic regression classiﬁers. Figure 12 shows the performance measures for\\nclassiﬁcation with rejection for the individual models and their combination. the same rejection fraction for the three classiﬁers. Observing',\n",
       " 'Observing\\nthe results, we can conclude that the combination strategy outperformed the individual\\nclassiﬁers for almost all training sizes and performance measures. Figure 12 shows the performance measures for\\nclassiﬁcation with rejection for the individual models and their combination. Bayes and logistic regression classiﬁers. It is also interesting',\n",
       " 'It is also interesting\\nto note that the combination strategy resulted always in a lower rejection fraction thanElectronics 2022 ,11, 396 18 of 20\\nthe obtained rejection fraction for the individual classiﬁers, which can be conﬁrmed by the results, we can conclude that the combination strategy outperformed the individual\\nclassiﬁers for almost all training sizes and performance measures.',\n",
       " 'the obtained rejection fraction for the individual classiﬁers, which can be conﬁrmed by\\nanalyzing Figures 9 and 12.\\n103104\\n# train samples0.8000.8250.8500.8750.9000.9250.950Nonrejected Accuracy\\n103104\\n# train samples0.800.820.840.860.880.90Classification Quality\\n103104\\n# train samples2.55.07.510.012.515.0Rejection Quality\\n103104\\n# train samples0.020.040.060.08Rejection Fraction',\n",
       " \"103104\\n# train samples0.800.820.840.860.880.90Classification Quality\\n103104\\n# train samples2.55.07.510.012.515.0Rejection Quality\\n103104\\n# train samples0.020.040.060.08Rejection Fraction\\nKDE Bayes Logistic Regression Models' Combination\\nFigure 12. Performance measures for classiﬁcation with rejection for different training sizes.\\n Conclusions 5.\",\n",
       " \"Conclusions\\nAs ML models are increasingly being integrated into safety-critical applications, in-\\ncorporating uncertainty quantiﬁcation estimates should become a required part of the ML Performance measures for classiﬁcation with rejection for different training sizes.\\n KDE Bayes Logistic Regression Models' Combination\\nFigure 12. 5.\",\n",
       " 'Conclusions\\nAs ML models are increasingly being integrated into safety-critical applications, in-\\ncorporating uncertainty quantiﬁcation estimates should become a required part of the ML\\nmethodology. Uncertainty quantiﬁcation can be used for “uncertainty-informed” decisions\\nand to support developers and end-users by increasing the interpretability of and trust in\\nmodel predictions. 5.',\n",
       " 'We introduced a complete study focused on how uncertainty quantiﬁcation can be\\nused in practice through three research questions: (1) How can UQ contribute to choosing Uncertainty quantiﬁcation can be used for “uncertainty-informed” decisions\\nand to support developers and end-users by increasing the interpretability of and trust in\\nmodel predictions.\\n methodology.',\n",
       " 'We introduced a complete study focused on how uncertainty quantiﬁcation can be\\nused in practice through three research questions: (1) How can UQ contribute to choosing\\nthe most suitable model for a given classiﬁcation task? (2) Can UQ be used to combine\\ndifferent models in a principled manner? (3) Can visualization techniques improve UQ’s model predictions.\\n',\n",
       " 'These questions were answered using a synthetic dataset and a HAR\\ndataset from the UCI repository.\\n (2) Can UQ be used to combine\\ndifferent models in a principled manner? Regarding the ﬁrst question, we showed that uncertainty quantiﬁcation in combination the most suitable model for a given classiﬁcation task? (3) Can visualization techniques improve UQ’s\\ninterpretability?',\n",
       " 'Regarding the ﬁrst question, we showed that uncertainty quantiﬁcation in combination\\nwith the model’s accuracy can give us important elements to choose the most suitable\\nmodel. For instance, the decision between different classiﬁers with the same accuracy\\ncan beneﬁt from the uncertainty quantiﬁcation methods, whereas classiﬁers with lower dataset from the UCI repository.\\n',\n",
       " 'For instance, the decision between different classiﬁers with the same accuracy\\ncan beneﬁt from the uncertainty quantiﬁcation methods, whereas classiﬁers with lower\\ndegrees of uncertainty can be preferable. Furthermore, if model uncertainty is high and the\\naddition of new samples is possible, the increase of training samples can reduce the model model.',\n",
       " 'By using uncertainty as a\\ncomplement of performance measures, we can make more informed decisions in model Furthermore, if model uncertainty is high and the\\naddition of new samples is possible, the increase of training samples can reduce the model\\nuncertainty and consequently increase the model’s accuracy. degrees of uncertainty can be preferable.',\n",
       " 'By using uncertainty as a\\ncomplement of performance measures, we can make more informed decisions in model\\nselection. In future work, we will explore how the UQ measures can be used in the context\\nof active learning. Active learning is the subset of ML in which the learning algorithm uncertainty and consequently increase the model’s accuracy.',\n",
       " 'The choice of the samples to be labeled is achieved\\nthrough measures that rank samples based on their potential informativeness. In future work, we will explore how the UQ measures can be used in the context\\nof active learning. Active learning is the subset of ML in which the learning algorithm\\nqueries users to label training data. Alternative selection.',\n",
       " 'The choice of the samples to be labeled is achieved\\nthrough measures that rank samples based on their potential informativeness. Based on two models with different degrees of uncertainty, we proposed a naive Alternative\\nor complementary ranking measures based on uncertainty can be explored.\\n queries users to label training data.',\n",
       " 'Based on two models with different degrees of uncertainty, we proposed a naive\\nuncertainty combination approach for models’ combination to answer the second question.\\n or complementary ranking measures based on uncertainty can be explored.\\n The preliminary results showed that the combination strategy outperformed the individual',\n",
       " 'Although the proposed naive approach achieved good results, the combination\\nstrategy presented some limitations for its application in a scenario with more than two uncertainty combination approach for models’ combination to answer the second question.\\n The preliminary results showed that the combination strategy outperformed the individual\\nmodels.',\n",
       " 'Although the proposed naive approach achieved good results, the combination\\nstrategy presented some limitations for its application in a scenario with more than two\\nmodels. A more versatile combination that considers the possibility of adding more\\nmodels and uses their degree of uncertainty must be developed. Therefore, for future models.',\n",
       " 'A more versatile combination that considers the possibility of adding more\\nmodels and uses their degree of uncertainty must be developed. Therefore, for future\\nwork, we will explore more comprehensive model combination methods to address more\\ncomplex problems.\\n In the third question, we explored visualization techniques to assist in interpreting models.',\n",
       " 'In the third question, we explored visualization techniques to assist in interpreting\\nclassiﬁers’ uncertainty during the model’s development and also to audit a given decision.\\n work, we will explore more comprehensive model combination methods to address more\\ncomplex problems.\\n Understanding which type of uncertainty is present during the model’s development can',\n",
       " 'Understanding which type of uncertainty is present during the model’s development can\\ngive us insights into the limitations of each model and allow us to take actions in accordance.\\n In the context of prediction reliability, the proposed visualization techniques were used to classiﬁers’ uncertainty during the model’s development and also to audit a given decision.\\n',\n",
       " 'In the context of prediction reliability, the proposed visualization techniques were used to\\naccess the interpretability of the rejection option in which a rejection may correspond to\\na low prediction probability (aleatoric uncertainty), a poor model ﬁt (model uncertainty), give us insights into the limitations of each model and allow us to take actions in accordance.\\n',\n",
       " 'As a limitation of our study, we identify that anElectronics 2022 ,11, 396 19 of 20\\nindividual rejection threshold for each source of uncertainty may not be a reliable solution access the interpretability of the rejection option in which a rejection may correspond to\\na low prediction probability (aleatoric uncertainty), a poor model ﬁt (model uncertainty),\\nor an outlier (knowledge uncertainty).',\n",
       " 'Our\\nfuture research on this topic will focus on understanding how optimization techniques\\ncan be used to establish the most adequate rejection thresholds, either individually or by individual rejection threshold for each source of uncertainty may not be a reliable solution\\nfor every ML problem. Deﬁning the best rejection threshold is still an open challenge.',\n",
       " 'future research on this topic will focus on understanding how optimization techniques\\ncan be used to establish the most adequate rejection thresholds, either individually or by\\nunifying the three quantiﬁcation measures.\\n We hope this paper might spark future research on how to consider uncertainty\\nquantiﬁcation as a tool to improve the ML model development lifecycle.',\n",
       " 'We hope this paper might spark future research on how to consider uncertainty\\nquantiﬁcation as a tool to improve the ML model development lifecycle.\\n Author Contributions: Conceptualization, M.B. and H.G.; methodology, M.B., D.F. and H.G.;\\nsoftware, M.B.; validation, M.B., D.F. and H.G.; investigation, M.B., D.F., R.S. (Ricardo Santos), unifying the three quantiﬁcation measures.\\n',\n",
       " 'Author Contributions: Conceptualization, M.B. and H.G.; methodology, M.B., D.F. and H.G.;\\nsoftware, M.B.; validation, M.B., D.F. and H.G.; investigation, M.B., D.F., R.S. (Ricardo Santos),\\nR.S. (Raquel Simão) and H.G.; writing—original draft preparation, M.B. and D.F.; writing— review\\nand editing, M.B., D.F., R.S. (Ricardo Santos), R.S. (Raquel Simão) and H.G.; visualization,',\n",
       " 'R.S. (Raquel Simão) and H.G.; writing—original draft preparation, M.B. and D.F.; writing— review\\nand editing, M.B., D.F., R.S. (Ricardo Santos), R.S. (Raquel Simão) and H.G.; visualization,\\nR.S. (Ricardo Santos) and M.B.; supervision, H.G. All authors have read and agreed to the published\\nversion of the manuscript.',\n",
       " 'This research was ﬁnancially supported by the project Geolocation non-Assisted by GPS\\nfor Mobile Networks in Indoor and Outdoor Environment (GARMIO), co-funded by Portugal 2020, All authors have read and agreed to the published\\nversion of the manuscript.\\n R.S. (Ricardo Santos) and M.B.; supervision, H.G. Funding:',\n",
       " 'This research was ﬁnancially supported by the project Geolocation non-Assisted by GPS\\nfor Mobile Networks in Indoor and Outdoor Environment (GARMIO), co-funded by Portugal 2020,\\nframed under the COMPETE 2020 (Operational Programme Competitiveness and Internationaliza-\\ntion) and European Regional Development Fund (ERDF) from European Union (EU), with Operation Funding:',\n",
       " 'framed under the COMPETE 2020 (Operational Programme Competitiveness and Internationaliza-\\ntion) and European Regional Development Fund (ERDF) from European Union (EU), with Operation\\nCode POCI-01-0247-FEDER-033479.\\n Institutional Review Board Statement: Not applicable\\nInformed Consent Statement: Not applicable.',\n",
       " 'These data can\\nbe found at the UC Irvine Machine Learning Repository, available at https://archive.ics.uci.edu/ml/ Data Availability Statement: Publicly available datasets were analyzed in this study. Institutional Review Board Statement: Not applicable\\nInformed Consent Statement: Not applicable.\\n Code POCI-01-0247-FEDER-033479.\\n',\n",
       " 'These data can\\nbe found at the UC Irvine Machine Learning Repository, available at https://archive.ics.uci.edu/ml/\\ndatasets/human+activity+recognition+using+smartphones (accessed on 20 December 2021).\\n Data Availability Statement: Publicly available datasets were analyzed in this study. The authors declare no conﬂict of interest.\\nReferences Conﬂicts of Interest:',\n",
       " 'Cobb, A.D.; Jalaian, B.; Bastian, N.D.; Russell, S. Toward Safe Decision-Making via Uncertainty Quantiﬁcation in Machine datasets/human+activity+recognition+using+smartphones (accessed on 20 December 2021).\\n The authors declare no conﬂict of interest.\\n Conﬂicts of Interest: References\\n1.',\n",
       " 'Cobb, A.D.; Jalaian, B.; Bastian, N.D.; Russell, S. Toward Safe Decision-Making via Uncertainty Quantiﬁcation in Machine\\nLearning. In Systems Engineering and Artiﬁcial Intelligence ; Springer: Berlin/Heidelberg, Germany, 2021; pp. The authors declare no conﬂict of interest.\\n Conﬂicts of Interest: 379–399.',\n",
       " 'In Systems Engineering and Artiﬁcial Intelligence ; Springer: Berlin/Heidelberg, Germany, 2021; pp. Senge, R.; Bösner, S.; Dembczy´ nski, K.; Haasenritter, J.; Hirsch, O.; Donner-Banzhoff, N.; Hüllermeier, E. Reliable classiﬁcation:\\n Learning classiﬁers that distinguish aleatoric and epistemic uncertainty. Inf. Sci. 2014 ,255, 16–29. 379–399.\\n',\n",
       " 'Hüllermeier, E.; Waegeman, W. Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and Learning classiﬁers that distinguish aleatoric and epistemic uncertainty. Inf. Sci. 2014 ,255, 16–29. Communicating uncertainty in medical machine learning. NPJ Digit.\\nMed. 2021 ,4, 1–6.',\n",
       " 'Hüllermeier, E.; Waegeman, W. Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and\\nmethods. [CrossRef]\\n5. Huang, Z.; Lam, H.; Zhang, H. Quantifying Epistemic Uncertainty in Deep Learning. Learn. 2021 ,110, 457–506. arXiv 2021 , arXiv:2110.12122. [CrossRef] [PubMed]\\n4.',\n",
       " 'Holzinger, A.; Langs, G.; Denk, H.; Zatloukal, K.; Müller, H. Causability and explainability of artiﬁcial intelligence in medicine.\\n [CrossRef]\\n5. Huang, Z.; Lam, H.; Zhang, H. Quantifying Epistemic Uncertainty in Deep Learning. Learn. 2021 ,110, 457–506. Rev. Data Min. Knowl. arXiv 2021 , arXiv:2110.12122.\\n',\n",
       " '[CrossRef] [PubMed]\\n7. Nguyen, V .L.; Shaker, M.H.; Hüllermeier, E. How to measure uncertainty in uncertainty sampling for active learning. [CrossRef]\\n8. Bota, P .; Silva, J.; Folgado, D.; Gamboa, H. A semi-automatic annotation approach for human activity recognition. Mach.\\nLearn. 2021 , 1–34. Rev. Data Min. Knowl. Wiley Interdiscip.',\n",
       " '[CrossRef]\\n8. Bota, P .; Silva, J.; Folgado, D.; Gamboa, H. A semi-automatic annotation approach for human activity recognition. Ghosh, S.; Liao, Q.V .; Ramamurthy, K.N.; Navratil, J.; Sattigeri, P .; Varshney, K.R.; Zhang, Y. Uncertainty Quantiﬁcation 360: A Sensors 2019 ,\\n19, 501. Learn. 2021 , 1–34. [CrossRef] [PubMed]\\n9.',\n",
       " 'Ghosh, S.; Liao, Q.V .; Ramamurthy, K.N.; Navratil, J.; Sattigeri, P .; Varshney, K.R.; Zhang, Y. Uncertainty Quantiﬁcation 360: A\\nHolistic Toolkit for Quantifying and Communicating the Uncertainty of AI. arXiv 2021 , arXiv:2106.01410. [CrossRef] [PubMed]\\n9. 19, 501.',\n",
       " 'Chung, Y.; Char, I.; Guo, H.; Schneider, J.; Neiswanger, W. Uncertainty toolbox: An open-source library for assessing, visualizing,\\nand improving uncertainty quantiﬁcation. Holistic Toolkit for Quantifying and Communicating the Uncertainty of AI. arXiv 2021 , arXiv:2109.10254. arXiv 2021 , arXiv:2106.01410.\\n 10.',\n",
       " 'Choudhary, S.; Fehr, J.; Leite, A.W.; Goldschmidt, P .G.; Johner, C.; Schörverth, E.D.;\\nNakasi, R.; et al. Machine Learning for Health: Algorithm Auditing & Quality Control. and improving uncertainty quantiﬁcation. arXiv 2021 , arXiv:2109.10254.\\n Oala, L.; Murchison, A.G.; Balachandran, P .;',\n",
       " 'An overview of advances in reliability estimation of individual predictions in machine learning. Machine Learning for Health: Algorithm Auditing & Quality Control. Data Anal. 2009 ,13, 385–401. Syst. 2021 ,45, 1–8.\\n12. Nakasi, R.; et al.',\n",
       " 'An overview of advances in reliability estimation of individual predictions in machine learning. Tornede, A.; Gehring, L.; Tornede, T.; Wever, M.; Hüllermeier, E. Algorithm selection on a meta level. Data Anal. 2009 ,13, 385–401. arXiv 2021 , arXiv:2107.09414. Bosni´ c, Z.; Kononenko, I.',\n",
       " 'Explainable Matrix-Visualization for Global and Local Interpretability of Random Forest Classiﬁcation\\nEnsembles. Tornede, A.; Gehring, L.; Tornede, T.; Wever, M.; Hüllermeier, E. Algorithm selection on a meta level. Data Anal. 2009 ,13, 385–401. Graph. 2020 ,27, 1427–1437. arXiv 2021 , arXiv:2107.09414.\\n',\n",
       " 'Shaker, M.H.; Hüllermeier, E. Ensemble-based Uncertainty Quantification: Bayesian versus Credal Inference. arXiv 2020 , arXiv:2006.10562.Electronics 2022 ,11, 396 20 of 20 Malinin, A.; Prokhorenkova, L.; Ustimenko, A. Uncertainty in gradient boosting via ensembles. Graph. 2020 ,27, 1427–1437. arXiv 2021, arXiv:2107.10384.\\n',\n",
       " 'Depeweg, S.; Hernandez-Lobato, J.M.; Doshi-Velez, F.; Udluft, S. Decomposition of uncertainty in Bayesian deep learning for arXiv 2020 , arXiv:2006.10562.Electronics 2022 ,11, 396 20 of 20\\n17. Malinin, A.; Prokhorenkova, L.; Ustimenko, A. Uncertainty in gradient boosting via ensembles. 16.',\n",
       " 'Depeweg, S.; Hernandez-Lobato, J.M.; Doshi-Velez, F.; Udluft, S. Decomposition of uncertainty in Bayesian deep learning for\\nefﬁcient and risk-sensitive learning. In Proceedings of the International Conference on Machine Learning, Stockholm, Sweden,\\n10–15 July 2018; pp. 1184–1193. 17.',\n",
       " 'In Proceedings of the International Conference on Machine Learning, Stockholm, Sweden,\\n10–15 July 2018; pp. Shaker, M.H.; Hüllermeier, E. Aleatoric and epistemic uncertainty with random forests. efﬁcient and risk-sensitive learning. arXiv 2020 , arXiv:2001.00893. 1184–1193.\\n',\n",
       " 'Efron, B.; Tibshirani, R. Bootstrap methods for standard errors, conﬁdence intervals, and other measures of statistical accuracy.\\n Shaker, M.H.; Hüllermeier, E. Aleatoric and epistemic uncertainty with random forests. 10–15 July 2018; pp. Sci. 1986 ,1, 54–75. arXiv 2020 , arXiv:2001.00893.\\n',\n",
       " '[CrossRef]\\n20. Stracuzzi, D.J.; Darling, M.C.; Peterson, M.G.; Chen, M.G. Quantifying Uncertainty to Improve Decision Making in Machine Learning ;\\nTechnical Report; Sandia National Lab. Efron, B.; Tibshirani, R. Bootstrap methods for standard errors, conﬁdence intervals, and other measures of statistical accuracy.\\n (SNL-NM): Albuquerque, NM, USA, 2018. Sci. 1986 ,1, 54–75. Stat.',\n",
       " 'Mena, J.; Pujol, O.; Vitrià, J. Uncertainty-based rejection wrappers for black-box classiﬁers. Geng, C.; Huang, S.j.; Chen, S. Recent advances in open set recognition: A survey. Technical Report; Sandia National Lab. IEEE Access 2020 ,8, 101721–101746.\\n (SNL-NM): Albuquerque, NM, USA, 2018.\\n',\n",
       " 'Geng, C.; Huang, S.j.; Chen, S. Recent advances in open set recognition: A survey. Background Check: A general technique to build more reliable Perello-Nieto, M.; Telmo De Menezes Filho, E.S.; Kull, M.; Flach, P . 2020 ,43,\\n3614–3631. Pattern Anal.',\n",
       " 'In Proceedings of the 2016 IEEE 16th International Conference on Data Mining (ICDM), Barcelona, Spain,\\n12–15 December 2016; pp. Background Check: A general technique to build more reliable\\nand versatile classiﬁers. Perello-Nieto, M.; Telmo De Menezes Filho, E.S.; Kull, M.; Flach, P . 1143–1148. [CrossRef]\\n23.',\n",
       " 'In Proceedings of the 2016 IEEE 16th International Conference on Data Mining (ICDM), Barcelona, Spain,\\n12–15 December 2016; pp. Pires, C.; Barandas, M.; Fernandes, L.; Folgado, D.; Gamboa, H. Towards Knowledge Uncertainty Estimation for Open Set\\nRecognition. Extr. 2020 ,2, 505–532. and versatile classiﬁers. 1143–1148.\\n',\n",
       " 'Pires, C.; Barandas, M.; Fernandes, L.; Folgado, D.; Gamboa, H. Towards Knowledge Uncertainty Estimation for Open Set\\nRecognition. Chow, C. On optimum recognition error and reject tradeoff. Theory 1970 ,16, 41–46. Extr. 2020 ,2, 505–532. IEEE Trans.',\n",
       " 'Chow, C. On optimum recognition error and reject tradeoff. Growing a multi-class classiﬁer with a reject option. Theory 1970 ,16, 41–46. 2008 ,29, 1565–1570. Extr. 2020 ,2, 505–532.',\n",
       " 'Fumera, G.; Roli, F.; Giacinto, G. Reject option with multiple thresholds. Growing a multi-class classiﬁer with a reject option. 2000 ,33, 2099–2101. 2008 ,29, 1565–1570. Pattern Recognit.',\n",
       " '[CrossRef]\\n28. Hanczar, B. Performance visualization spaces for classiﬁcation with rejection option. Fumera, G.; Roli, F.; Giacinto, G. Reject option with multiple thresholds. Optimal strategies for reject option classiﬁers. 2000 ,33, 2099–2101. arXiv 2021 , arXiv:2101.12523.',\n",
       " 'In Proceedings of the International Conference on Machine Learning, Virtual, 13–15 April 2021; pp. Charoenphakdee, N.; Cui, Z.; Zhang, Y.; Sugiyama, M. Classiﬁcation with rejection based on cost-sensitive classiﬁcation.\\n Optimal strategies for reject option classiﬁers. arXiv 2021 , arXiv:2101.12523.\\n Franc, V .; Prusa, D.; Voracek, V .',\n",
       " 'In Proceedings of the International Conference on Machine Learning, Virtual, 13–15 April 2021; pp. Nadeem, M.S.A.; Zucker, J.D.; Hanczar, B. Accuracy-rejection curves (ARCs) for comparing classiﬁcation methods with a Ph.D. Dissertation, University of Cambridge, Cambridge, UK, 2016.\\n Gal, Y. Uncertainty in Deep Learning. 1507–1517.\\n',\n",
       " 'In Proceedings of the third International Workshop on Machine Learning in Systems Biology, Ljubljana, Slovenia,\\n5–6 September 2009; pp. Nadeem, M.S.A.; Zucker, J.D.; Hanczar, B. Accuracy-rejection curves (ARCs) for comparing classiﬁcation methods with a\\nreject option. 65–81. 32.',\n",
       " 'In Proceedings of the third International Workshop on Machine Learning in Systems Biology, Ljubljana, Slovenia,\\n5–6 September 2009; pp. Condessa, F.; Bioucas-Dias, J.; Kovaˇ cevi´ c, J. Performance measures for classiﬁcation systems with rejection. 2017 ,\\n63, 437–450. Pattern Recognit. 65–81.\\n',\n",
       " '[CrossRef]\\n34. Kläs, M. Towards identifying and managing sources of uncertainty in AI and machine learning models-an overview. Condessa, F.; Bioucas-Dias, J.; Kovaˇ cevi´ c, J. Performance measures for classiﬁcation systems with rejection. 2017 ,\\n63, 437–450. arXiv 2018 ,\\narXiv:1811.11669. 5–6 September 2009; pp.',\n",
       " '[CrossRef]\\n34. Kläs, M. Towards identifying and managing sources of uncertainty in AI and machine learning models-an overview. Campagner, A.; Cabitza, F.; Ciucci, D. Three-way decision for handling uncertainty in machine learning: A narrative review. arXiv 2018 ,\\narXiv:1811.11669.\\n 63, 437–450. 35.',\n",
       " 'Campagner, A.; Cabitza, F.; Ciucci, D. Three-way decision for handling uncertainty in machine learning: A narrative review.\\n InInternational Joint Conference on Rough Sets ; Springer: Berlin/Heidelberg, Germany, 2020; pp. Sambyal, A.S.; Krishnan, N.C.; Bathula, D.R. Towards Reducing Aleatoric Uncertainty for Medical Imaging Tasks. arXiv 2021 ,\\narXiv:2110.11012. arXiv:1811.11669.\\n',\n",
       " 'Sambyal, A.S.; Krishnan, N.C.; Bathula, D.R. Towards Reducing Aleatoric Uncertainty for Medical Imaging Tasks. Fischer, L.; Hammer, B.; Wersing, H. Optimal local rejection for classiﬁers. Neurocomputing 2016 ,214, 445–457. arXiv 2021 ,\\narXiv:2110.11012.\\n [CrossRef]',\n",
       " 'Dua, D.; Graff, C. UCI Machine Learning Repository ; University of California, School of Information and Computer Science: Irvine,\\nCA, USA, 2019. Available online: http://archive.ics.uci.edu/ml (accessed on 20 December 2021). Fischer, L.; Hammer, B.; Wersing, H. Optimal local rejection for classiﬁers. Neurocomputing 2016 ,214, 445–457. arXiv:2110.11012.\\n',\n",
       " 'Available online: http://archive.ics.uci.edu/ml (accessed on 20 December 2021).\\n Buckley, C.; Alcock, L.; McArdle, R.; Rehman, R.Z.U.; Del Din, S.; Mazzà, C.; Yarnall, A.J.; Rochester, L. A public domain dataset for human activity recognition using\\nsmartphones. Anguita, D.; Ghio, A.; Oneto, L.; Parra, X.; Reyes-Ortiz, J.L. The role of movement',\n",
       " 'The role of movement\\nanalysis in diagnosing and monitoring neurodegenerative conditions: Insights from gait and postural control. Buckley, C.; Alcock, L.; McArdle, R.; Rehman, R.Z.U.; Del Din, S.; Mazzà, C.; Yarnall, A.J.; Rochester, L. Brain Sci. 2019 ,\\n9, 34. Esann 2013 ,3, 3.\\n40. [CrossRef] [PubMed]']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e_summary(text_chunk,5) for text_chunk in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarthak mohapatra\\AppData\\Local\\Temp\\ipykernel_7148\\2494437653.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  similarity = np.dot(doc_vec, sent_vec) / (np.linalg.norm(doc_vec) * np.linalg.norm(sent_vec))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence scores: [0.99947023, 0.80939084, nan]\n",
      "Sentence scores: [0.99211246, 0.82807434, 0.9802796, nan]\n",
      "Sentence scores: [0.67325246, 0.6103508, nan, 0.69972456, 0.9201282, nan]\n",
      "Sentence scores: [0.7820894, nan, 0.7820894, 0.6594528, 0.7422658, nan]\n",
      "Sentence scores: [0.5454428, 0.79852057]\n",
      "Sentence scores: [0.79786557, 0.9068147]\n",
      "Sentence scores: [0.99999994]\n",
      "Sentence scores: [0.9770924, 0.87155986, nan]\n",
      "Sentence scores: [0.89672434, 0.92039704, 0.76441383]\n",
      "Sentence scores: [0.7820894, 0.79997367, 0.5034795]\n",
      "Sentence scores: [0.22614604, 0.9422839, 0.9422839, 0.85001063, nan]\n",
      "Sentence scores: [0.6488466, 0.96481526, 0.7002124, 0.93999326, nan]\n",
      "Sentence scores: [0.9546417, 0.6629174, nan]\n",
      "Sentence scores: [0.7820894, 0.9444478]\n",
      "Sentence scores: [0.79193854, 0.90538454, 0.9132318, nan]\n",
      "Sentence scores: [0.98018295, 0.8315373, 0.8315373, 0.54578584]\n",
      "Sentence scores: [0.7992118, 0.7992118, 0.840493, 0.28111786]\n",
      "Sentence scores: [0.7426404, 0.8022276, 0.91748565]\n",
      "Sentence scores: [0.56677777, 0.91748565, 0.943453, nan]\n",
      "Sentence scores: [0.79921174, 0.9289726, 0.9491272, nan]\n",
      "Sentence scores: [0.9897011, 0.59624285, 0.9473925, nan]\n",
      "Sentence scores: [0.44093192, 0.9897028, 0.9473887, 0.8923655]\n",
      "Sentence scores: [0.9800949, 0.9920772, nan]\n",
      "Sentence scores: [0.9756241, 0.8540528, 0.9696535]\n",
      "Sentence scores: [0.813342, 0.813342, 0.47928742]\n",
      "Sentence scores: [0.43403983, 0.9769413]\n",
      "Sentence scores: [0.9756241, 0.4409319, nan]\n",
      "Sentence scores: [0.94886005, 0.94886005, 0.89285594, nan]\n",
      "Sentence scores: [0.46727863, 0.94046676, 0.88882345, 0.85610974]\n",
      "Sentence scores: [nan, 0.90649176, 0.86012906, nan]\n",
      "Sentence scores: [nan, 0.90492606, 0.90492606, 0.86923754, nan]\n",
      "Sentence scores: [0.94886005, 0.94886005, 0.89285594, nan]\n",
      "Sentence scores: [0.876898, 0.7852588, 0.876898, 0.93047434, 0.43159044]\n",
      "Sentence scores: [0.86059344, 0.91906977, 0.91906977, 0.18784578, 0.75575405, nan]\n",
      "Sentence scores: [0.6455267, 0.64494187, 0.8596663, nan]\n",
      "Sentence scores: [0.9630355, 0.574249, nan, nan]\n",
      "Sentence scores: [0.83153737, 0.83153737, 0.98018306, 0.5457859]\n",
      "Sentence scores: [0.5000965, 0.9558616, 0.9686096, 0.84481245]\n",
      "Sentence scores: [0.98193157, 0.925478, 0.8740723]\n",
      "Sentence scores: [0.84121585, 0.94206357]\n",
      "Sentence scores: [0.59697413, 0.8727716, 0.67747957, nan]\n",
      "Sentence scores: [0.9117487, 0.7814106, 0.7814106, 0.97290605, 0.5859363, nan]\n",
      "Sentence scores: [0.7814106, 0.97290605, 0.97290605, 0.9117488, nan]\n",
      "Sentence scores: [0.5823395, 0.91467005, 0.9666501, 0.78410655]\n",
      "Sentence scores: [0.78412277, 0.95985293, 0.6429252]\n",
      "Sentence scores: [0.91401184, 0.9159025, 0.9670739, 0.39807004]\n",
      "Sentence scores: [0.64331514, 0.985044, 0.7752947, 0.63723874]\n",
      "Sentence scores: [0.42394438, 0.76505643, 0.8153379]\n",
      "Sentence scores: [0.97875834, 0.870175, nan, 0.86930573]\n",
      "Sentence scores: [0.6558715, nan, 0.95328474, 0.71296847, 0.8560797]\n",
      "Sentence scores: [0.7814106, 0.8786218, 0.7967105, 0.5859363]\n",
      "Sentence scores: [0.7239541, 0.9260649, 0.68795586]\n",
      "Sentence scores: [0.9800949, 0.9920772, nan]\n",
      "Sentence scores: [0.9755242, 0.68363667, 0.93662685]\n",
      "Sentence scores: [0.5823395, 0.9623427, 0.9714671, 0.78410655]\n",
      "Sentence scores: [1.0, 1.0, 0.7050237, 0.700958]\n",
      "Sentence scores: [0.4654496, 0.4654496, 0.9037947, 0.8656328]\n",
      "Sentence scores: [0.4983958, 0.9543397, 0.7495159]\n",
      "Sentence scores: [0.93102854, 0.8717468, 0.36505958, nan]\n",
      "Sentence scores: [0.38847008, 0.56957805, 0.81485796, 0.72646224]\n",
      "Sentence scores: [0.49026212, 0.993931]\n",
      "Sentence scores: [0.9924606, 0.45847744]\n",
      "Sentence scores: [0.6999839, 0.9541514, 0.85089266]\n",
      "Sentence scores: [0.40820843, 0.7519251, 0.8135993]\n",
      "Sentence scores: [0.5087678, 0.89921814, 0.8977036]\n",
      "Sentence scores: [0.8007739, 0.9849694, 0.69421995]\n",
      "Sentence scores: [0.5340713, 0.8228029, 0.9528743]\n",
      "Sentence scores: [0.23901843, 0.99485755]\n",
      "Sentence scores: [0.9284892, 0.9346246]\n",
      "Sentence scores: [0.9760671, 0.92039716, nan]\n",
      "Sentence scores: [0.7991434, 0.98973405, 0.7991434, 0.98973405, 0.5918303]\n",
      "Sentence scores: [0.69198793, 0.98595977, 0.9246517, 0.98595977]\n",
      "Sentence scores: [0.85488755, 0.92539746, 0.92539746, 0.81752604]\n",
      "Sentence scores: [0.7197371, 0.98757297, nan]\n",
      "Sentence scores: [0.8720849, 0.85457486, 0.8873601, 0.7648066]\n",
      "Sentence scores: [0.8514858, 0.8680675, 0.9437356, 0.7243559]\n",
      "Sentence scores: [0.959305, 0.91988665, 0.7984407]\n",
      "Sentence scores: [0.5707904, 0.99389625, 0.6544913]\n",
      "Sentence scores: [0.9877603, 0.9976829, 0.9337714]\n",
      "Sentence scores: [0.96447873, 0.8693106, 0.38303483]\n",
      "Sentence scores: [0.9159025, 0.98515993, 0.9670739]\n",
      "Sentence scores: [0.9450046, 0.8242379]\n",
      "Sentence scores: [0.947663, 0.9656055]\n",
      "Sentence scores: [0.8792063, 0.82476085, nan]\n",
      "Sentence scores: [0.74443406, 0.78214794, 0.9069409, 0.5272975]\n",
      "Sentence scores: [0.11870626, 0.9924717]\n",
      "Sentence scores: [1.0]\n",
      "Sentence scores: [0.94500476, 0.8320539, 0.7806708]\n",
      "Sentence scores: [0.57619697, 0.7806708, 0.9450046, 0.5937146]\n",
      "Sentence scores: [0.974566, 0.9931255]\n",
      "Sentence scores: [0.9912173, 0.97900915]\n",
      "Sentence scores: [0.93816507, 0.97893226, 0.89927447, 0.39390635]\n",
      "Sentence scores: [0.44490024, 0.8954883, 0.8473478, 0.7956684, 0.78765154]\n",
      "Sentence scores: [0.95201975, 0.95201975, 0.74737597]\n",
      "Sentence scores: [0.9005122, 0.66212684, 0.34927434]\n",
      "Sentence scores: [0.95051825, 0.96659654, nan]\n",
      "Sentence scores: [0.67194414, 0.87366086, 0.6752199, 0.5894839]\n",
      "Sentence scores: [0.7258869, 0.8116009, 0.73052835, 0.40342093]\n",
      "Sentence scores: [0.73760384, 0.73760384, 0.8362381, 0.94659334, 0.63395435]\n",
      "Sentence scores: [0.7697528, 0.99171585, 0.9603961]\n",
      "Sentence scores: [0.9640517, 0.9450671]\n",
      "Sentence scores: [0.9827927, 0.9470259]\n",
      "Sentence scores: [0.8525125, 0.98160243, 0.8542202]\n",
      "Sentence scores: [0.79921174, 0.9289726, 0.79921174, 0.53450674]\n",
      "Sentence scores: [0.5093231, 0.5093231, 0.9403721]\n",
      "Sentence scores: [0.974226, 0.8804728, 0.30875316, nan]\n",
      "Sentence scores: [0.7475946, 0.48125413, 0.48125413, 0.75905514, 0.69471616]\n",
      "Sentence scores: [0.32519382, 0.7111367, 0.818552, 0.9082719]\n",
      "Sentence scores: [0.25843823, 0.99227285, 0.89083034]\n",
      "Sentence scores: [0.92547786, 0.92547786, 0.88059694]\n",
      "Sentence scores: [0.89054394, 0.96830076]\n",
      "Sentence scores: [0.86691946, 0.9806502]\n",
      "Sentence scores: [1.0]\n",
      "Sentence scores: [0.8262739, 0.96844167]\n",
      "Sentence scores: [0.96892416, 0.9805885]\n",
      "Sentence scores: [0.9798033, 0.39136964, 0.81533736, 0.79773605]\n",
      "Sentence scores: [0.6925936, 0.14520171, 0.9744176, 0.89565235, 0.9206219, 0.6925936, nan]\n",
      "Sentence scores: [0.6118491, 0.967173, 0.6118491, 0.90116626, 0.76985085]\n",
      "Sentence scores: [0.55019593, 0.9920772, 0.82859737]\n",
      "Sentence scores: [0.44093192, 0.9897028, 0.8923655]\n",
      "Sentence scores: [0.996459, 0.99823314]\n",
      "Sentence scores: [0.9840199, 0.9688058, 0.9558616]\n",
      "Sentence scores: [0.926823, 0.852739, 0.50711447, 0.7501208]\n",
      "Sentence scores: [0.53031963, 0.56046325, 0.92549497, 0.76441383]\n",
      "Sentence scores: [0.8661949, 0.98088646, 0.8592333]\n",
      "Sentence scores: [0.7447723, 0.94448256]\n",
      "Sentence scores: [0.9609856, 0.6533861, 0.70712495]\n",
      "Sentence scores: [0.67747957, 0.62711966, 0.89825654, 0.66007096]\n",
      "Sentence scores: [0.84121585, 0.94206357, nan]\n",
      "Sentence scores: [0.54453343, 0.92132616]\n",
      "Sentence scores: [0.9952953, 0.97998583]\n",
      "Sentence scores: [0.925478, 0.9819316, 0.8740723]\n",
      "Sentence scores: [0.40075052, 0.9450046, 0.903997]\n",
      "Sentence scores: [0.5826429, 0.903997, 0.40075052, 0.8242378]\n",
      "Sentence scores: [0.4904917, 0.965008, 0.84055305]\n",
      "Sentence scores: [0.96517855, 0.98635274, nan]\n",
      "Sentence scores: [0.8958464, 0.749761]\n",
      "Sentence scores: [0.53648156, 0.8091159, 0.8341991]\n",
      "Sentence scores: [0.9783288, 0.9104154]\n",
      "Sentence scores: [0.8662494, 0.86945885, 0.38526365]\n",
      "Sentence scores: [0.9065626, 0.8972227]\n",
      "Sentence scores: [0.23122573, 0.97552997]\n",
      "Sentence scores: [0.96560556, 0.82504666, 0.78495955]\n",
      "Sentence scores: [0.3366319, 0.76574206, 0.9220187]\n",
      "Sentence scores: [1.0, nan]\n",
      "Sentence scores: [0.9999999]\n",
      "Sentence scores: [0.5716164, 0.78265643, 0.46288386, 0.6380205]\n",
      "Sentence scores: [0.6541017, 0.6541017, 0.79121697, 0.78681403]\n",
      "Sentence scores: [0.7694697, 0.85894144, 0.5982928]\n",
      "Sentence scores: [0.9421726, 0.8167808, nan]\n",
      "Sentence scores: [0.6900276, 0.7131425]\n",
      "Sentence scores: [0.6849101, 0.92982745, 0.95256734, nan]\n",
      "Sentence scores: [0.83864516, 0.82902586, 0.91808903, 0.28864828]\n",
      "Sentence scores: [0.86043465, 0.7034474, 0.56007963]\n",
      "Sentence scores: [0.6663521, 0.9755242, 0.9260649]\n",
      "Sentence scores: [0.36390582, 0.996459, 0.92715204]\n",
      "Sentence scores: [0.99517936, 0.94506717]\n",
      "Sentence scores: [0.47921264, 0.92547786, 0.8740722]\n",
      "Sentence scores: [0.4204886, 0.9765042, 0.9132914, 0.8602309]\n",
      "Sentence scores: [0.55112225, 0.9679211, 0.98535174, 0.7485218]\n",
      "Sentence scores: [0.55112225, 0.98535174, 0.98535174, nan]\n",
      "Sentence scores: [0.8261531, 0.8430886, 0.9580687, 0.8430886, 0.8430886]\n",
      "Sentence scores: [0.42924613, 0.37359828, 0.42924613, 0.42924613, 0.9045634]\n",
      "Sentence scores: [0.97421604, 0.9732189]\n",
      "Sentence scores: [1.0000001]\n",
      "Sentence scores: [0.60673255, 0.90322083, 0.8683957]\n",
      "Sentence scores: [0.9874387, 0.86509985]\n",
      "Sentence scores: [0.9139386, 0.9191376, 0.95639807]\n",
      "Sentence scores: [0.7560387, 0.97207475, 0.34771764]\n",
      "Sentence scores: [0.9664049, 0.9664049, 0.74178714, 0.82188344]\n",
      "Sentence scores: [0.94904107, 0.82881176, 0.8822756, 0.6281902]\n",
      "Sentence scores: [0.97474664, 0.5787523, 0.97474664, 0.7729359]\n",
      "Sentence scores: [0.39697504, 0.85019064, 0.8609222]\n",
      "Sentence scores: [0.24898869, 0.98798764, 0.9053697]\n",
      "Sentence scores: [0.9093883, 0.98427624, 0.6131129]\n",
      "Sentence scores: [0.5345879, 0.9210275, 0.7466929]\n",
      "Sentence scores: [0.8397601, 0.8575025, 0.6158289, 0.5647238]\n",
      "Sentence scores: [0.80586666, 0.6520082, 0.96251833, 0.6637892, 0.30297694]\n",
      "Sentence scores: [0.8390546, 0.94194037, 0.7377638, 0.8390546, 0.6906484, 0.48430473]\n",
      "Sentence scores: [0.6774795, 0.59697413, 0.89825654, 0.64133364]\n",
      "Sentence scores: [0.40075052, 0.9450047, 0.903997]\n",
      "Sentence scores: [0.45090398, 0.91575843, 0.45090398, 0.7290348]\n",
      "Sentence scores: [0.7290401, 0.8290367, 0.80765206, 0.7290401, nan]\n",
      "Sentence scores: [0.9596775, 0.52767974, 0.7656173]\n",
      "Sentence scores: [0.8828348, 0.8666666]\n",
      "Sentence scores: [0.65171176, 0.8491715, 0.869538, 0.6349864]\n",
      "Sentence scores: [0.84776974, 0.99440885, 0.9301046]\n",
      "Sentence scores: [0.9947919, 0.97389144, 0.95293653]\n",
      "Sentence scores: [0.8927114, 0.94443244, 0.22591153]\n",
      "Sentence scores: [0.48403215, 0.8436328]\n",
      "Sentence scores: [0.6703156, 0.7514558, 0.6305351]\n",
      "Sentence scores: [0.6621268, 0.9656054, 0.9519308, 0.9476629]\n",
      "Sentence scores: [0.77064854, 0.9491272, 0.7992118, 0.53450674]\n",
      "Sentence scores: [0.50957036, 0.932486, 0.5462223]\n",
      "Sentence scores: [0.70115966, 0.8672223, 0.81353533]\n",
      "Sentence scores: [0.4355293, 0.95971924, 0.96298325, 0.8314252]\n",
      "Sentence scores: [0.37400013, 0.9662149, 0.8882363, 0.8762731]\n",
      "Sentence scores: [0.9473887, 1.0, 0.8923655]\n",
      "Sentence scores: [0.52767974, 0.94646466, 0.837189]\n",
      "Sentence scores: [0.42840257, 0.9819315, 0.8740722]\n",
      "Sentence scores: [0.22589846, 0.97176605]\n",
      "Sentence scores: [0.9905814, 0.98088646]\n",
      "Sentence scores: [0.9026069, 0.7980037, 0.7795387, 0.8414964]\n",
      "Sentence scores: [0.89441544, 0.9477574, nan, nan]\n",
      "Sentence scores: [nan, nan, nan, nan]\n",
      "Sentence scores: [nan, nan, nan, nan, nan, nan]\n",
      "Sentence scores: [nan, nan, nan]\n",
      "Sentence scores: [0.72424173, 0.99999994, 0.6921949]\n",
      "Sentence scores: [0.5639009, 0.9159024, 0.91401184, 0.66776603]\n",
      "Sentence scores: [0.5843505, 0.993686, 0.92862695, nan]\n",
      "Sentence scores: [0.9473887, 0.9473887, 0.8923655]\n",
      "Sentence scores: [0.69972456, 0.9201282, 0.9272882, nan]\n",
      "Sentence scores: [0.580492, 0.88820624, 0.9054085, 0.76318944]\n",
      "Sentence scores: [0.89054406, 0.9779249, 0.8740723]\n",
      "Sentence scores: [0.43972856, 0.8701748, 0.8693057]\n",
      "Sentence scores: [0.51544166, 0.9758688, 0.94701105, nan]\n",
      "Sentence scores: [0.7120945, 0.6734376, 0.8339381, 0.26850778]\n",
      "Sentence scores: [0.82591754, 0.80483234, 0.45464432]\n",
      "Sentence scores: [0.47965524, 0.9905814, 0.8592333]\n",
      "Sentence scores: [0.9006772, 0.9824043, 0.85417]\n",
      "Sentence scores: [0.9763227, 0.94294524, 0.71383053, nan]\n",
      "Sentence scores: [0.8167808, 0.8167808, 0.57227534]\n",
      "Sentence scores: [0.9640517, 0.9450671]\n",
      "Sentence scores: [0.8097395, 0.9973037, 0.9209045]\n",
      "Sentence scores: [0.84345216, 0.9794505, nan]\n",
      "Sentence scores: [0.99528927, 0.9738914]\n",
      "Sentence scores: [0.15414722, 0.11870148, 0.9514036, nan]\n",
      "Sentence scores: [nan, 0.9958729, 0.99635184]\n",
      "Sentence scores: [0.97934425, 0.15631837, 0.2832939]\n",
      "Sentence scores: [0.9132318, 0.79193854, 0.90538454]\n",
      "Sentence scores: [0.8645391, 0.87756795, 0.7466929]\n",
      "Sentence scores: [0.44093192, 0.9756241, nan]\n",
      "Sentence scores: [0.9005122, 0.66212684, 0.34927434]\n",
      "Sentence scores: [0.90261924, 0.95052266, nan]\n",
      "Sentence scores: [0.4778643, 0.8010418, 0.82748246]\n",
      "Sentence scores: [0.69738996, 0.94670445, nan]\n",
      "Sentence scores: [0.80978113, 0.8827414, 0.8827414, 0.38484678]\n",
      "Sentence scores: [0.7908628, 0.7908628, 0.8706661, 0.85867715, nan]\n",
      "Sentence scores: [0.9221113, 0.8727116, 0.6860516, 0.32443333]\n",
      "Sentence scores: [0.66074824, 0.9261685, 0.55438006]\n",
      "Sentence scores: [0.9473887, 0.9473887, 0.8923655]\n",
      "Sentence scores: [0.47965524, 0.9905814, 0.8592333]\n",
      "Sentence scores: [0.7492968, 0.9845043, 0.8599648]\n",
      "Sentence scores: [0.6270155, 0.8962308, 0.8421926, 0.99202085]\n",
      "Sentence scores: [0.6774795, 0.9177006, 0.9079364, 0.66007096]\n",
      "Sentence scores: [0.8588401, 0.8842766, 0.8585977]\n",
      "Sentence scores: [0.6158289, 0.9206463, 0.6158289, 0.56472373]\n",
      "Sentence scores: [0.7322031, 0.79193854, 0.7983466]\n",
      "Sentence scores: [0.7536555, 0.8878325]\n",
      "Sentence scores: [0.7384701, 0.85656154, 0.66025686, nan]\n",
      "Sentence scores: [0.89285594, 0.94886005, 0.94886005, nan]\n",
      "Sentence scores: [0.95294714, 0.95294714, 0.8991907, nan]\n",
      "Sentence scores: [nan, nan, nan, nan]\n",
      "Sentence scores: [nan, nan, nan]\n",
      "Sentence scores: [0.84121585, 0.84121585, 0.53082025]\n",
      "Sentence scores: [0.53858024, 0.53858024, 0.84772515, 0.8149252]\n",
      "Sentence scores: [0.8257654, 0.9593903, 0.75963056]\n",
      "Sentence scores: [0.95571464, 0.8448076, 0.85027474]\n",
      "Sentence scores: [0.66782403, 0.9579639, 0.90774214, 0.73506933]\n",
      "Sentence scores: [0.3599514, 0.9873922, 0.87253296]\n",
      "Sentence scores: [0.94431996, 0.8927114, 0.74622905]\n",
      "Sentence scores: [0.4265203, 0.9844926, 0.8502747]\n",
      "Sentence scores: [0.90295476, 0.980848]\n",
      "Sentence scores: [0.99058914, 0.98091274]\n",
      "Sentence scores: [0.47939673, 0.978115, 0.993686]\n",
      "Sentence scores: [0.6271116, 0.97588056, 0.95073944]\n",
      "Sentence scores: [0.9827928, 0.8704109]\n",
      "Sentence scores: [0.56704116, 0.96767014]\n",
      "Sentence scores: [0.87441254, 0.6817031, 0.7488116, nan]\n",
      "Sentence scores: [0.90349144, 0.7289325, 0.90125984, 0.8090743, 0.5473268, 0.47183868]\n",
      "Sentence scores: [0.45565447, 0.6049625, 0.94133276, 0.833907, 0.6570714]\n",
      "Sentence scores: [0.22532189, 0.67581075, 0.9684218, 0.8985649]\n",
      "Sentence scores: [0.9906727, 0.9809913]\n",
      "Sentence scores: [0.8793794, 0.82495]\n",
      "Sentence scores: [0.51190996, 0.89214396, 0.7466929]\n",
      "Sentence scores: [0.55019593, 0.9920772, 0.82859737]\n",
      "Sentence scores: [0.1731735, 0.96896464, 0.98162866]\n",
      "Sentence scores: [0.8870008, 0.98511386, 0.84487957, nan]\n",
      "Sentence scores: [0.7322031, 0.9132318, 0.9132318, nan]\n",
      "Sentence scores: [1.0, 1.0, nan]\n",
      "Sentence scores: [0.79008627, 0.9068446, 0.9068446, 0.7881157, nan]\n",
      "Sentence scores: [0.782616, 0.94550806, nan]\n",
      "Sentence scores: [nan]\n",
      "Sentence scores: [nan]\n",
      "Sentence scores: [0.8358995, 0.944951]\n",
      "Sentence scores: [0.7337689, 0.8025375, 0.47406143]\n",
      "Sentence scores: [0.82412946, 0.9450671]\n",
      "Sentence scores: [0.48203516, 0.8232284, 0.43002382]\n",
      "Sentence scores: [0.54373467, 0.91123813, 0.46503457]\n",
      "Sentence scores: [0.93601424, 0.94990367, 0.80327183]\n",
      "Sentence scores: [0.921296, 0.8361289, 0.921296, 0.23436023]\n",
      "Sentence scores: [0.8827414, 0.8827414, 0.83115757, 0.25402892]\n",
      "Sentence scores: [0.4889738, 0.9284819, 0.87348276]\n",
      "Sentence scores: [0.98973405, 0.7991434, 0.7991434, 0.5918303]\n",
      "Sentence scores: [0.7991434, 0.7991434, 0.7991434, 0.8180042, nan]\n",
      "Sentence scores: [0.9260649, 0.6836366, 0.9755242, 0.25083145]\n",
      "Sentence scores: [0.7992118, 0.9491272, 0.9289726, nan]\n",
      "Sentence scores: [1.0, nan]\n",
      "Sentence scores: [nan, nan]\n",
      "Sentence scores: [0.79921174, 0.79921174, 0.9289726, 0.53450674]\n",
      "Sentence scores: [0.93226737, 0.94646466, 0.80382335]\n",
      "Sentence scores: [0.43403983, 0.9106716, 0.8947977]\n",
      "Sentence scores: [0.6849102, 0.8991753, 0.6849102, nan]\n",
      "Sentence scores: [0.94886005, 0.94886005, 0.89285594, nan]\n",
      "Sentence scores: [0.8528175, 0.9451518]\n",
      "Sentence scores: [1.0, nan]\n",
      "Sentence scores: [nan, 1.0, 1.0, 1.0, nan]\n",
      "Sentence scores: [0.9049261, 0.9049261, 0.9049261, 0.42039508]\n",
      "Sentence scores: [0.90492606, 0.86923754, 0.90492606]\n",
      "Sentence scores: [0.782616, 0.782616, 0.6356254]\n",
      "Sentence scores: [0.2075311, 0.9025967, 0.96617776, 0.7771906]\n",
      "Sentence scores: [0.7657033, 0.8930104, 0.55827457, 0.77446055, 0.17155218]\n",
      "Sentence scores: [0.54426396, 0.9193643, 0.7937984]\n",
      "Sentence scores: [0.44093192, 1.0, 0.8923655]\n",
      "Sentence scores: [0.5210514, 0.9522995, 0.7457194]\n",
      "Sentence scores: [0.709847, 0.9029023, 0.91362077, nan]\n",
      "Sentence scores: [0.9703036, 0.8556317, 0.9703036, 0.9703036, nan]\n",
      "Sentence scores: [0.9049261, 0.9049261, 0.9049261, 0.42039508]\n",
      "Sentence scores: [0.8167808, 0.9421726, nan]\n",
      "Sentence scores: [0.8167808, 0.8167808, 0.57227534]\n",
      "Sentence scores: [0.78242934, 0.9008757, 0.7593679, 0.50771904]\n",
      "Sentence scores: [0.6992342, 0.67485785, 0.9202655, 0.6736518]\n",
      "Sentence scores: [0.7890995, 0.97186536, 0.48278236]\n",
      "Sentence scores: [0.9159055, 0.88355297, 0.27105018]\n",
      "Sentence scores: [0.2073637, 0.9792549]\n",
      "Sentence scores: [0.9524169, 0.8206001]\n",
      "Sentence scores: [0.87327754, 0.8167808, 0.41435292]\n",
      "Sentence scores: [0.8764415, 0.87327754]\n",
      "Sentence scores: [0.7032478, 0.57411295, 0.99165726]\n",
      "Sentence scores: [1.0]\n",
      "Sentence scores: [0.9999999]\n",
      "Sentence scores: [0.9546224, 0.72118586, nan, 0.6853362]\n",
      "Sentence scores: [nan, 1.0]\n",
      "Sentence scores: [0.97699356, 0.45410293]\n",
      "Sentence scores: [0.94886005, 0.94886005, 0.94886005, 0.30466947]\n",
      "Sentence scores: [0.8827414, 0.8685438, nan, 0.8827414]\n",
      "Sentence scores: [0.5227068, nan, 0.5871866, 0.5871866, 0.7592137]\n",
      "Sentence scores: [nan, 0.6370759, 0.6370759, 0.8981241, 0.9727322, 0.6370759]\n",
      "Sentence scores: [0.6213387, 0.9772288, 0.6213387, 0.6213387, 0.77628195, 0.6213387, 0.8369255, nan]\n",
      "Sentence scores: [0.8432601, 0.96982473, 0.8432601, 0.77104574, nan, 0.8432601, 0.96982473, 0.8432601, 0.5276881]\n",
      "Sentence scores: [0.9774434, 0.7797848, 0.9057352, 0.7797848, 0.9774434, 0.95180655, 0.9937497]\n",
      "Sentence scores: [0.80562097, 0.80562097, 0.98551726, 0.9379507, 0.9881246, 0.80562097, 0.73209864, 0.80562097, 0.80562097, 0.80562097, 0.9881246, nan]\n",
      "Sentence scores: [0.8479031, 0.8479031, 0.8479031, 0.9720895, 0.99487, 0.9711619, 0.927949, 0.5179158]\n",
      "Sentence scores: [0.91839004, 0.9948395, 0.9623797, 0.65042573, 0.9961286]\n",
      "Sentence scores: [0.99723923, 0.7067902, 0.9968163, 0.99723923]\n",
      "Sentence scores: [0.47999194, 0.9605534, 0.47999194, 0.9325695, 0.9605534]\n",
      "Sentence scores: [0.7050237, 1.0, 0.7050237, 0.89181674, 0.96387553, 0.7050237, 0.7050237, 0.9477575]\n",
      "Sentence scores: [0.92729944, 0.9074582, 0.9074582, 0.98904186, 0.72724587, 0.9074582, 0.9074582, 0.99296516, nan]\n",
      "Sentence scores: [0.70214874, 0.8638608, 0.70214874, 0.70214874, 0.9412211, 0.70214874, 0.8181568, 0.991686]\n",
      "Sentence scores: [0.9857666, 0.810746, 0.7209135, 0.98486453, 0.810746, 0.98486453, 0.98486453, 0.810746, 0.810746, 0.810746, 0.810746, 0.9857666, nan]\n",
      "Sentence scores: [0.8219694, 0.8219694, 0.8219694, 0.8219694, 0.9884977, 0.8219694, 0.9811904, 0.9811904, 0.8219694, 0.9183863, 0.55682844]\n",
      "Sentence scores: [0.4852539, 0.9824721, 0.99443555, 0.9587586]\n",
      "Sentence scores: [0.577173, 0.98744524, 0.95466685, 0.577173]\n",
      "Sentence scores: [0.7578983, 0.8540471, 0.7578983, 0.7578983, 0.9969885, 0.9969885]\n",
      "Sentence scores: [0.8079779, 0.8079779, 0.8079779, 0.98750365, 0.98750365, 0.8079779, 0.7614008, 0.8079779, 0.9861858, nan]\n",
      "Sentence scores: [0.7062808, 0.84885323, 0.7062808, 0.94635564, 0.9780907, 0.85176295]\n",
      "Sentence scores: [0.76415026, 0.81144375, 0.76415026, 0.84229547, 0.9912016, 0.76415026, 0.9422642, 0.76415026, 0.76415026, 0.76415026, 0.76415026, 0.9912016, nan]\n",
      "Sentence scores: [0.80495, 0.9371043, 0.80495, 0.80495, 0.80495, 0.80495, 0.97699046, 0.80495, 0.8731666, 0.22741117]\n",
      "Sentence scores: [0.70619255, 0.70619255, 0.9299869, 0.60076433, 0.86036104, 0.70619255]\n",
      "Sentence scores: [0.7422905, 0.83514, 0.7422905, 0.7422905, 0.78933954, 0.7422905, 0.7422905, 0.7422905, 0.9602982, nan]\n",
      "Sentence scores: [0.83153737, 0.70060915, 0.83153737, 0.83153737, 0.83153737, 0.99216616, 0.83153737, 0.98018306, 0.83153737, 0.83153737, 0.98018306, nan]\n",
      "Sentence scores: [0.94285893, 0.94285893, 0.94285893, 0.94285893, 0.98540395, 0.94285893, 0.8900598, 0.94285893, 0.94285893, 0.8900598, 0.94285893, 0.8900598, 0.53987026, 0.94285893, 0.94285893, 0.8900598, nan]\n",
      "Sentence scores: [0.83173215, 0.9663834, 0.5357777, 0.83173215, 0.83173215, 0.9663834, 0.83173215, 0.76588905, 0.83173215, 0.9663834, nan]\n",
      "Sentence scores: [0.8130303, 0.8042805, 0.8130303, 0.9861076, 0.9552575, 0.8130303, 0.9861076, 0.8130303, 0.93350154, 0.8130303, 0.9861076]\n",
      "Sentence scores: [0.6663076, 0.9892666, 0.6663076, 0.99858475, 0.6663076, 0.88051033, 0.96307164, 0.6663076]\n",
      "Sentence scores: [0.9549656, 0.66456753, 0.66456753, 0.92423713, 0.87215346, 0.66456753, 0.9450592]\n",
      "Sentence scores: [0.697068, 0.98423934, 0.8727982, 0.697068]\n",
      "Sentence scores: [0.696351, 0.89299697, 0.696351, 0.696351, 0.9628743, 0.696351, 0.9471973, nan]\n",
      "Sentence scores: [0.811803, 0.811803, 0.811803, 0.90972155, 0.811803, 0.87780845, 0.9851304, 0.983102]\n",
      "Sentence scores: [0.9938575, 0.9444248, 0.9938575, 0.70622677, 0.8903752]\n",
      "Sentence scores: [0.70679027, 0.70679027, 0.88401747, 0.94309723, 0.70679027, 0.70679027, 0.97634965, 0.99723923]\n",
      "Sentence scores: [0.65568507, 0.9912359, 0.99773175, 0.65568507, 0.9202475, 0.99773175, nan]\n",
      "Sentence scores: [0.5707346, 0.5707346, 0.9499983, 0.9795141, 0.5707346, 0.8920535, 0.38999432]\n",
      "Sentence scores: [0.99441105, 0.30810973, 0.4899976, 0.94329077, 0.41015097, 0.8261096, 0.98272663, nan]\n",
      "Sentence scores: [0.5842206, 0.88551134, 0.9628424, 0.5842206, 0.98745924, nan]\n",
      "Summary: ['https://\\n/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045 /gid00001\\n/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046Citation: Barandas, M.; Folgado, D.;\\nSantos, R.; Simão, R.; Gamboa, H.\\nUncertainty-Based Rejection in Machine\\nLearning: Implications for Model\\nDevelopment and Interpretability.\\n\\nElectronics 2022 ,11, 396.', 'Published: 28 January 2022\\nSantos, R.; Simão, R.; Gamboa, H.\\nUncertainty-Based Rejection in Machine\\nLearning: Implications for Model\\nDevelopment and Interpretability.\\n\\nhttps://\\ndoi.org/10.3390/electronics11030396\\nAcademic Editors: Christian\\nMorbidoni, Francesco Di Nardo and\\nAlessandro Cucchiarelli\\nReceived: 20 December 2021\\nAccepted: 26 January 2022\\n\\nElectronics 2022 ,11, 396.', 'This article is an open access article\\nCopyright:\\nLicensee MDPI, Basel, Switzerland.\\n\\n© 2022 by the authors.\\n\\nAcademic Editors: Christian\\nMorbidoni, Francesco Di Nardo and\\nAlessandro Cucchiarelli\\nReceived: 20 December 2021\\nAccepted: 26 January 2022\\nPublished:\\n28 January 2022\\nPublisher’s Note: MDPI stays neutral\\nwith regard to jurisdictional claims in\\npublished maps and institutional afﬁl-\\niations.\\n', 'electronics\\nArticle\\nCopyright:\\n© 2022 by the authors.\\n\\nwith regard to jurisdictional claims in\\npublished maps and institutional afﬁl-\\niations.\\n\\nThis article is an open access article\\ndistributed under the terms and\\nconditions of the Creative Commons\\nAttribution (CC BY) license (https://\\ncreativecommons.org/licenses/by/\\n4.0/).\\n\\nLicensee MDPI, Basel, Switzerland.\\n', 'electronics\\nArticle\\nUncertainty-Based Rejection in Machine Learning: Implications\\nfor Model Development and Interpretability\\nMarília Barandas1,2,*\\n, Duarte Folgado1,2\\n, Ricardo Santos1,2\\n, Raquel Simão2\\nand Hugo Gamboa1,2\\ndistributed under the terms and\\nconditions of the Creative Commons\\nAttribution (CC BY) license (https://\\ncreativecommons.org/licenses/by/\\n4.0/).\\n', '1Associação Fraunhofer Portugal Research, Rua Alfredo Allen 455/461, 4200-135 Porto, Portugal;\\nduarte.folgado@fraunhofer.pt (D.F.); ricardo.santos@fraunhofer.pt (R.S.); hugo.gamboa@fraunhofer.pt (H.G.)\\nfor Model Development and Interpretability\\nMarília Barandas1,2,*\\n, Duarte Folgado1,2\\n, Ricardo Santos1,2\\n, Raquel Simão2\\nand Hugo Gamboa1,2\\n', 'duarte.folgado@fraunhofer.pt (D.F.); ricardo.santos@fraunhofer.pt (R.S.); hugo.gamboa@fraunhofer.pt (H.G.)\\n2Laboratório de Instrumentação, Engenharia Biomédica e Física da Radiação (LIBPhys-UNL),\\nDepartamento de Física, Faculdade de Ciências e Tecnologia, Universidade Nova de Lisboa,\\n2829-516 Caparica, Portugal; rf.simao@campus.fct.unl.pt\\n*Correspondence: marilia.barandas@fraunhofer.pt', 'Prior\\nDepartamento de Física, Faculdade de Ciências e Tecnologia, Universidade Nova de Lisboa,\\n2829-516 Caparica, Portugal; rf.simao@campus.fct.unl.pt\\n*Correspondence: marilia.barandas@fraunhofer.pt\\nAbstract: Uncertainty is present in every single prediction of Machine Learning (ML) models.\\nUncer-\\ntainty Quantiﬁcation (UQ) is arguably relevant, in particular for safety-critical applications.', 'Prior\\nresearch focused on the development of methods to quantify uncertainty; however, less attention has\\nbeen given to how to leverage the knowledge of uncertainty in the process of model development.\\n\\ntainty Quantiﬁcation (UQ) is arguably relevant, in particular for safety-critical applications.\\nThis work focused on applying UQ into practice, closing the gap of its utility in the ML pipeline', 'This work focused on applying UQ into practice, closing the gap of its utility in the ML pipeline\\nand giving insights into how UQ is used to improve model development and its interpretability.\\nbeen given to how to leverage the knowledge of uncertainty in the process of model development.\\n\\nWe\\nidentiﬁed three main research questions: (1) How can UQ contribute to choosing the most suitable', 'These questions\\n(2) Can UQ be used to combine different models in a prin-\\ncipled manner?\\nWe\\nidentiﬁed three main research questions: (1) How can UQ contribute to choosing the most suitable\\nmodel for a given classiﬁcation task?\\n(3) Can visualization techniques improve UQ’s interpretability?\\nand giving insights into how UQ is used to improve model development and its interpretability.', 'Our results showed that uncertainty\\n(2) Can UQ be used to combine different models in a prin-\\ncipled manner?\\nThese questions\\nare answered by applying several methods to quantify uncertainty in both a simulated dataset and\\na real-world dataset of Human Activity Recognition (HAR).\\n(3) Can visualization techniques improve UQ’s interpretability?\\nmodel for a given classiﬁcation task?', 'Keywords: artiﬁcial intelligence; uncertainty quantiﬁcation; machine learning; rejection option;\\ninterpretability; human activity recognition\\nare answered by applying several methods to quantify uncertainty in both a simulated dataset and\\na real-world dataset of Human Activity Recognition (HAR).\\nOur results showed that uncertainty\\nquantiﬁcation can increase model robustness and interpretability.\\n', 'Introduction\\nMachine Learning (ML) has continuously attracted the interest of the research com-\\nmunity, motivated by the promising results obtained in many decision-critical domains.\\nKeywords: artiﬁcial intelligence; uncertainty quantiﬁcation; machine learning; rejection option;\\ninterpretability; human activity recognition\\n1.', 'ML models learn from data and\\nHowever, we argue that approaches that are safe to use in decision-critical domains must\\naccount for the inherent uncertainty in the process [ 1].\\nIntroduction\\nMachine Learning (ML) has continuously attracted the interest of the research com-\\nmunity, motivated by the promising results obtained in many decision-critical domains.\\n\\n1.', 'However, we argue that approaches that are safe to use in decision-critical domains must\\naccount for the inherent uncertainty in the process [ 1].\\nLearning from data is inseparably con-\\nnected with uncertainty [ 2].\\nML models learn from data and\\nuse the extracted models to make predictions.\\nThus, the predictions made by ML models have an associated', 'Thus, the predictions made by ML models have an associated\\nuncertainty, as they are susceptible to noise and suboptimal model inference.\\nLearning from data is inseparably con-\\nnected with uncertainty [ 2].\\nuse the extracted models to make predictions.\\nIt is highly de-\\nsirable to take into account uncertainty as a path towards trustworthy Artiﬁcial Intelligence', 'As such, ML models should have the ability to quantify uncertainty in\\ntheir predictions and abstain from providing a decision when a large amount of uncertainty\\nis present [3].\\nIt is highly de-\\nsirable to take into account uncertainty as a path towards trustworthy Artiﬁcial Intelligence\\n(AI)-based systems.\\nuncertainty, as they are susceptible to noise and suboptimal model inference.', 'Aleatoric uncertainty refers\\nBased on the origin of uncertainty, a distinction between two different sources of uncer-\\ntainty is commonly made: aleatoric and epistemic uncertainty.\\nAs such, ML models should have the ability to quantify uncertainty in\\ntheir predictions and abstain from providing a decision when a large amount of uncertainty\\nis present [3].\\n\\n(AI)-based systems.', 'Epistemic\\nuncertainty refers to the uncertainty associated with the model and by the lack of knowl-\\nAleatoric uncertainty refers\\nto the notion of randomness, and it is related to the data-measurement process.\\nBased on the origin of uncertainty, a distinction between two different sources of uncer-\\ntainty is commonly made: aleatoric and epistemic uncertainty.\\nis present [3].\\n', 'Although different types of uncertainty should\\nto the notion of randomness, and it is related to the data-measurement process.\\nIn principle, epistemic uncertainty can be reduced by extending the training data,\\nbetter modeling, or better data analysis.\\nEpistemic\\nuncertainty refers to the uncertainty associated with the model and by the lack of knowl-\\nedge.', 'In principle, epistemic uncertainty can be reduced by extending the training data,\\nbetter modeling, or better data analysis.\\nAlthough different types of uncertainty should\\nbe measured differently, this distinction in ML has only received attention recently [ 4].\\n\\nIn particular, in the literature on deep learning, this distinction has been studied due to\\nedge.', 'Recently there has\\nIn particular, in the literature on deep learning, this distinction has been studied due to\\nthe limited awareness of neural networks of their own conﬁdence.\\nbe measured differently, this distinction in ML has only received attention recently [ 4].\\n', 'In particular, in the literature on deep learning, this distinction has been studied due to\\nthe limited awareness of neural networks of their own conﬁdence.\\nhttps://doi.org/10.3390/electronics11030396 https://www.mdpi.com/journal/electronicsElectronics 2022 ,11, 396 2 of 20\\nRecently there has\\nElectronics 2022 ,11, 396.', 'https://doi.org/10.3390/electronics11030396 https://www.mdpi.com/journal/electronicsElectronics 2022 ,11, 396 2 of 20\\nbeen more focus on epistemic uncertainty since deep learning models are known as being\\noverconﬁdent with out-of-distribution examples or even adversarial examples [5].\\n\\nElectronics 2022 ,11, 396.\\nAlthough Uncertainty Quantiﬁcation (UQ) plays an important role in AI deployment', 'Although Uncertainty Quantiﬁcation (UQ) plays an important role in AI deployment\\nscenarios for cost-sensitive decision-making domains, such as medicine [ 6], it is also an\\nimportant concept within the ML methodology itself, as for instance, in active learning [ 7,8].\\noverconﬁdent with out-of-distribution examples or even adversarial examples [5].\\n', 'UQ is important\\nscenarios for cost-sensitive decision-making domains, such as medicine [ 6], it is also an\\nimportant concept within the ML methodology itself, as for instance, in active learning [ 7,8].\\n\\nRecent uncertainty frameworks have been proposed that provide different capabilities to\\nquantify and evaluate uncertainty in the AI development lifecycle [ 9,10].', 'For the users\\nUQ is important\\nacross several stakeholders of the ML lifecycle.\\nRecent uncertainty frameworks have been proposed that provide different capabilities to\\nquantify and evaluate uncertainty in the AI development lifecycle [ 9,10].\\nIt helps developers debug their models,\\nin understanding their ﬂaws so they can be used for model improvement.', 'It helps developers debug their models,\\nin understanding their ﬂaws so they can be used for model improvement.\\nFor the users\\nof AI systems, UQ increases interpretability and trust in model predictions, answering\\nthe question: Can I trust this model?\\nFor regulators and certiﬁcation bodies, it contributes\\nacross several stakeholders of the ML lifecycle.', 'Previous research has been focused on the development of techniques to characterize\\nof AI systems\\n, UQ increases interpretability and trust in model predictions, answering\\nthe question: Can I trust this model?\\nFor regulators and certiﬁcation bodies, it contributes\\nto algorithm auditing and quality control as a path towards the effective and reliable\\napplication of ML systems [11].\\n', 'This work\\nfocused on leveraging the outcome from uncertainty quantiﬁcation to improve the model\\napplication of ML systems\\nPrevious research has been focused on the development of techniques to characterize\\nand quantify uncertainty.\\n[11].\\n\\nHowever, few studies addressed a comprehensive analysis of\\nhow UQ can be used to improve model performance and its interpretability.', 'We identiﬁed the following\\nresearch questions:\\nThis work\\nfocused on leveraging the outcome from uncertainty quantiﬁcation to improve the model\\ndevelopment process.\\nhow UQ can be used to improve model performance and its interpretability.\\nWe applied the UQ concept in practice, giving insights into why it\\ncan be an effective procedure to improve model development.', 'How can UQ contribute to choosing the most suitable model for a given classification task?\\n2.\\nWe identiﬁed the following\\nresearch questions:\\n1.\\ndevelopment process.\\nWe applied the UQ concept in practice, giving insights into why it\\ncan be an effective procedure to improve model development.\\nCan UQ be used to combine different models in a principled manner?', 'Model selection\\nCan UQ be used to combine different models in a principled manner?\\n3.\\nHow can UQ contribute to choosing the most suitable model for a given classification task?\\n2.\\nresearch questions:\\n1.\\nIn ML, various criteria can be used in the problem of model selection.\\nCan visualization techniques improve UQ’s interpretability?\\n', 'It\\ncan be applied either to different types of models or the same type conﬁgured with different\\nModel selection\\nconsists of selecting a ﬁnal model among a collection of candidates for a training dataset.\\n3. Can visualization techniques improve UQ’s interpretability?\\n\\nIn ML, various criteria can be used in the problem of model selection.', 'that\\nThe main goal of model selection is to achieve the best predictive\\nperformance for modeling learning data and for making predictions for new examples\\nconsists of selecting a ﬁnal model among a collection of candidates for a training dataset.\\nIt\\ncan be applied either to different types of models or the same type conﬁgured with different\\nhyperparameters.', 'In supervised learning, the predictive\\naccuracy is usually considered as the most important criterion for model selection.\\nThe main goal of model selection is to achieve the best predictive\\nperformance for modeling learning data and for making predictions for new examples that\\nwere not included in the learning process [ 12,13].\\nhyperparameters.\\nHowever,', 'However,\\nvarious criteria for the predictive model quality, such as interpretability or computational\\ncost, can also play a key role in model selection.\\nIn supervised learning, the predictive\\naccuracy is usually considered as the most important criterion for model selection.\\nTo the best of our knowledge, uncertainty is\\nwere not included in the learning process [ 12,13].', 'various criteria for the predictive model quality, such as interpretability or computational\\ncost, can also play a key role in model selection.\\nTo the best of our knowledge, uncertainty is\\nnot being considered as criterion for model selection.\\nQuestion 1 addresses how uncertainty\\nmight contribute to model characterization with valuable quantitative information, either', 'Question 1 addresses how uncertainty\\nmight contribute to model characterization with valuable quantitative information, either\\nby describing the quality of the model’s ﬁt or evaluating if sufﬁcient training data were\\nprovided to calculate trustworthy predictions.\\nnot being considered as criterion for model selection.', 'Some rules address\\nIt is often found that, in particularly complex classiﬁcation problems, performance\\ncan be improved by combining multiple models, instead of just using a single one.\\nThere\\nare several combination rules to train and combine different models.\\nby describing the quality of the model’s ﬁt or evaluating if sufﬁcient training data were\\nprovided to calculate trustworthy predictions.\\n', 'we\\nNev-\\nertheless, the uncertainty of multiple models is seldom considered.\\ncan be improved by combining multiple models, instead of just using a single one.\\nSome rules address\\nmodels’ combination using the average of the predictions or the class probabilities.\\nThere\\nare several combination rules to train and combine different models.\\nWith Question 2,', 'For difﬁcult\\nWith Question 2, we\\naddress how uncertainty can be taken into account for model combination.\\n\\nNev-\\nertheless, the uncertainty of multiple models is seldom considered.\\nIn ordinary classiﬁcation, the classiﬁer is usually forced to predict a label.\\nmodels’ combination using the average of the predictions or the class probabilities.', 'For difﬁcult\\nsamples, it might lead to misclassiﬁcation, which may cause problems in risk-sensitive\\napplications.\\nIn ordinary classiﬁcation, the classiﬁer is usually forced to predict a label.\\nIn these scenarios, it will be more appropriate to avoid making decisions\\naddress how uncertainty can be taken into account for model combination.\\n', 'In these scenarios, it will be more appropriate to avoid making decisions\\non the difﬁcult cases in anticipation of a lower error rate on those examples for which\\na classiﬁcation decision is made [ 3].\\nsamples, it might lead to misclassiﬁcation, which may cause problems in risk-sensitive\\napplications.\\nThis approach is known as classiﬁcation with a', 'In addition to quantitative methods for sample rejection, it is important\\nto provide the interpretability of why a particular sample was rejected.\\nThis approach is known as classiﬁcation with a\\nrejecting option.\\non the difﬁcult cases in anticipation of a lower error rate on those examples for which\\na classiﬁcation decision is made [ 3].\\nIn this context,', 'In addition to quantitative methods for sample rejection, it is important\\nto provide the interpretability of why a particular sample was rejected.\\nIn this context,\\nNeto et al.\\nrejecting option.\\n[14] proposed a visualization explainable matrix applied to random forests\\nwith a focus on global and local explanations where conﬁdence scores were used as an', 'However, with regard to uncertainty visualization for a given\\nprediction or applied to the model itself, few or no studies have considered this in theElectronics 2022 ,11, 396 3 of 20\\n[14] proposed a visualization explainable matrix applied to random forests\\nwith a focus on global and local explanations where conﬁdence scores were used as an\\ninterpretability measure.\\nNeto et al.', 'The remainder of this paper is organized as follows:\\nprediction or applied to the model itself, few or no studies have considered this in theElectronics 2022 ,11, 396 3 of 20\\nliterature.\\nTherefore, Question 3 addresses how visualization techniques might be used to\\nimprove UQ’s interpretability.\\n\\nIn Section 2, we introduce the', 'The remainder of this paper is organized as follows:\\nIn Section 2, we introduce the\\nbackground concepts and related work.\\nSection 4 contains experimental results,\\nand in Section 5, we detail the conclusions and discuss possible directions for future work.\\nSection 3 contains a thorough description of the\\nmethods used to answer the research questions.\\nimprove UQ’s interpretability.\\n', 'Section 4 contains experimental results,\\nand in Section 5, we detail the conclusions and discuss possible directions for future work.\\n\\n2. Background and Related Work\\nThe awareness of uncertainty is of major importance in ML and constitutes a key\\nelement of its methodology.\\nmethods used to answer the research questions.\\nTraditionally, uncertainty in ML is modeled using probability', 'Traditionally, uncertainty in ML is modeled using probability\\ntheory, which has always been perceived as the reference tool for uncertainty handling [ 4].\\n\\n2. Background and Related Work\\nThe awareness of uncertainty is of major importance in ML and constitutes a key\\nelement of its methodology.\\nIn the recent ML literature, two inherently different sources of uncertainty are commonly', 'Aleatoric uncertainty refers to\\nthe notion of randomness and cannot be reduced by adding more samples to the training\\nIn the recent ML literature, two inherently different sources of uncertainty are commonly\\ndistinguished, referred to as aleatoric and epistemic [ 15].\\ntheory, which has always been perceived as the reference tool for uncertainty handling [ 4].\\n', 'distinguished, referred to as aleatoric and epistemic [ 15].\\nOn the other hand, epistemic uncertainty refers to the uncertainty caused by a lack\\nof knowledge, either due to the uncertainty associated with the model or the lack of data.\\nAleatoric uncertainty refers to\\nthe notion of randomness and cannot be reduced by adding more samples to the training\\nprocess.', 'In principle, this uncertainty can be reduced by adding more training data.\\n\\nOn the other hand, epistemic uncertainty refers to the uncertainty caused by a lack\\nof knowledge, either due to the uncertainty associated with the model or the lack of data.\\n\\nIn the following subsections, we present an overview of previous works that have\\nprocess.', 'In the following subsections, we present an overview of previous works that have\\nexplored different strategies for UQ and methods about classiﬁcation with rejection.\\n\\nIn principle, this uncertainty can be reduced by adding more training data.\\n\\n2.1.\\nUncertainty Quantiﬁcation\\nIn standard probabilistic modeling and Bayesian inference, the representation of', 'Uncertainty Quantiﬁcation\\nIn standard probabilistic modeling and Bayesian inference, the representation of\\nuncertainty about a prediction is given by the posterior distribution.\\nLet us consider a ﬁnite\\ntraining dataset, D=f(xi,wi)gN\\ni, with Nsamples, composed of pairs of input features\\n2.1.\\nexplored different strategies for UQ and methods about classiﬁcation with rejection.\\n', 'Let us consider a ﬁnite\\ntraining dataset, D=f(xi,wi)gN\\ni, with Nsamples, composed of pairs of input features\\nxand labels w, where wk2fw1, ...,wKgconsists of a ﬁnite set of Kclass labels.\\nSuppose\\na hypothesis space of probabilistic predictors, where a hypothesis hmaps instances x\\nuncertainty about a prediction is given by the posterior distribution.', 'Samples from the posterior distribution should\\nxand labels w, where wk2fw1, ...,wKgconsists of a ﬁnite set of Kclass labels.\\nSuppose\\na hypothesis space of probabilistic predictors, where a hypothesis hmaps instances x\\nto probability distributions on outcomes w.\\nEach hypothesis can be considered as an\\nexplanation of how the world works.', 'Samples from the posterior distribution should\\nyield explanations consistent with the observations of the world contained within the\\ntraining data, D[16].\\nFrom a Bayesian perspective, each hypothesis is equipped with a\\nEach hypothesis can be considered as an\\nexplanation of how the world works.\\nto probability distributions on outcomes w.', 'From a Bayesian perspective, each hypothesis is equipped with a\\nprior distribution p(h), and the posterior distribution, p(hjD), can be computed via the\\nBayes rule:\\np(hjD) =p(Djh)p(h)\\np(D)(1)\\nwhere p(Djh)is the probability of the data given h, i.e., the likelihood of the parameters h.\\nyield explanations consistent with the observations of the world contained within the\\ntraining data, D[16].', 'Bayes rule:\\np(hjD) =p(Djh)p(h)\\np(D)(1)\\nwhere p(Djh)is the probability of the data given h, i.e., the likelihood of the parameters h.\\nFor a given instance x, the predictive uncertainty of a classiﬁcation model depends\\non how the uncertainty is represented as a basis for prediction and decision-making.\\nIn\\nBayesian inference, the belief about the outcome wkis represented by a second-order', 'In\\nBayesian inference, the belief about the outcome wkis represented by a second-order\\nprobability: a probability distribution of probability distributions [ 15].\\nIn this type of\\nBayesian inference, a given prediction is obtained through model averaging, i.e., different\\non how the uncertainty is represented as a basis for prediction and decision-making.', 'Thus, the predictive posterior distribution is given by:\\np(wjx) =Z\\np(wjx,h)dP(hjD) (2)\\nIn this type of\\nBayesian inference, a given prediction is obtained through model averaging, i.e., different\\nhypotheses hprovide predictions, which are aggregated in terms of a weighted average.\\n\\nprobability: a probability distribution of probability distributions [ 15].', 'Thus, the predictive posterior distribution is given by:\\np(wjx) =Z\\np(wjx,h)dP(hjD) (2)\\n\\nThus, the predicted probability of an outcome wis the expected probability p(wjx,h),\\nwhere the expectation over the hypotheses is taken with respect to the posterior distribution,\\nhypotheses hprovide predictions, which are aggregated in terms of a weighted average.\\n', 'Thus, the predicted probability of an outcome wis the expected probability p(wjx,h),\\nwhere the expectation over the hypotheses is taken with respect to the posterior distribution,\\nP(hjD).\\np(wjx,h)dP(hjD) (2)\\n\\nHowever, since model averaging is often difﬁcult and computationally costly, in\\nML, it is common to make predictions considering a single probability distribution for each', 'The most well-known measure of uncertainty of a single probability distribution, p,\\nis the (Shannon) entropy, which for discrete class labels is given as:\\nH(p) =\\x00K\\nå\\nHowever, since model averaging is often difﬁcult and computationally costly, in\\nML, it is common to make predictions considering a single probability distribution for each\\nclass.\\nP(hjD).', 'The most well-known measure of uncertainty of a single probability distribution, p,\\nis the (Shannon) entropy, which for discrete class labels is given as:\\nH(p) =\\x00K\\nå\\nk=1p(w)log2p(w) (3)Electronics 2022 ,11, 396 4 of 20\\nThis measure of uncertainty primarily captures the shape of the distribution and,\\nhence, is mostly concerned with the aleatoric part of the overall uncertainty.\\nclass.', 'In order to account for both aleatoric and epistemic uncertainty, the Bayesian per-\\nspective is quite common in ML, where the (total) uncertainty is quantiﬁed on the basis\\nThis measure of uncertainty primarily captures the shape of the distribution and,\\nhence, is mostly concerned with the aleatoric part of the overall uncertainty.\\n', '[ 17] proposed an approach to quantify and separate uncertainties with\\nIn order to account for both aleatoric and epistemic uncertainty, the Bayesian per-\\nspective is quite common in ML, where the (total) uncertainty is quantiﬁed on the basis\\nof the predictive posterior distribution.\\nIn the context of neural networks for regression,\\nDepeweg et al.', 'The authors’ idea was more general and can\\nalso be applied to other settings, such as in the work of Shaker et al.\\nIn the context of neural networks for regression,\\nDepeweg et al.\\n[ 17] proposed an approach to quantify and separate uncertainties with\\nclassical information-theoretic measures.\\nof the predictive posterior distribution.\\n[ 18], where mea-', '[16], who adopted these measures in the context of gradient boosting models.\\nThe authors’ idea was more general and can\\nalso be applied to other settings, such as in the work of Shaker et al.\\n[ 18], where mea-\\nsures of entropy were applied using a random forest classiﬁer, or the work of Andrey\\nMalinin et al.\\nclassical information-theoretic measures.', 'More speciﬁcally, Depeweg et al.\\n[16], who adopted these measures in the context of gradient boosting models.\\n\\nsures of entropy were applied using a random forest classiﬁer, or the work of Andrey\\nMalinin et al.\\n[ 17] proposed to measure the total uncertainty in terms of\\nthe entropy of the predictive posterior distribution, H[p(wjx)], and measure the aleatoric', 'The aleatoric uncertainty is measured in terms of the expectation over\\n[ 17] proposed to measure the total uncertainty in terms of\\nthe entropy of the predictive posterior distribution, H[p(wjx)], and measure the aleatoric\\nuncertainty in terms of the expectation of entropy with regard to the posterior probability,\\nEp(hjD)H[p(wjx,h)].\\nMore speciﬁcally, Depeweg et al.', 'However, the idea is that by\\nﬁxing a hypothesis h, the epistemic uncertainty is essentially removed.\\nuncertainty in terms of the expectation of entropy with regard to the posterior probability,\\nEp(hjD)H[p(wjx,h)].\\nThe aleatoric uncertainty is measured in terms of the expectation over\\nthe entropies of distributions, since his not precisely known.\\nThen, the epistemic', 'Then, the epistemic\\nuncertainty is measured in terms of the mutual information between hypotheses and out-\\ncomes, I(w,hjx,D).\\nHowever, the idea is that by\\nﬁxing a hypothesis h, the epistemic uncertainty is essentially removed.\\nthe entropies of distributions, since his not precisely known.\\nEpistemic uncertainty is high if the distribution p(wjx,h)varies greatly', 'uncertainty is measured in terms of the mutual information between hypotheses and out-\\ncomes, I(w,hjx,D).\\nEpistemic uncertainty is high if the distribution p(wjx,h)varies greatly\\nfor different hypotheses hwith high probability, but leading to quite different predictions.\\n\\nDue to the computational complexity of these measures, which involve the integration', 'Due to the computational complexity of these measures, which involve the integration\\nover the hypothesis space, an approximation by means of ensemble techniques, based on\\nan ensemble of Mhypotheses, can be obtained using the following equations:\\nualeat(x) =Ep(hjD)H[p(wjx,h)]\\x191\\nMM\\nå\\ni=1H[p(wjx,hi)]\\n(4)\\nfor different hypotheses hwith high probability, but leading to quite different predictions.\\n', '(4)\\nutotal(x) =H[Ep(hjD)p(wjx,h)]\\x19H\"\\n1\\nMM\\nå\\ni=1P(wjx,hi)#\\n(5)\\nuepist(x) =I(w,hjx,D) =H[Ep(hjD)p(wjx,h)]\\x00Ep(hjD)H[p(wjx,h)]\\nan ensemble of Mhypotheses, can be obtained using the following equations:\\nualeat(x) =Ep(hjD)H[p(wjx,h)]\\x191\\nMM\\nå\\ni=1H[p(wjx,hi)]\\n(6)\\nBesides the classical information-theoretic measures, the bootstrap method [ 19] is also', '1\\nMM\\nå\\ni=1P(wjx,hi)#\\n(5)\\nuepist(x) =I(w,hjx,D) =H[Ep(hjD)p(wjx,h)]\\x00Ep(hjD)H[p(wjx,h)]\\n(6)\\nBesides the classical information-theoretic measures, the bootstrap method [ 19] is also\\na common approach to estimate uncertainty.\\nIn order to quantify the uncertainty in the\\nresults of a given algorithm, the sampling distribution of a parameter of interest is required.', 'In order to quantify the uncertainty in the\\nresults of a given algorithm, the sampling distribution of a parameter of interest is required.\\n\\nBecause data represent one collection of observable data, resampling methods that generate\\nadditional representative samples in order to obtain a sampling distribution are used [ 20].\\na common approach to estimate uncertainty.', 'Because data represent one collection of observable data, resampling methods that generate\\nadditional representative samples in order to obtain a sampling distribution are used [ 20].\\n\\nThe bootstrap method uses Monte Carlo simulation to approximate the sampling\\ndistribution by repeatedly simulating bootstrap samples, which are new datasets created', 'To\\nbootstrap a supervised learning algorithm, one would need to sample Sbootstrap datasets\\nand run the learning procedure from scratch each time.\\nThe bootstrap method uses Monte Carlo simulation to approximate the sampling\\ndistribution by repeatedly simulating bootstrap samples, which are new datasets created\\nby sampling with replacement from the uniform distribution over the original dataset.', 'Variation ratios measure the variability of the predictions obtained from sampling by\\nbootstrap a supervised learning algorithm, one would need to sample Sbootstrap datasets\\nand run the learning procedure from scratch each time.\\n\\nA measure to quantify uncertainty using the bootstrap method is the variation ratios.\\n', 'This heuristic is a measure of\\nthe dispersion of the predictions around its mode [ 21].\\nVariation ratios measure the variability of the predictions obtained from sampling by\\ncomputing the fraction of samples with the correct output.\\nA measure to quantify uncertainty using the bootstrap method is the variation ratios.\\n\\nFor a given instance x, the variation\\nratios are computed as follows:\\nVR=1\\x00fw\\x03', 'For a given instance x, the variation\\nratios are computed as follows:\\nVR=1\\x00fw\\x03\\nS(7)\\nwhere fwk=åS\\ni=11[wi=w\\x03]andw\\x03corresponds to the sampled majority class,\\nw\\x03=arg max\\nw=w1,...,wKS\\nå\\ni=11[wi=w] (8)\\nAdditionally, measures for novelty, anomaly, or outlier detection, where testing sam-\\nthe dispersion of the predictions around its mode [ 21].', 'where fwk=åS\\ni=11[wi=w\\x03]andw\\x03corresponds to the sampled majority class,\\nw\\x03=arg max\\nw=w1,...,wKS\\nå\\ni=11[wi=w] (8)\\nAdditionally, measures for novelty, anomaly, or outlier detection, where testing sam-\\nples come from a different population than the training set, can also be used to quantifyElectronics 2022 ,11, 396 5 of 20', 'ples come from a different population than the training set, can also be used to quantifyElectronics 2022 ,11, 396 5 of 20\\nuncertainty.\\nIn this scenario, the open set recognition and out-of-distribution problems are\\ncommonly mentioned [ 22].\\nApproaches based on generative models typically use densities\\nto decide whether to reject a test input that is located in a region without training inputs.', 'These low-density regions, where no training inputs have been encountered so far, repre-\\nsent a high knowledge uncertainty.\\nApproaches based on generative models typically use densities\\nto decide whether to reject a test input that is located in a region without training inputs.\\n\\nTraditional methods, such as Kernel Density Estimation\\ncommonly mentioned [ 22].', 'Traditional methods, such as Kernel Density Estimation\\n(KDE), can be used to estimate densities, and often, threshold-based methods are applied\\non top of the density where a classiﬁer can refuse to predict a test input in that region [ 23].\\nThese low-density regions, where no training inputs have been encountered so far, repre-\\nsent a high knowledge uncertainty.', '(KDE), can be used to estimate densities, and often, threshold-based methods are applied\\non top of the density where a classiﬁer can refuse to predict a test input in that region [ 23].\\n\\nIn this context, Knowledge Uncertainty Estimation (KUE) [ 24] learns the feature density\\nestimation from the training data, to reject test inputs that represent a density different', 'For a test input xi, represented by P-dimensional feature vectors,\\nwhere fj2ff1,. .\\nIn this context, Knowledge Uncertainty Estimation (KUE) [ 24] learns the feature density\\nestimation from the training data, to reject test inputs that represent a density different\\nfrom the training dataset.\\n.,fPgis\\nthe feature vector in a bounded area of the feature space and wk', 'For a test input xi, represented by P-dimensional feature vectors,\\nwhere fj2ff1,. .\\n.,fPgis\\nthe feature vector in a bounded area of the feature space and wk\\nis the predicted class, the KUE measure is calculated as follows:\\nKUE(xijwk)\\n=1\\x00 \\nP\\nÕ\\nj=1dunc(fjjwk,xi)!1\\nP\\n(9)\\nwhere duncis an uncertainty distance obtained from the feature density, assuming values\\nfrom the training dataset.', '=1\\x00 \\nP\\nÕ\\nj=1dunc(fjjwk,xi)!1\\nP\\n(9)\\nwhere duncis an uncertainty distance obtained from the feature density, assuming values\\nin the interval\\nis the predicted class, the KUE measure is calculated as follows:\\nKUE(xijwk)\\n[0, 1], where one represents the maximum density seen in training and\\nnear-zero values represent low-density regions where no training inputs were observed\\nduring training.', 'in the interval [0, 1], where one represents the maximum density seen in training and\\nnear-zero values represent low-density regions where no training inputs were observed\\nduring training.\\n\\n2.2.\\nClassiﬁcation with the Rejection Option\\nThe process of abstaining from producing an answer or discarding a prediction when\\nthe system is not conﬁdent enough is more than 60 years old and was introduced by', 'If the classiﬁer is not sufﬁciently accurate for\\nChow’s theory suggests that objects are rejected for which the maximum\\nposterior probability is below a threshold.\\nThe process of abstaining from producing an answer or discarding a prediction when\\nthe system is not conﬁdent enough is more than 60 years old and was introduced by\\nChow [ 25].', 'Chow’s theory suggests that objects are rejected for which the maximum\\nposterior probability is below a threshold.\\nIf the classiﬁer is not sufﬁciently accurate for\\nthe task at hand, then one can take the approach not to classify all examples, but only\\nthose whose posterior probability is sufﬁciently high.\\nChow [ 25].\\nChow’s theory is suitable when a', 'Chow’s theory is suitable when a\\nsufﬁciently large training sample is available for all classes and when the training sample\\nis not contaminated by outliers [ 26].\\nFumera et al.\\nthe task at hand, then one can take the approach not to classify all examples, but only\\nthose whose posterior probability is sufﬁciently high.\\n[ 27] showed that Chow’s rule does not', 'In that case, a\\ndifferent rejection threshold per class has to be used.\\n[ 27] showed that Chow’s rule does not\\nperform well if a signiﬁcant error in the probability estimation is present.\\nFumera et al.\\nsufﬁciently large training sample is available for all classes and when the training sample\\nis not contaminated by outliers [ 26].\\nIn classiﬁers with a rejection option,', 'In that case, a\\ndifferent rejection threshold per class has to be used.\\nIn classiﬁers with a rejection option,\\nthe key parameters are the thresholds that deﬁne the rejection area, which may be hard to\\ndeﬁne and may vary signiﬁcantly in value, especially when classes have a large spread.\\nperform well if a signiﬁcant error in the probability estimation is present.', 'the key parameters are the thresholds that deﬁne the rejection area, which may be hard to\\ndeﬁne and may vary signiﬁcantly in value, especially when classes have a large spread.\\n\\nIn these kinds of methods, the rejection is mostly applied to samples with high\\naleatoric uncertainty, since it has been argued that probability distributions are less suitable', 'In these kinds of methods, the rejection is mostly applied to samples with high\\naleatoric uncertainty, since it has been argued that probability distributions are less suitable\\nfor representing ignorance in the sense of a lack of knowledge [ 4].\\nAlternatively, more\\nrecent works [ 15,18,21] included the classiﬁcation with rejection with a distinction between', 'Alternatively, more\\nrecent works [ 15,18,21] included the classiﬁcation with rejection with a distinction between\\naleatoric and epistemic uncertainty using ensemble techniques and/or deep learning\\napproaches.\\nFor the classiﬁcation with rejection, a conﬁdence threshold value needs to be\\nfor representing ignorance in the sense of a lack of knowledge [ 4].', 'For the classiﬁcation with rejection, a conﬁdence threshold value needs to be\\ndeﬁned indicating the rejection point.\\nDifferent cost-based rejection methods have been\\nproposed to minimize the classiﬁcation risk [ 28–30].\\naleatoric and epistemic uncertainty using ensemble techniques and/or deep learning\\napproaches.\\nIn probabilistic classiﬁers, risk can', 'In probabilistic classiﬁers, risk can\\nderive from the observation of the output probabilities employing different metrics, such\\nas the least conﬁdence, margin of conﬁdence, variation ratios, and predictive entropy [ 31].\\nDifferent cost-based rejection methods have been\\nproposed to minimize the classiﬁcation risk [ 28–30].\\ndeﬁned indicating the rejection point.', 'According to\\nderive from the observation of the output probabilities employing different metrics, such\\nas the least conﬁdence, margin of conﬁdence, variation ratios, and predictive entropy [ 31].\\n\\nThe evaluation of the performance of classiﬁers with rejection usually uses standard\\nmetrics, such as accuracy, to obtain an Accuracy-Rejection Curve (ARC)\\n[ 32].', '[ 32], an ARC is a function representing the accuracy of a classiﬁer as a function\\nof its rejection rate.\\nThe evaluation of the performance of classiﬁers with rejection usually uses standard\\nmetrics, such as accuracy, to obtain an Accuracy-Rejection Curve (ARC)\\nTherefore, the ARCs plot the rejection rate of the metrics (from 0–1)\\nAccording to\\nNadeem et al.\\n[ 32].', 'Since the accuracy is always 100% when the rejection\\nrate is one, all curves converge to the point (1, 1), and they start from the point (0,a), where\\nTherefore, the ARCs plot the rejection rate of the metrics (from 0–1)\\nagainst the accuracy of the classiﬁer.\\n[ 32], an ARC is a function representing the accuracy of a classiﬁer as a function\\nof its rejection rate.\\nNadeem et al.', 'Since the accuracy is always 100% when the rejection\\nrate is one, all curves converge to the point (1, 1), and they start from the point (0,a), where\\nais the initial accuracy of the classiﬁer, with 0% of rejected samples.\\nUsing this approach, it\\nis not possible to determine the optimal rejection rate by comparing the performance of\\nagainst the accuracy of the classiﬁer.', 'Using this approach, it\\nis not possible to determine the optimal rejection rate by comparing the performance of\\nthe classiﬁers.\\nais the initial accuracy of the classiﬁer, with 0% of rejected samples.\\nAlthough there are other metrics for evaluating classiﬁers with rejection,\\nthey are centered only on the nonrejected accuracy as a core component of ARCs [ 33].Electronics 2022 ,11, 396 6 of 20', '[ 33] expanded the set of performance measures for classiﬁcation with\\nrejection and, besides the nonrejected accuracy, proposed two novel performance measures\\nto evaluate the best rejection point, namely classiﬁcation quality and rejection quality.\\nthey are centered only on the nonrejected accuracy as a core component of ARCs [ 33].Electronics 2022 ,11, 396 6 of 20\\nCondessa et al.', 'Considering a partition of a set of samples in subsets A,M,N, and R, where Ais a\\nsubset of accurately classiﬁed samples, Mis a subset of misclassiﬁed samples, Nis a subset\\nrejection and, besides the nonrejected accuracy, proposed two novel performance measures\\nto evaluate the best rejection point, namely classiﬁcation quality and rejection quality.\\n', 'Considering a partition of a set of samples in subsets A,M,N, and R, where Ais a\\nsubset of accurately classiﬁed samples, Mis a subset of misclassiﬁed samples, Nis a subset\\nof nonrejected samples, and Ris a subset of the rejected samples, each metric can be derived\\nas follows:\\n• Nonrejected accuracy measures the ability of the classiﬁer to accurately classify nonre-', ', each metric can be derived\\nas follows:\\n• Nonrejected accuracy measures the ability of the classiﬁer to accurately classify nonre-\\njected samples, and it is computed as,\\nNRA =jA\\\\Nj\\njNj; (10)\\n• Classiﬁcation quality measures the ability of the classiﬁer with rejection to accurately\\nof nonrejected samples, and Ris a subset of the rejected samples', 'It is computed as,\\nCQ=jA\\\\Nj+jM\\\\Rj\\njNj+jRj; (11)\\n• Rejection quality measures the ability of the classiﬁer with rejection to make errors on\\nrejected samples only, and it is computed as,\\njected samples, and it is computed as,\\nNRA =jA\\\\Nj\\njNj; (10)\\n• Classiﬁcation quality measures the ability of the classiﬁer with rejection to accurately\\nclassify nonrejected samples and to reject misclassiﬁed samples.', 'CQ=jA\\\\Nj+jM\\\\Rj\\njNj+jRj; (11)\\n• Rejection quality measures the ability of the classiﬁer with rejection to make errors on\\nrejected samples only, and it is computed as,\\nRQ=jM\\\\RjjAj\\njA\\\\RjjMj.\\nThe nonrejected accuracy and the classiﬁcation quality are bounded in the interval\\n[0, 1].\\nUnlike these measures, the rejection quality has a minimum value of zero, and its\\n(12)\\n', 'Methods\\nThe nonrejected accuracy and the classiﬁcation quality are bounded in the interval\\n[0, 1].\\nNonetheless, the higher the values, the better the\\nmetric performs for rejection.\\n\\nUnlike these measures, the rejection quality has a minimum value of zero, and its\\nmaximum is unbounded by construction.\\n3.\\nRQ=jM\\\\RjjAj\\njA\\\\RjjMj.\\n(12)\\n', 'Nonetheless, the higher the values, the better the\\nmetric performs for rejection.\\n\\nMethods\\nIn this work, we considered the uncertainty estimation problem in a traditional ML\\nclassiﬁcation setting.\\nBesides the common division between aleatoric and epistemic uncer-\\ntainty, we further divided the epistemic uncertainty into two additional categories, namely\\n3.\\nmaximum is unbounded by construction.', 'Besides the common division between aleatoric and epistemic uncer-\\ntainty, we further divided the epistemic uncertainty into two additional categories, namely\\nknowledge and model uncertainty.\\nAlthough these terms are commonly used to refer to the\\nbroad view of epistemic uncertainty, we refer to knowledge uncertainty as the uncertainty\\nclassiﬁcation setting.', 'Although these terms are commonly used to refer to the\\nbroad view of epistemic uncertainty, we refer to knowledge uncertainty as the uncertainty\\nrelated to the lack of data, i.e., to the regions in space where there is little or no evidence of\\nany class regardless of being far from/near the decision boundary.\\nOn the other hand, we\\nknowledge and model uncertainty.', 'On the other hand, we\\nrefer to model uncertainty as the uncertainty related to the model itself, i.e., the quality of\\nthe model ﬁt on known data or uncertainty about the model parameters.\\nrelated to the lack of data, i.e., to the regions in space where there is little or no evidence of\\nany class regardless of being far from/near the decision boundary.', 'refer to model uncertainty as the uncertainty related to the model itself, i.e., the quality of\\nthe model ﬁt on known data or uncertainty about the model parameters.\\n\\nML systems share a set of core components comprising data, an ML model, and\\nits outputs.\\nUncertainties are present in all ML components under different sources, as\\nvisualized in Figure 1.', 'ML systems share a set of core components comprising data, an ML model, and\\nits outputs.\\nUncertainties are present in all ML components under different sources, as\\nvisualized in Figure 1.\\nFigure 1.\\nElectronics 2022 ,11, 396 7 of 20\\n• Data: Data used to feed ML models are limited in their accuracy and potentially\\nUncertainty in Machine Learning (ML) classiﬁcation settings.', 'Electronics 2022 ,11, 396 7 of 20\\n• Data: Data used to feed ML models are limited in their accuracy and potentially\\naffected by various kinds of quality issues, which limits the models from being ap-\\nplied under optimal conditions [ 34,35].\\nFor example, the uncertainty caused due to\\nUncertainty in Machine Learning (ML) classiﬁcation settings.\\nFigure 1.', 'For example, the uncertainty caused due to\\nerrors in the measurement might affect the performance of a given classiﬁcation task.\\n\\naffected by various kinds of quality issues, which limits the models from being ap-\\nplied under optimal conditions [ 34,35].\\nAlthough the aleatoric uncertainty is supposed to be irreducible for a speciﬁc dataset,', 'Although the aleatoric uncertainty is supposed to be irreducible for a speciﬁc dataset,\\nincorporating additional features or improving the quality of the existing features can\\nassist in its reduction [36];\\n• Model: For a given classiﬁcation task, several ML models can be applied and de-\\nerrors in the measurement might affect the performance of a given classiﬁcation task.\\n', 'incorporating additional features or improving the quality of the existing features can\\nassist in its reduction [36];\\n• Model: For a given classiﬁcation task, several ML models can be applied and de-\\nveloped.\\nHowever, besides models’ accuracy, the\\nThe choice of a model is arguably important and is often based on the\\ndegree of error in the model’s outcomes.', 'However, besides models’ accuracy, the\\nuse of uncertainty quantiﬁcation methods during model development can provide\\nimportant elements to choose the right model for the problem at hand.\\nveloped.\\nMoreover,\\nThe choice of a model is arguably important and is often based on the\\ndegree of error in the model’s outcomes.', 'The\\nMoreover,\\nunderstanding the model’s uncertainty during training can give us insights about the\\nspeciﬁc limitations of each model and help in developing more robust models.\\nuse of uncertainty quantiﬁcation methods during model development can provide\\nimportant elements to choose the right model for the problem at hand.', 'The\\nestimation of model uncertainty increases model interpretability, by allowing the user\\nto interpret how conﬁdent the model is for a given prediction;\\n• Output: After the model’s training, estimating and quantifying uncertainty in a\\nunderstanding the model’s uncertainty during training can give us insights about the\\nspeciﬁc limitations of each model and help in developing more robust models.', 'to interpret how conﬁdent the model is for a given prediction;\\n• Output: After the model’s training, estimating and quantifying uncertainty in a\\ntransductive way, in the sense of tailoring it to individual instances, are arguably\\nrelevant, all the more in safety-critical applications.\\nFor instance, in the context of\\ncomputer-aided diagnosis systems, a prediction with high uncertainty shall justify', 'For instance, in the context of\\ncomputer-aided diagnosis systems, a prediction with high uncertainty shall justify\\neither disregarding its output or conducting further medical examinations of the\\npatient.\\nrelevant, all the more in safety-critical applications.\\nIn the latter, the goal is to retrieve additional evidence that supports or', 'In the latter, the goal is to retrieve additional evidence that supports or\\ncontradicts a given hypothesis.\\nIn the former, it is the case of classiﬁcation with\\nrejection, which is a viable option, where the presence and cost of errors can be\\neither disregarding its output or conducting further medical examinations of the\\npatient.', 'In the former, it is the case of classiﬁcation with\\nrejection, which is a viable option, where the presence and cost of errors can be\\ndetrimental to the performance of automated classiﬁcation systems\\nTo illustrate the different sources of uncertainty and the methods for UQ, we introduce\\ncontradicts a given hypothesis.\\n[33].\\n', 'To illustrate the different sources of uncertainty and the methods for UQ, we introduce\\na scenario using a simulated small dataset shown in Figure 2.\\nThe scenario consists of a\\ntwo-dimensional dataset with two classes, where features from class A were modeled with\\ndetrimental to the performance of automated classiﬁcation systems [33].\\n', 'The\\nThe scenario consists of a\\ntwo-dimensional dataset with two classes, where features from class A were modeled with\\nan unimodal Gaussian distribution and features from class B were modeled as a bimodal\\ndistribution with a mixture of two Gaussian distributions with highly unequal mass.\\na scenario using a simulated small dataset shown in Figure 2.', 'an unimodal Gaussian distribution and features from class B were modeled as a bimodal\\ndistribution with a mixture of two Gaussian distributions with highly unequal mass.\\nThe\\nminor mode is approximately 5.5% of the mass of the major mode.\\n0.4\\n 0.2\\n 0.0 0.2 0.4 0.6\\nFeature 10.40.60.81.01.21.4Feature 2Class A\\nClass B', 'Electronics 2022 ,11, 396 8 of 20\\nFor model training, a Naive Bayes (NB) classiﬁer using KDE was applied using a\\nSynthetic dataset used to illustrate the different sources of uncertainty in a toy scenario.\\nminor mode is approximately 5.5% of the mass of the major mode.\\n0.4\\n 0.2\\n 0.0 0.2 0.4 0.6\\nFeature 10.40.60.81.01.21.4Feature 2Class A\\nClass B\\nFigure 2.', 'For model training, a Naive Bayes (NB) classiﬁer using KDE was applied using a\\nbootstrap approach with 50 bootstrap samples to estimate the sampling distribution of\\narbitrary functions of a dataset.\\nUsing this approach, it is possible to access the amount\\nthat a prediction changes when the model is ﬁt on slightly different data.', 'Using this approach, it is possible to access the amount\\nthat a prediction changes when the model is ﬁt on slightly different data.\\n\\narbitrary functions of a dataset.\\nThe selected uncertainty quantiﬁcation methods for each source of uncertainty were\\nthe following:\\n• Aleatoric uncertainty: The (Shannon) entropy is the most notable measure of uncer-', 'The selected uncertainty quantiﬁcation methods for each source of uncertainty were\\nthe following:\\n• Aleatoric uncertainty: The (Shannon) entropy is the most notable measure of uncer-\\ntainty for probability distributions being more akin to aleatoric uncertainty.\\nEquation (4) ,\\nwhich measures the aleatoric uncertainty in terms of expectation over the entropies of', 'Equation (4) ,\\nwhich measures the aleatoric uncertainty in terms of expectation over the entropies of\\ndistributions, was used for the rest of the analysis;\\n• Model uncertainty: Variation ratios (Equation (7)) were selected as a primary uncer-\\ntainty for probability distributions being more akin to aleatoric uncertainty.', 'distributions, was used for the rest of the analysis;\\n• Model uncertainty: Variation ratios (Equation (7)) were selected as a primary uncer-\\ntainty quantiﬁcation method, to estimate model uncertainty, as we were interested in\\nevaluating the quality of the model ﬁt.\\nIn this sense, changes in the predicted label\\nhave a signiﬁcant impact on the variation ratio measure.\\nContrarily, measures based', 'Contrarily, measures based\\non entropies (Equation (6) is commonly used) can also be used, but the impact on the\\nmeasure is lower, since in variation ratios, we are merely counting changes in the pre-\\nIn this sense, changes in the predicted label\\nhave a signiﬁcant impact on the variation ratio measure.\\nevaluating the quality of the model ﬁt.', 'Although the majority of works addressed the quantiﬁcation\\non entropies (Equation (6) is commonly used) can also be used, but the impact on the\\nmeasure is lower, since in variation ratios, we are merely counting changes in the pre-\\ndictions, and in entropy measures, we are averaging the prediction probabilities [ 21];\\n• Knowledge uncertainty:', 'dictions, and in entropy measures, we are averaging the prediction probabilities [ 21];\\n• Knowledge uncertainty: Although the majority of works addressed the quantiﬁcation\\nof knowledge uncertainty with measures such as the mutual information using ensem-\\nbles (Equation (6)), we argue that these kinds of measures are more akin to model un-', ', we argue that these kinds of measures are more akin to model un-\\ncertainty.\\nIn this perspective, we considered density estimation methods, commonly\\nof knowledge uncertainty with measures such as the mutual information using ensem-\\nbles (Equation (6))\\nThe uncertainty related to the lack of data might be poorly modeled by these\\nmeasures.', 'In this perspective, we considered density estimation methods, commonly\\nused for outlier or novelty detection, more prone to model knowledge uncertainty.\\n\\nThus, the KUE measure (Equation (9)) was used to model knowledge uncertainty.\\nThe uncertainty related to the lack of data might be poorly modeled by these\\nmeasures.\\ncertainty.', 'Thus, the KUE measure (Equation (9)) was used to model knowledge uncertainty.\\n\\nused for outlier or novelty detection, more prone to model knowledge uncertainty.\\n\\nIn order to visualize the uncertainty estimations in the whole region presented in\\nFigure 2, we applied the uncertainty quantiﬁcation measures to a new set of points that', '0.5\\n 0.0 0.5\\nFeature 10.500.751.001.251.50Feature 2Aleatoric Uncertainty\\n0.5\\n 0.0 0.5\\nIn order to visualize the uncertainty estimations in the whole region presented in\\nFigure 2, we applied the uncertainty quantiﬁcation measures to a new set of points that\\nincluded all combinations of feature values in the deﬁned region.\\nFigure 3 shows the\\nuncertainty values for each point of the feature space.\\n', 'Toy dataset uncertainty measures for aleatoric, model, and knowledge uncertainty (from\\nuncertainty values for each point of the feature space.\\n0.5\\n 0.0 0.5\\nFeature 10.500.751.001.251.50Feature 2Aleatoric Uncertainty\\n0.5\\n 0.0 0.5\\nFeature 1Model Uncertainty\\n0.5\\n 0.0 0.5\\nFeature 1Knowledge Uncertainty\\n0.00.20.40.60.81.0\\nentropy\\n0.00.10.20.30.40.5\\nvariation ratios\\n0.00.20.40.60.81.0\\nKUE\\nFigure 3.', 'The aleatoric uncertainty is high\\nObserving the uncertainty regions for each source of uncertainty, one can see com-\\npletely different behaviors depending on the uncertainty.\\nToy dataset uncertainty measures for aleatoric, model, and knowledge uncertainty (from\\nlefttoright ).\\n\\n0.00.20.40.60.81.0\\nentropy\\n0.00.10.20.30.40.5\\nvariation ratios\\n0.00.20.40.60.81.0\\nKUE\\nFigure 3.', 'The aleatoric uncertainty is high\\nin the middle of the two major clusters (Feature 1 equals to 0.15 approximately), due to\\nthe overlap between the classes.\\nlefttoright ).\\n\\nObserving the uncertainty regions for each source of uncertainty, one can see com-\\npletely different behaviors depending on the uncertainty.\\nThe overlap between the cluster of class A and the minor', 'in the middle of the two major clusters (Feature 1 equals to 0.15 approximately), due to\\nthe overlap between the classes.\\nThe overlap between the cluster of class A and the minor\\ncluster of class B also presents a higher uncertainty compared to the rest of the region.\\n\\nHowever, it does not produce an uncertainty as high as the overlap between the two', 'However, it does not produce an uncertainty as high as the overlap between the two\\nmajor clusters due to the differences in the masses of both clusters.\\nThe entropy value is\\nnormalized to the maximum entropy, i.e., the logarithm of the number of classes.\\ncluster of class B also presents a higher uncertainty compared to the rest of the region.\\n', 'The entropy value is\\nnormalized to the maximum entropy, i.e., the logarithm of the number of classes.\\n\\nRegarding the model uncertainty and referring to this toy scenario with two classes,\\nthe maximum possible value occurs when the frequency of both classes is equal, i.e., the\\nmajor clusters due to the differences in the masses of both clusters.', 'Regarding the model uncertainty and referring to this toy scenario with two classes,\\nthe maximum possible value occurs when the frequency of both classes is equal, i.e., the\\nvariation ratios have a value of 0.5.\\nThe regions with higher uncertainty values are the\\nones with little evidence, since the model ﬁt in these regions is highly dependent on the', 'The regions with higher uncertainty values are the\\nones with little evidence, since the model ﬁt in these regions is highly dependent on the\\navailable data.\\nTherefore, it is expected that slight differences in the training data, especiallyElectronics 2022 ,11, 396 9 of 20\\nvariation ratios have a value of 0.5.', 'Therefore, it is expected that slight differences in the training data, especiallyElectronics 2022 ,11, 396 9 of 20\\nin regions with little evidence, have a high impact on the model ﬁt and produce high model\\nuncertainty.\\nObserving the ﬁgure, it is possible to see that the minor cluster of class B\\nproduces a high model uncertainty.\\nAdditionally, the upper and lower regions between\\navailable data.', 'Additionally, the upper and lower regions between\\nthe major clusters also produce a high uncertainty, due to slight differences in the decision\\nboundary on different bootstrap samples.\\n\\nObserving the ﬁgure, it is possible to see that the minor cluster of class B\\nproduces a high model uncertainty.\\nFinally, knowledge uncertainty was modeled using the feature density on the training\\nuncertainty.', 'The\\nFor the classiﬁcation with rejection, we deﬁne a rejection rule for each type of uncer-\\ntainty, using the previously uncertainty measures to deﬁne the conﬁdence threshold.\\nFinally, knowledge uncertainty was modeled using the feature density on the training\\ndata, which produces a high uncertainty in all the feature space without data.\\n\\nboundary on different bootstrap samples.\\n', 'There are several works entirely dedicated to this topic, such as the work of\\nCondessa et al.\\n[37].\\n[33] and Fisher et al.\\nThe\\nproblem of choosing the optimal rejection point is not trivial and was not addressed in\\nthis work.\\nFor the classiﬁcation with rejection, we deﬁne a rejection rule for each type of uncer-\\ntainty, using the previously uncertainty measures to deﬁne the conﬁdence threshold.', 'In our classiﬁcation setting, the ﬁnal prediction is given by the following rejection rule:\\nˆw=(\\nreject ifF(x)>0\\nf(x) otherwise(13)\\nwhere f(x)is the classiﬁer without rejection and F(x)is a function on the input that\\n[37].\\n\\n[33] and Fisher et al.\\nthis work.\\nThere are several works entirely dedicated to this topic, such as the work of\\nCondessa et al.', 'ˆw=(\\nreject ifF(x)>0\\nf(x) otherwise(13)\\nwhere f(x)is the classiﬁer without rejection and F(x)is a function on the input that\\nevaluates the uncertainty of the prediction model.\\nThis uncertainty function is given\\nby the set of uncertainties—aleatoric ( a), model ( m), and knowledge ( k)—through the\\nfollowing equation:\\nF(x) =å\\nu2U1[fu(x)>tu] (14)', 'by the set of uncertainties—aleatoric ( a), model ( m), and knowledge ( k)—through the\\nfollowing equation:\\nF(x) =å\\nu2U1[fu(x)>tu] (14)\\nwhere U2[a,m,k]is the set of available uncertainties, fuis an uncertainty function that\\nevaluates uncertainty u, and tuis a threshold for the rejection point for uncertainty u.\\nRegarding aleatoric uncertainty, fais equal to Equation (4) and the optimal threshold,', 'Regarding aleatoric uncertainty, fais equal to Equation (4) and the optimal threshold,\\nta, was obtained using the following equation:\\nta=argmax\\nq\\x12\\njM\\\\Rqj\\x00b\\n1\\x00b\\x01jA\\\\Rqj\\x13\\n(15)\\nwhere qis a threshold in the interval\\n[0, 1], representing a normalized entropy value\\nevaluates uncertainty u, and tuis a threshold for the rejection point for uncertainty u.\\n', 'ta, was obtained using the following equation:\\nta=argmax\\nq\\x12\\njM\\\\Rqj\\x00b\\n1\\x00b\\x01jA\\\\Rqj\\x13\\n(15)\\nwhere qis a threshold in the interval [0, 1], representing a normalized entropy value\\nmeasured with Equation (4), and bis a rejection cost, here set to 0.5.\\nFor jM\\\\Rqjand\\njA\\\\Rqj, the notation from Section 2.2 was used, and the subsets represent the true rejections', 'The uncertainty function used for model uncertainty, fm, is equal to Equation (7), and\\nFor jM\\\\Rqjand\\njA\\\\Rqj, the notation from Section 2.2 was used, and the subsets represent the true rejections\\nand false rejections using threshold q, respectively.\\n\\nmeasured with Equation (4), and bis a rejection cost, here set to 0.5.', 'The uncertainty function used for model uncertainty, fm, is equal to Equation (7), and\\ntmwas set to zero, which means that a prediction must be equal in all bootstraps samples\\nto not be rejected.\\nand false rejections using threshold q, respectively.\\n\\nThis assumption was made because if a sample is predicted differently', 'This assumption was made because if a sample is predicted differently\\nusing slightly different datasets, the model in that particular region will still have some\\nuncertainty associated.\\n\\ntmwas set to zero, which means that a prediction must be equal in all bootstraps samples\\nto not be rejected.\\nTo deﬁne tk, we used a\\nFor knowledge uncertainty, fkis equal to Equation (9).', 'using slightly different datasets, the model in that particular region will still have some\\nuncertainty associated.\\n\\nTo deﬁne tk, we used a\\n95% value of the training uncertainty values, meaning that tk=P95%[KUE].\\nFor knowledge uncertainty, fkis equal to Equation (9).\\nA detailed\\ndescription of this approach is available in [24].', 'In summary, our proposed approach was developed in the context of classiﬁcation\\nwith rejection where rejection was obtained through measures of uncertainty.\\n95% value of the training uncertainty values, meaning that tk=P95%[KUE].\\nThese un-\\ncertainty measures were distinguished by three different sources: aleatoric, model, and\\nA detailed\\ndescription of this approach is available in [24].\\n', 'For the uncertainty quantiﬁcation, we used an entropy measure\\nfor aleatoric uncertainty (Equation (4)), the variation ratio measure for model uncertainty\\nThese un-\\ncertainty measures were distinguished by three different sources: aleatoric, model, and\\nknowledge uncertainty.\\nwith rejection where rejection was obtained through measures of uncertainty.', 'For the uncertainty quantiﬁcation, we used an entropy measure\\nfor aleatoric uncertainty (Equation (4)), the variation ratio measure for model uncertainty\\n(Equation (7)), and KUE to quantify the knowledge uncertainty.\\nRegarding the rejection\\nsetting, we applied the rejection rule from Equation (13), where each source of uncertainty\\nknowledge uncertainty.', 'Regarding the rejection\\nsetting, we applied the rejection rule from Equation (13), where each source of uncertainty\\nhas an uncertainty function given by Equation (14).\\n(Equation (7)), and KUE to quantify the knowledge uncertainty.\\nFor the training procedure, a bootstrap\\napproach with 20 bootstrap samples was used, and the uncertainty measures were calcu-', 'For the training procedure, a bootstrap\\napproach with 20 bootstrap samples was used, and the uncertainty measures were calcu-\\nlated.\\nThe evaluation of the selected models was performed through the accuracy and the\\nnonrejection accuracy followed by the rejection fraction for each individual measure andElectronics 2022 ,11, 396 10 of 20\\nhas an uncertainty function given by Equation (14).', 'In the case of the models’ combination, the performance\\nmeasures from Equations (10)–(12) were also employed.\\n\\nnonrejection accuracy followed by the rejection fraction for each individual measure andElectronics 2022 ,11, 396 10 of 20\\nalso the total rejection fraction.\\n4.\\nExperiments\\nIn this section, we demonstrate the usefulness of uncertainty quantiﬁcation using', 'Experiments\\nIn this section, we demonstrate the usefulness of uncertainty quantiﬁcation using\\nsynthetic datasets and a benchmark dataset from the University of California Irvine (UCI)\\nML repository [38].\\nmeasures from Equations (10)–(12) were also employed.\\n\\nSpeciﬁcally, we answer the following questions:\\n• Q1.\\n4.\\nHow can UQ contribute to choosing the most suitable model for a given', 'Speciﬁcally, we answer the following questions:\\n• Q1.\\nCan UQ be use to combine different models?\\n• Q3.\\nML repository [38].\\nHow can UQ contribute to choosing the most suitable model for a given\\nclassiﬁcation task?\\n• Q2.\\nCan visualization techniques improve UQ’s interpretability?\\n4.1.\\nAnalysis on Synthetic Data\\nPredicted uncertainties are often evaluated indirectly, since normally, data do not', 'Analysis on Synthetic Data\\nPredicted uncertainties are often evaluated indirectly, since normally, data do not\\ncontain information about any sort of “ground truth” uncertainties.\\n• Q3.\\nFor this reason, the\\nuse of a synthetic dataset can more easily provide an intuition about the different types of\\nCan visualization techniques improve UQ’s interpretability?\\n4.1.', 'For this reason, the\\nuse of a synthetic dataset can more easily provide an intuition about the different types of\\nuncertainties and their quantiﬁcation.\\nFurthermore, in a controllable setting, we can alter\\nthe size of the datasets, evaluate the models’ performance and uncertainties in different\\ncontain information about any sort of “ground truth” uncertainties.', 'Furthermore, in a controllable setting, we can alter\\nthe size of the datasets, evaluate the models’ performance and uncertainties in different\\nconditions, and introduce noise in the data to check the models’ robustness.\\n\\nUncertainty for Model Selection (Q1)\\nTo answer Q1, we generated a dataset composed of a total of 150,000 ten-dimensional\\n4.1.1.\\nuncertainties and their quantiﬁcation.', 'To evaluate\\nUncertainty for Model Selection (Q1)\\nTo answer Q1, we generated a dataset composed of a total of 150,000 ten-dimensional\\npoints corresponding to six different classes equally distributed.\\nFeatures from each class\\nwere modeled using Gaussian, exponential, and uniform distributions.\\nThe distributions\\nwere randomly selected and could be unimodal or bimodal distributions.\\n4.1.1.', 'were modeled using Gaussian, exponential, and uniform distributions.\\nTo evaluate\\nthe behavior of uncertainty estimations with the increasing number of training samples,\\nthe models were trained for different training sizes using a k-fold cross-validation as the\\nThe distributions\\nwere randomly selected and could be unimodal or bimodal distributions.', 'the behavior of uncertainty estimations with the increasing number of training samples,\\nthe models were trained for different training sizes using a k-fold cross-validation as the\\nvalidation strategy where k was set to 5.\\nAn exponential growth of the training samples\\nwas applied, starting with 50 samples per class (training size equals 300 samples).', 'For model training, different classiﬁers using a training size of 7692 samples were\\ntested as presented in Table 1.\\nAn exponential growth of the training samples\\nwas applied, starting with 50 samples per class (training size equals 300 samples).\\n\\nvalidation strategy where k was set to 5.\\nSince features data were simulated using Gaussian, expo-', 'Since features data were simulated using Gaussian, expo-\\nnential, and uniform distributions, a focus on Bayesian models using Gaussian, KDE, and\\nexponential distributions was employed.\\nAs expected, Bayesian models obtained higher\\nFor model training, different classiﬁers using a training size of 7692 samples were\\ntested as presented in Table 1.', 'nential, and uniform distributions, a focus on Bayesian models using Gaussian, KDE, and\\nexponential distributions was employed.\\nAs expected, Bayesian models obtained higher\\nbaseline accuracies than the other tested classiﬁers, since part of the features likelihood\\nwas modeled with the true data distribution.\\nWith the purpose of answering Q1, the three', 'With the purpose of answering Q1, the three\\nclassiﬁers highlighted in Table 1, with a similar baseline accuracy, were selected to continue\\nthe analysis.\\nbaseline accuracies than the other tested classiﬁers, since part of the features likelihood\\nwas modeled with the true data distribution.\\nThese classiﬁers were: (1) the NB classiﬁer where the features likelihood', 'These classiﬁers were: (1) the NB classiﬁer where the features likelihood\\nwas assumed to be Gaussian; (2) the NB classiﬁer where the features likelihood was as-\\nsumed to be exponential; (3) the Bayes classiﬁer where the features likelihood was based\\nclassiﬁers highlighted in Table 1, with a similar baseline accuracy, were selected to continue\\nthe analysis.', 'Additionally, the selected classiﬁers were trained using a bootstrap procedure\\nwith 20 bootstrap samples.\\n\\nwas assumed to be Gaussian; (2) the NB classiﬁer where the features likelihood was as-\\nsumed to be exponential; (3) the Bayes classiﬁer where the features likelihood was based\\non KDE.\\nFor this analysis, only aleatoric and model uncertainty measures were considered,', 'Additionally, the selected classiﬁers were trained using a bootstrap procedure\\nwith 20 bootstrap samples.\\n\\nFor this analysis, only aleatoric and model uncertainty measures were considered,\\nsince a synthetic dataset without outliers was used.\\nTherefore, KUE would be near zero\\nand would not bring relevant information for this analysis.\\non KDE.', 'Therefore, KUE would be near zero\\nand would not bring relevant information for this analysis.\\n\\nFigure 4 shows the rejection fraction and accuracy with the increasing number of\\ntraining samples for the different tested models.\\nsince a synthetic dataset without outliers was used.\\nThe rejection fraction was obtained\\nusing both aleatoric and model uncertainty measures independently, and the nonrejected', 'The rejection fraction was obtained\\nusing both aleatoric and model uncertainty measures independently, and the nonrejected\\naccuracy was obtained by rejecting all samples with aleatoric and/or model uncertainty\\n(see Equation (13)).\\n\\nAs previously mentioned, the model’s accuracy is often one of the most important\\ntraining samples for the different tested models.', 'As previously mentioned, the model’s accuracy is often one of the most important\\nelements to model selection.\\nHowever, we argue that uncertainty quantiﬁcation methods\\nshould also be evaluated during the model’s training, to help us choose the right model.\\naccuracy was obtained by rejecting all samples with aleatoric and/or model uncertainty\\n(see Equation (13)).\\n', 'Observing Figure 4, different models can achieve the same accuracy, but with different\\ndegrees of uncertainty.\\nHowever, we argue that uncertainty quantiﬁcation methods\\nshould also be evaluated during the model’s training, to help us choose the right model.\\n\\nFor example, for a training size of 7692 samples (dashed gray line inElectronics 2022 ,11, 396 11 of 20\\nelements to model selection.', 'For example, for a training size of 7692 samples (dashed gray line inElectronics 2022 ,11, 396 11 of 20\\nFigure 4), the three models obtained a baseline accuracy of 84%, approximately.\\nSeen only\\nfrom this point of view, the decision between the three models would be equal.\\nHowever,\\nobserving the rejection fraction from uncertainty measures, it is easy to understand that\\ndegrees of uncertainty.', 'However,\\nobserving the rejection fraction from uncertainty measures, it is easy to understand that\\nthe KDE model had higher model uncertainty compared with the other two models.\\nfrom this point of view, the decision between the three models would be equal.\\nThe\\nreason for this difference is that the KDE model is more complex, which means that it', 'The\\nreason for this difference is that the KDE model is more complex, which means that it\\nneeds more data to correctly model the data distribution.\\nTherefore, the differences in the\\nbootstrap samples have a high impact on the model ﬁt, meaning that the same sample is\\nthe KDE model had higher model uncertainty compared with the other two models.', 'Therefore, the differences in the\\nbootstrap samples have a high impact on the model ﬁt, meaning that the same sample is\\nclassiﬁed differently depending on the bootstrap sample used to ﬁt the model.\\nAdditionally,\\nobserving the standard deviation with the increasing number of training samples, we can\\nneeds more data to correctly model the data distribution.', 'Additionally,\\nobserving the standard deviation with the increasing number of training samples, we can\\nnote a slight decrease in both the rejection fraction and accuracy values, except from the\\nexponential model, which seemed to have an almost constant value across the different\\nclassiﬁed differently depending on the bootstrap sample used to ﬁt the model.', 'note a slight decrease in both the rejection fraction and accuracy values, except from the\\nexponential model, which seemed to have an almost constant value across the different\\ntraining sizes.\\nUsing this information and since the accuracy was approximately equal for\\nthe three models, the choice of a Gaussian NB would be probably preferable due to its low\\naleatoric and model uncertainty.', 'the three models, the choice of a Gaussian NB would be probably preferable due to its low\\naleatoric and model uncertainty.\\n\\nThe highlighted baseline accuracies represent the selected models that were\\nconsidered for further analysis, since the models attained similar accuracy values.\\nTable 1.\\nPerformance measures (mean \\x06standard deviation) for different models using a training\\nsize of 7692 samples.', '\\x060.004 0.929\\x060.004 0.050\\x060.007\\nModelBaseline Nonrejected Rejection\\nAccuracy Accuracy Fraction\\nGaussian Naive Bayes 0.838\\x060.004 0.861\\x060.004 0.056\\x060.006\\nKDE Naive Bayes 0.918\\nThe highlighted baseline accuracies represent the selected models that were\\nconsidered for further analysis, since the models attained similar accuracy values.\\n\\nsize of 7692 samples.', '\\x060.024 0.884\\x060.004 0.328\\x060.111\\n\\x060.003 0.788\\x060.005 0.198\\x060.006\\nDecision Tree 0.764\\n\\x060.004 0.929\\x060.004 0.050\\x060.007\\nExponential Naive Bayes 0.848\\x060.012 0.894\\x060.011 0.109\\x060.041\\nKDE Bayes 0.845\\x060.003 0.914\\x060.004 0.178\\x060.004\\nLogistic Regression 0.717\\nModelBaseline Nonrejected Rejection\\nAccuracy Accuracy Fraction\\nGaussian Naive Bayes 0.838\\x060.004 0.861\\x060.004 0.056\\x060.006\\nKDE Naive Bayes 0.918', '\\x060.004 0.806\\x060.005 0.173\\x060.010\\n0.00.20.4Rejection Fraction\\nGuassian Naive Bayes\\n Exponential Naive Bayes\\n\\x060.004 0.902\\x060.007 0.202\\x060.005\\nSupport Vector Machines 0.744\\n\\x060.004 0.871\\x060.006 0.169\\x060.004\\nk-Nearest Neighbors 0.820\\n\\x060.024 0.884\\x060.004 0.328\\x060.111\\nRandom Forest 0.806\\n\\x060.003 0.788\\x060.005 0.198\\x060.006\\nDecision Tree 0.764\\nKDE Bayes 0.845\\x060.003 0.914\\x060.004 0.178\\x060.004\\nLogistic Regression 0.717', '\\x060.004 0.806\\x060.005 0.173\\x060.010\\n0.00.20.4Rejection Fraction\\nGuassian Naive Bayes\\n Exponential Naive Bayes\\n KDE Model\\nAleatoric\\nModel\\n103104105\\n# train samples0.60.70.80.91.0Accuracy\\n103104105\\n# train samples\\n103104105\\n# train samples\\nBaseline\\nNRA\\n\\x060.004 0.902\\x060.007 0.202\\x060.005\\nSupport Vector Machines 0.744\\nk-Nearest Neighbors 0.820', 'Uncertainties’ rejection fraction and obtained accuracies using a k-fold cross-validation\\nwith an increasing number of training samples for 3 different models.\\nGuassian Naive Bayes\\n Exponential Naive Bayes\\n KDE Model\\nAleatoric\\nModel\\n103104105\\n# train samples0.60.70.80.91.0Accuracy\\n103104105\\n# train samples\\n103104105\\n# train samples\\nBaseline\\nNRA\\nFigure 4.\\nThe vertical line represents a', 'Uncertainties’ rejection fraction and obtained accuracies using a k-fold cross-validation\\nwith an increasing number of training samples for 3 different models.\\nThe vertical line represents a\\ntraining size that obtained a similar baseline accuracy for all models.\\n\\nNonetheless, if the rejection of samples or the addition of new samples is an option, a\\nFigure 4.', 'Increasing the number\\nNonetheless, if the rejection of samples or the addition of new samples is an option, a\\ndifferent analysis can be performed.\\nBy deﬁnition, aleatoric uncertainty is irreducible for theElectronics 2022 ,11, 396 12 of 20\\nsame dataset, which was veriﬁed with these experimental results.\\ntraining size that obtained a similar baseline accuracy for all models.\\n', 'Increasing the number\\nof training samples did not change the aleatoric uncertainty, making the rejection fraction\\nmostly constant across the different training sizes.\\nsame dataset, which was veriﬁed with these experimental results.\\nContrarily, model uncertainty decreased\\nwith the increase of the number of training samples, tending towards zero when the model', 'In Gaussian\\nThus, the analysis of model uncertainty can give us\\ninsights about the usefulness of adding more samples for the model’s training.\\nContrarily, model uncertainty decreased\\nwith the increase of the number of training samples, tending towards zero when the model\\nﬁt was equal for all bootstrap samples.\\nmostly constant across the different training sizes.', 'In Gaussian\\nand KDE models, the decrease of model uncertainty had a clear increase in the baseline\\naccuracy.\\nThus, the analysis of model uncertainty can give us\\ninsights about the usefulness of adding more samples for the model’s training.\\nFor the Gaussian NB model, from 103training samples, the baseline accuracy was\\nﬁt was equal for all bootstrap samples.', 'For the Gaussian NB model, from 103training samples, the baseline accuracy was\\nmostly constant and the decrease of model uncertainty was not signiﬁcant.\\nand KDE models, the decrease of model uncertainty had a clear increase in the baseline\\naccuracy.\\nThis means that\\nthe model ﬁt did not change using different bootstrap samples, and the addition of new', 'This means that\\nthe model ﬁt did not change using different bootstrap samples, and the addition of new\\ndata did not improve the model’s performance.\\nHowever, observing the KDE model, due to\\nits high rejection fraction of model uncertainty, the addition of new samples still increased\\nmostly constant and the decrease of model uncertainty was not signiﬁcant.', 'This\\nHowever, observing the KDE model, due to\\nits high rejection fraction of model uncertainty, the addition of new samples still increased\\nthe model’s performance.\\nFurthermore, the nonrejected accuracy was always higher than\\nthe baseline accuracy, and it was mostly constant across the different training sizes.\\ndata did not improve the model’s performance.', 'This\\nmeans that the model uncertainty measure was in fact detecting the regions in the feature\\nspace responsible for a high number of misclassiﬁcations due to a poor model ﬁt.\\n4.1.2.\\nthe model’s performance.\\nFurthermore, the nonrejected accuracy was always higher than\\nthe baseline accuracy, and it was mostly constant across the different training sizes.\\nUncertainty for Models’ Combination (Q2)', 'space responsible for a high number of misclassiﬁcations due to a poor model ﬁt.\\n4.1.2.\\nUncertainty for Models’ Combination (Q2)\\nFrom the analysis of the previous question, we observed that different models had\\ndifferent degrees of uncertainty for the same training size.\\nSince different models were\\nbased on different assumptions, we hypothesized that uncertainty measures can be used', 'Since different models were\\nbased on different assumptions, we hypothesized that uncertainty measures can be used\\nto combine different models, producing a more robust model.\\nIn order to validate this\\nhypothesis, a new dataset composed of 150,000 ten-dimensional points corresponding to\\ndifferent degrees of uncertainty for the same training size.', 'In order to validate this\\nhypothesis, a new dataset composed of 150,000 ten-dimensional points corresponding to\\nsix different classes equally distributed and modeled as a bimodal Gaussian distribution\\nwas generated.\\n\\nto combine different models, producing a more robust model.\\nA Gaussian NB and a KDE Bayes classiﬁer were trained with a bootstrap approach', 'As the Gaussian model uses\\nsix different classes equally distributed and modeled as a bimodal Gaussian distribution\\nwas generated.\\n\\nA Gaussian NB and a KDE Bayes classiﬁer were trained with a bootstrap approach\\nwith 20 bootstrap samples.\\nFigure 5 shows the rejection fraction and accuracy with the\\nincreasing number of training samples for both models.', 'Figure 5 shows the rejection fraction and accuracy with the\\nincreasing number of training samples for both models.\\nwith 20 bootstrap samples.\\nAs the Gaussian model uses\\nunimodal distributions to ﬁt the features data and the dataset was composed of features\\nmodeled as bimodal Gaussian distributions, the Gaussian NB classiﬁer presented a high', 'unimodal distributions to ﬁt the features data and the dataset was composed of features\\nmodeled as bimodal Gaussian distributions, the Gaussian NB classiﬁer presented a high\\nrejection fraction due to aleatoric uncertainty, since the overlap between the ﬁt distributions\\nwas high.\\nContrarily, the KDE Bayes classiﬁer deals well with bimodal distributions, which', 'Contrarily, the KDE Bayes classiﬁer deals well with bimodal distributions, which\\nresulted in a low overlap between classes, obtaining a low rejection fraction due to aleatoric\\nuncertainty.\\nRegarding model uncertainty, although both models started with a high\\nrejection fraction due to aleatoric uncertainty, since the overlap between the ﬁt distributions\\nwas high.', 'In\\nRegarding model uncertainty, although both models started with a high\\nrejection fraction, the Gaussian NB reached 105training samples with almost zero rejection,\\nand the KDE model, due to its complexity, still had a 10% rejection rate, approximately.\\nresulted in a low overlap between classes, obtaining a low rejection fraction due to aleatoric\\nuncertainty.', 'rejection fraction, the Gaussian NB reached 105training samples with almost zero rejection,\\nand the KDE model, due to its complexity, still had a 10% rejection rate, approximately.\\nIn\\nsummary, the Gaussian NB had high aleatoric uncertainty and low model uncertainty, and\\nthe KDE Bayes classiﬁer had low aleatoric uncertainty and high model uncertainty.', '=0\\nˆw=8\\n>>>><\\n>>>>:fc1(x) ifFc1(x) =0 and Fc2(x)>0\\nfc2(x) ifFc1(x)>0 and Fc2(x)\\nsummary, the Gaussian NB had high aleatoric uncertainty and low model uncertainty, and\\nthe KDE Bayes classiﬁer had low aleatoric uncertainty and high model uncertainty.\\n\\nTo verify the potential for combining both models using uncertainty measures, the\\nfollowing combination rules were applied:\\n', 'following combination rules were applied:\\n\\n=0\\nfc1(x) ifFc1(x) =0 and Fc2(x) =0 and fc1(x) = fc2(x)\\nreject otherwise(16)\\nwhere c1and c2represent the Gaussian NB and KDE Bayes classiﬁer and Fcis the uncer-\\ntainty function deﬁned in Equation (14).\\nˆw=8\\n>>>><\\n>>>>:fc1(x) ifFc1(x) =0 and Fc2(x)>0\\nfc2(x) ifFc1(x)>0 and Fc2(x)', 'fc1(x) ifFc1(x) =0 and Fc2(x) =0 and fc1(x) = fc2(x)\\nreject otherwise(16)\\nwhere c1and c2represent the Gaussian NB and KDE Bayes classiﬁer and Fcis the uncer-\\ntainty function deﬁned in Equation (14).\\n\\n[33] .\\nTo validate that the proposed combination strategy performed better than the individual\\nmodels, we applied the performance measures proposed in the work of Condessa et al.', 'To validate that the proposed combination strategy performed better than the individual\\nmodels, we applied the performance measures proposed in the work of Condessa et al.\\nTo compare the performance of the classifiers with rejection, 10% of the rejected samples were\\nused with the highest training size available ( \\x1890,000 training samples).\\n[33] .\\n', 'In Table 2, the obtained results for the three models using a 10% rejection fraction\\nare shown.\\nTo compare the performance of the classifiers with rejection, 10% of the rejected samples were\\nused with the highest training size available ( \\x1890,000 training samples).\\n\\nThe combination strategy using the uncertainties of both individual modelsElectronics 2022 ,11, 396 13 of 20', '0.00.20.4Rejection Fraction\\nGuassian Naive Bayes\\n KDE Model\\nAleatoric\\nModel\\n103104105\\nThe combination strategy using the uncertainties of both individual modelsElectronics 2022 ,11, 396 13 of 20\\nresulted in higher values for the three performance measures for classiﬁers with rejection,\\nnamely the nonrejected accuracy, classiﬁcation quality, and rejection quality.\\n\\nare shown.', 'namely the nonrejected accuracy, classiﬁcation quality, and rejection quality.\\n\\n0.00.20.4Rejection Fraction\\nGuassian Naive Bayes\\n KDE Model\\nAleatoric\\nModel\\n103104105\\n# train samples0.70.80.9Accuracy\\n103104105\\n# train samples\\nBaseline\\nNRA\\nFigure 5.\\nUncertainties’ rejection fraction and obtained accuracies using a k-fold cross-validation', 'These preliminary results showed that the access to uncertainty estimations during\\nUncertainties’ rejection fraction and obtained accuracies using a k-fold cross-validation\\nwith an increasing number of training samples for Gaussian NB and KDE Bayes models.\\n\\nAleatoric\\nModel\\n103104105\\n# train samples0.70.80.9Accuracy\\n103104105\\n# train samples\\nBaseline\\nNRA\\nFigure 5.', 'Although a simpler model, such as an NB classiﬁer, can have a lower performance\\nThese preliminary results showed that the access to uncertainty estimations during\\nthe model’s development might be a useful source of information to develop more robust\\nmodels.\\nwith an increasing number of training samples for Gaussian NB and KDE Bayes models.\\n', 'Using this\\nAlthough a simpler model, such as an NB classiﬁer, can have a lower performance\\nin comparison with more complex models, the use of uncertainty estimations can provide\\ninformation about the speciﬁc regions where the model has low uncertainty.\\nthe model’s development might be a useful source of information to develop more robust\\nmodels.', 'Table 2.\\nUsing this\\ninformation in combination with more powerful models can in fact increase the overall\\nmodel performance.\\n\\nin comparison with more complex models, the use of uncertainty estimations can provide\\ninformation about the speciﬁc regions where the model has low uncertainty.\\nPerformance measures for individual models (Gaussian naive Bayes and KDE Bayes) and', 'ModelNonrejected Classiﬁcation Rejection\\nAccuracy Quality Quality\\nPerformance measures for individual models (Gaussian naive Bayes and KDE Bayes) and\\na combination of both models.\\nThe results were obtained using a rejection fraction of 10% and a\\ntraining size of 90,000 samples.\\n\\nTable 2.\\ninformation in combination with more powerful models can in fact increase the overall\\nmodel performance.\\n', 'a combination of both models.\\nThe results were obtained using a rejection fraction of 10% and a\\ntraining size of 90,000 samples.\\n\\nModelNonrejected Classiﬁcation Rejection\\nAccuracy Quality Quality\\nGaussian Naive Bayes 0.72 0.72 2.60\\nKDE Bayes 0.85 0.82 5.84\\nModel’s Combination 0.86 0.83 6.89\\n4.1.3.\\nUncertainty Visualization (Q3)', 'Uncertainty Visualization (Q3)\\nTo use ML in high-stakes applications, we need auditing tools to build conﬁdence in\\nthe models and their decisions.\\nModelNonrejected Classiﬁcation Rejection\\nAccuracy Quality Quality\\nGaussian Naive Bayes 0.72 0.72 2.60\\nKDE Bayes 0.85 0.82 5.84\\nModel’s Combination 0.86 0.83 6.89\\n4.1.3.\\nBesides quantiﬁcation metrics, visualization techniques', 'Besides quantiﬁcation metrics, visualization techniques\\nhave been used to support the interpretability of classiﬁcation models.\\nTo use ML in high-stakes applications, we need auditing tools to build conﬁdence in\\nthe models and their decisions.\\nTherefore, to answer\\nthis question, we quantiﬁed the different sources of uncertainty using visualization methods', 'Therefore, to answer\\nthis question, we quantiﬁed the different sources of uncertainty using visualization methods\\nto assist in interpreting the models’ uncertainty during model development and also to\\naudit a given decision.\\n\\nFor uncertainty visualization, the dataset from Section 4.1.2 with a training size of\\nhave been used to support the interpretability of classiﬁcation models.', 'For uncertainty visualization, the dataset from Section 4.1.2 with a training size of\\n2.6\\x02104was used.\\nTo simulate a realistic real-world setting, some outliers were addedElectronics 2022 ,11, 396 14 of 20\\nto assist in interpreting the models’ uncertainty during model development and also to\\naudit a given decision.\\n', 'Fifty outliers per\\nclass were generated, resulting in a total of 300 outliers.\\nTo simulate a realistic real-world setting, some outliers were addedElectronics 2022 ,11, 396 14 of 20\\nto the test set.\\nThese outliers were generated from a Gaussian distribution that had a\\ncovariance matrix that is four-times larger than that of the dataset itself.\\n2.6\\x02104was used.', 'Fifty outliers per\\nclass were generated, resulting in a total of 300 outliers.\\n\\nIn Figure 6, an overview of the uncertainty estimation obtained during the model’s\\ndevelopment is shown.\\ncovariance matrix that is four-times larger than that of the dataset itself.\\nIn this visualization, the x-axis represents the number of samples', 'In this visualization, the x-axis represents the number of samples\\nwhere samples are ordered by uncertainty.\\nIn Figure 6, an overview of the uncertainty estimation obtained during the model’s\\ndevelopment is shown.\\nUsing this ordering scheme, it was possible\\nto interpret the overall dataset uncertainty (upper bar), as well as the proportion of the', 'Using this ordering scheme, it was possible\\nto interpret the overall dataset uncertainty (upper bar), as well as the proportion of the\\ndifferent sources of uncertainty across the dataset (lower bars).\\nThe size of each bar\\nrepresents the number of samples rejected by each type of uncertainty.\\nwhere samples are ordered by uncertainty.\\nFurthermore, this', 'Furthermore, this\\nvisualization allowed us to make some observations, such as noting that all rejected samples\\nby model uncertainty were also rejected by aleatoric uncertainty.\\n0.0 0.2 0.4 0.6 0.8 1.0\\n# Samples1e4Uncertain\\nThe size of each bar\\nrepresents the number of samples rejected by each type of uncertainty.\\ndifferent sources of uncertainty across the dataset (lower bars).', 'Overview of the overall dataset uncertainty ( upper bar ) and uncertainties distribution by\\nthe uncertainty source ( lower bars ).\\nby model uncertainty were also rejected by aleatoric uncertainty.\\n0.0 0.2 0.4 0.6 0.8 1.0\\n# Samples1e4Uncertain\\n0.0 1.0 2.0 3.0 4.0 5.0\\n# Uncertain Samples1e3Aleatoric\\nModel\\nKnowledge\\nFigure 6.', 'Analyzing the\\nuncertainty by each class can give us insights about the particular limitations of the model\\nOverview of the overall dataset uncertainty ( upper bar ) and uncertainties distribution by\\nthe uncertainty source ( lower bars ).\\n\\n# Uncertain Samples1e3Aleatoric\\nModel\\nKnowledge\\nFigure 6.\\nSimilarly, this representation can be applied to each individual class.', 'Note that almost all samples with knowledge uncertainty from Figure 6 were the generated\\nFigure 7 presents the obtained uncertainty by uncertainty source and class.\\n\\nAnalyzing the\\nuncertainty by each class can give us insights about the particular limitations of the model\\nbeing used.\\nSimilarly, this representation can be applied to each individual class.', 'Uncertain Samples1e20.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Samples1e3Class 1\\nFigure 7 presents the obtained uncertainty by uncertainty source and class.\\n\\nbeing used.\\nNote that almost all samples with knowledge uncertainty from Figure 6 were the generated\\noutliers and do not have a representation in Figure 7.\\n0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Samples1e3Class 0\\n0.0 1.0 2.0 3.0 4.0 5.0 6.0\\n#', 'Samples1e3Class 2\\nUncertain\\n0.0 2.0 4.0 6.0 8.0\\n# Uncertain Samples1e2Aleatoric\\nModel\\nKnowledge\\n0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Samples1e3Class 3\\nUncertain Samples1e20.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n#\\nUncertain Samples1e20.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Samples1e3Class 1\\n0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0\\n#\\n0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Samples1e3Class 0\\n0.0 1.0 2.0 3.0 4.0 5.0 6.0\\n#', 'Uncertain Samples1e20.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Samples1e3Class 5\\n0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0\\n# Uncertain Samples1e2\\n0.0 2.0 4.0 6.0 8.0\\n# Uncertain Samples1e20.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Samples1e3Class 4\\n0.0 2.0 4.0 6.0 8.0\\n#\\n# Samples1e3Class 2\\nUncertain\\n0.0 2.0 4.0 6.0 8.0\\n# Uncertain Samples1e2Aleatoric\\nModel\\nKnowledge\\n0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Samples1e3Class 3\\n', 'Uncertainty distribution by uncertainty source and class.\\n\\n# Samples1e3Class 4\\n0.0 2.0 4.0 6.0 8.0\\n# Uncertain Samples1e20.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Samples1e3Class 5\\n0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0\\n# Uncertain Samples1e2\\nFigure 7.\\nBesides the visualization applied to the overall classiﬁer’s uncertainty, an alternative', 'Besides the visualization applied to the overall classiﬁer’s uncertainty, an alternative\\nis to audit the reliability of a given prediction, answering questions such as: Can I trust this\\nprediction?\\nWhy did I reject this sample?Electronics 2022 ,11, 396 15 of 20\\nUncertainty distribution by uncertainty source and class.\\n\\n# Uncertain Samples1e2\\nFigure 7.', 'Why did I reject this sample?Electronics 2022 ,11, 396 15 of 20\\nFor this purpose, using the uncertainty estimations for each type of uncertainty,\\nFigure 8 was obtained.\\nis to audit the reliability of a given prediction, answering questions such as: Can I trust this\\nprediction?\\nIn this visualization, the bar’s size represents how much the', 'For this purpose, using the uncertainty estimations for each type of uncertainty,\\nFigure 8 was obtained.\\nTo make the\\nvisualization more intuitive, 0 conﬁdence/uncertainty represents the obtained threshold\\nIn this visualization, the bar’s size represents how much the\\nmodel is conﬁdent or uncertain about a prediction by uncertainty type.', 'To make the\\nvisualization more intuitive, 0 conﬁdence/uncertainty represents the obtained threshold\\nfor rejecting a sample.\\nThen, the bars’ sizes where normalized between 0 and 1 by the\\nmaximum/minimum theoretical value for each uncertainty.\\n\\nNote that, in the aleatoric uncertainty, we visualize the prediction’s expected data\\nmodel is conﬁdent or uncertain about a prediction by uncertainty type.', 'Note that, in the aleatoric uncertainty, we visualize the prediction’s expected data\\nentropy, meaning that in Figure 8a, the prediction probability was near 100% (entropy of 0).\\n\\nIn the case of Figure 8b, the obtained entropy was greater than the deﬁned threshold for\\nmaximum/minimum theoretical value for each uncertainty.\\n', 'entropy, meaning that in Figure 8a, the prediction probability was near 100% (entropy of 0).\\n\\nIn the case of Figure 8b, the obtained entropy was greater than the deﬁned threshold for\\nrejection and its value represents approximately 1/3 of the entropies that range between\\n1 and the rejection threshold.\\nIn the case of model uncertainty, we evaluated if a given', 'In the case of model uncertainty, we evaluated if a given\\nprediction changes between different bootstrap samples, i.e., the bar’s size represents the\\nnormalized variation ratios.\\nIn Figure 8a, the prediction was the same in all bootstrap\\nrejection and its value represents approximately 1/3 of the entropies that range between\\n1 and the rejection threshold.', 'In Figure 8a, the prediction was the same in all bootstrap\\nsamples, obtaining a maximum conﬁdence value, and in Figure 8b, the prediction changed\\nhalf the total number of possibilities, which are given by the number of bootstrap samples\\nprediction changes between different bootstrap samples, i.e., the bar’s size represents the\\nnormalized variation ratios.', 'samples, obtaining a maximum conﬁdence value, and in Figure 8b, the prediction changed\\nhalf the total number of possibilities, which are given by the number of bootstrap samples\\nand the number of classes.\\nFor instance, this dataset had 6 classes and 20 bootstrap samples\\nwere used, meaning that the maximum variation ratio was 0.8, and the prediction from', 'Finally, the knowledge uncertainty represents\\nhow much a prediction is similar to the training dataset, in terms of probability density.\\nFor instance, this dataset had 6 classes and 20 bootstrap samples\\nwere used, meaning that the maximum variation ratio was 0.8, and the prediction from\\nFigure 8b obtained a variation ratio of 0.4.\\nand the number of classes.', 'Finally, the knowledge uncertainty represents\\nhow much a prediction is similar to the training dataset, in terms of probability density.\\n\\nThus, Figure 8a represents a prediction where the combination of the features density\\nresulted in a KDE value close to the rejection threshold, i.e., few training samples were\\nFigure 8b obtained a variation ratio of 0.4.', 'Thus, Figure 8a represents a prediction where the combination of the features density\\nresulted in a KDE value close to the rejection threshold, i.e., few training samples were\\nsimilar to this prediction.\\nIn the case of Figure 8b, the sample was more similar to the\\nsamples in the training dataset.\\n1.0\\n 0.5\\n 0.0 0.5 1.0\\nConfidenceMore\\nConfidentMore\\nUncertainAleatoric\\nModel', 'In the case of Figure 8b, the sample was more similar to the\\nsamples in the training dataset.\\n1.0\\n 0.5\\n 0.0 0.5 1.0\\nConfidenceMore\\nConfidentMore\\nUncertainAleatoric\\nModel\\nKnowledgePredicted Class: 0\\n(a)\\n1.0\\n 0.5\\n 0.0 0.5 1.0\\nConfidenceMore\\nConfidentMore\\nUncertainAleatoric\\nModel\\nKnowledgePredicted Class: 4 (b)\\nsimilar to this prediction.', 'Bars’ sizes are normalized between the maximum theoretical\\nConfidenceMore\\nConfidentMore\\nUncertainAleatoric\\nModel\\nKnowledgePredicted Class: 0\\n(a)\\n1.0\\n 0.5\\n 0.0 0.5 1.0\\nConfidenceMore\\nConfidentMore\\nUncertainAleatoric\\nModel\\nKnowledgePredicted Class: 4 (b)\\nFigure 8.\\nA conﬁdence value of 0 represents the obtained threshold for reject-\\ning a sample by the uncertainty source.\\nPrediction uncertainty.', 'ing a sample by the uncertainty source.\\n( a) Prediction not rejected by all uncertainty sources.\\n( b) Prediction rejected\\nby aleatoric and model uncertainty.\\n4.2.\\nBars’ sizes are normalized between the maximum theoretical\\nconﬁdence/uncertainty.\\nExperiments on a Human Activity Recognition\\nDataset\\nIn order to broaden our analysis, we conducted an additional experiment with a', 'Dataset\\nIn order to broaden our analysis, we conducted an additional experiment with a\\nbenchmark dataset from the UCI repository [ 38].\\nAs a case study, we selected a Human\\nActivity Recognition (HAR) dataset\\n[39] that contains six classes ( walking ,walking upstairs ,\\nExperiments on a Human Activity Recognition\\nby aleatoric and model uncertainty.\\n4.2.', '[39] that contains six classes ( walking ,walking upstairs ,\\nwalking downstairs ,sitting ,standing , and laying ), recorded with the accelerometer and\\ngyroscope smartphone sensors.\\nBesides the importance of UQ for trustworthy ML systems,\\nAs a case study, we selected a Human\\nActivity Recognition (HAR) dataset\\nbenchmark dataset from the UCI repository [ 38].', 'walking downstairs ,sitting ,standing , and laying ), recorded with the accelerometer and\\ngyroscope smartphone sensors.\\nBesides the importance of UQ for trustworthy ML systems,\\nthe use of uncertainty measures for human movements analysis plays also an important role\\nin the recognition of abnormal human activities or the analysis, diagnosis, and monitoring', 'the use of uncertainty measures for human movements analysis plays also an important role\\nin the recognition of abnormal human activities or the analysis, diagnosis, and monitoring\\nof neurodegenerative conditions [ 40].\\nFurthermore, the high number of available samples\\n(10,299 samples) in this dataset allowed us to make a similar evaluation to the synthetic', 'Furthermore, the high number of available samples\\n(10,299 samples) in this dataset allowed us to make a similar evaluation to the synthetic\\ndata.\\nFor the data split into training and test sets, we used the available partition in the\\nrepository, where 70% of the volunteers were selected for generating the training data and\\nof neurodegenerative conditions [ 40].', 'For the data split into training and test sets, we used the available partition in the\\nrepository, where 70% of the volunteers were selected for generating the training data and\\n30% the test data.\\nRegarding the feature vector, the original 561-feature vector with time\\nand frequency domain variables was reduced using features correlation and the sequential\\ndata.', 'Electronics 2022 ,11, 396 16 of 20\\nSimilar to Section 4.1.1, we applied a training size exponential growth, starting with\\nRegarding the feature vector, the original 561-feature vector with time\\nand frequency domain variables was reduced using features correlation and the sequential\\nforward feature selector, resulting in a 17-dimensional feature vector.\\n30% the test data.', 'Table 3 shows the\\nElectronics 2022 ,11, 396 16 of 20\\nSimilar to Section 4.1.1, we applied a training size exponential growth, starting with\\n300 samples (50 per class) until the maximum training size of 7352 samples.\\nforward feature selector, resulting in a 17-dimensional feature vector.\\nFor model\\ntraining, we tested different classiﬁers with 20 bootstrap samples.', 'To visualize the behavior of accuracy and the corresponding\\nTable 3 shows the\\nobtained baseline accuracy, as well as the nonrejected accuracy and the rejection fraction for\\neach of the tested classiﬁers.\\nFor model\\ntraining, we tested different classiﬁers with 20 bootstrap samples.\\n300 samples (50 per class) until the maximum training size of 7352 samples.', 'Figure 9 shows these performance measures with the increased number\\nTo visualize the behavior of accuracy and the corresponding\\nrejection fraction for each type of uncertainty, we selected the 4 models that obtained higher\\nbaseline accuracy.\\nobtained baseline accuracy, as well as the nonrejected accuracy and the rejection fraction for\\neach of the tested classiﬁers.', 'ModelBaseline Nonrejected Rejection\\nTable 3.\\nFigure 9 shows these performance measures with the increased number\\nof samples used to train the classiﬁers.\\n\\nrejection fraction for each type of uncertainty, we selected the 4 models that obtained higher\\nbaseline accuracy.\\nPerformance measures for different models using a training size of 7352 samples and the\\nHuman Activity Recognition (HAR) dataset.\\n', 'ModelBaseline Nonrejected Rejection\\nAccuracy Accuracy Fraction\\nGaussian Naive Bayes 0.89 0.90 0.03\\nKDE Bayes 0.88 0.92 0.12\\nLogistic Regression 0.89 0.92 0.06\\nDecision Tree 0.82 0.92 0.23\\nRandom Forest 0.84 0.91 0.16\\nk-Nearest Neighbors 0.87 0.94 0.13\\nPerformance measures for different models using a training size of 7352 samples and the\\nHuman Activity Recognition (HAR) dataset.\\n\\nTable 3.', 'Gaussian Naive Bayes 0.89 0.90 0.03\\nKDE Bayes 0.88 0.92 0.12\\nLogistic Regression 0.89 0.92 0.06\\nDecision Tree 0.82 0.92 0.23\\nRandom Forest 0.84 0.91 0.16\\nk-Nearest Neighbors 0.87 0.94 0.13\\nSupport Vector Machines 0.91 0.93 0.06\\n0.00.10.20.3Rejection Fraction\\nGuassian Naive Bayes\\n KDE Bayes\\n Support Vector Machines\\n Logistic Regression\\nAleatoric\\nModel\\nKnowledge\\n103104', 'Support Vector Machines 0.91 0.93 0.06\\n0.00.10.20.3Rejection Fraction\\nGuassian Naive Bayes\\n KDE Bayes\\n Support Vector Machines\\n Logistic Regression\\nAleatoric\\nModel\\nKnowledge\\n103104\\n# train samples0.800.850.900.951.00Accuracy\\n103104\\n# train samples\\n103104\\n# train samples\\n103104\\n# train samples\\nBaseline\\nNRA', 'Uncertainties’ rejection fraction and obtained accuracies with the increasing number of\\ntraining samples for the Human Activity Recognition (HAR) dataset.\\nLogistic Regression\\nAleatoric\\nModel\\nKnowledge\\n103104\\n# train samples0.800.850.900.951.00Accuracy\\n103104\\n# train samples\\n103104\\n# train samples\\n103104\\n# train samples\\nBaseline\\nNRA\\nFigure 9.', 'Uncertainties’ rejection fraction and obtained accuracies with the increasing number of\\ntraining samples for the Human Activity Recognition (HAR) dataset.\\n\\n103104\\n# train samples\\nBaseline\\nNRA\\nFigure 9.\\nFor the HAR dataset, the rejection fraction obtained with both the aleatoric and\\nknowledge uncertainty measures presented a low value for all training sizes and classiﬁers', 'As expected, regarding the model uncertainty, the rejection fraction\\ndecreased with the increasing number of training samples for all classiﬁers, where more\\nFor the HAR dataset, the rejection fraction obtained with both the aleatoric and\\nknowledge uncertainty measures presented a low value for all training sizes and classiﬁers\\nbeing analyzed.', 'As expected, regarding the model uncertainty, the rejection fraction\\ndecreased with the increasing number of training samples for all classiﬁers, where more\\ncomplex classiﬁers had a higher rejection fraction than simpler classiﬁers.\\nbeing analyzed.\\nDue to the low\\nobtained uncertainty (rejection fraction < 4%) and satisfactory accuracy (baseline accuracy', 'Due to the low\\nobtained uncertainty (rejection fraction < 4%) and satisfactory accuracy (baseline accuracy\\nof 89%), the Gaussian NB classiﬁer was selected.\\n\\ncomplex classiﬁers had a higher rejection fraction than simpler classiﬁers.\\nUsing the visualization scheme presented in Section 4.1.3, Figure 10 shows the overall', 'Using the visualization scheme presented in Section 4.1.3, Figure 10 shows the overall\\ndataset uncertainty and the uncertainty type distribution across the uncertain samples.\\n\\nof 89%), the Gaussian NB classiﬁer was selected.\\n\\nAlthough only 4% of the test samples were rejected, we can make some observations about', 'The majority of uncertain samples rejected by aleatoric uncertainty\\nwere also rejected by model uncertainty.\\ndataset uncertainty and the uncertainty type distribution across the uncertain samples.\\n\\nAlthough only 4% of the test samples were rejected, we can make some observations about\\nthe uncertain samples.\\nRegions with an overlap between classes (aleatoric', 'The majority of uncertain samples rejected by aleatoric uncertainty\\nwere also rejected by model uncertainty.\\nthe uncertain samples.\\nRegions with an overlap between classes (aleatoric\\nuncertainty) were also regions where it was expected that the model ﬁt would change\\nbetween bootstrap samples.\\nIn the case of knowledge uncertainty, it was expected that', 'In the case of knowledge uncertainty, it was expected that\\nsamples with knowledge uncertainty would not have aleatoric uncertainty.\\nHowever, forElectronics 2022 ,11, 396 17 of 20\\nmodel uncertainty, it is possible that some samples shared both model and knowledge\\nuncertainty) were also regions where it was expected that the model ﬁt would change\\nbetween bootstrap samples.', 'model uncertainty, it is possible that some samples shared both model and knowledge\\nuncertainty, which is also veriﬁed with Figure 10.\\n0.0 0.5 1.0 1.5 2.0 2.5\\n# Samples1e3Uncertain\\n0.0 0.2 0.4 0.6 0.8 1.0\\n# Uncertain Samples1e2Aleatoric\\nModel\\nKnowledge\\nFigure 10.\\nFigure 11 shows the uncertainty distribution by class.\\nHAR dataset uncertainty overview.\\n\\nFrom it, we can conclude that', 'It is also possible to\\nFrom it, we can conclude that\\naleatoric uncertainty was presented only in walking ,walking upstairs and walking downstairs ,\\nwhich makes perfect sense due to the similarity of these three classes.\\nFigure 11 shows the uncertainty distribution by class.\\nHAR dataset uncertainty overview.\\n\\n# Uncertain Samples1e2Aleatoric\\nModel\\nKnowledge\\nFigure 10.', 'However, it was the class\\nwith the highest knowledge uncertainty.\\naleatoric uncertainty was presented only in walking ,walking upstairs and walking downstairs ,\\nwhich makes perfect sense due to the similarity of these three classes.\\nIt is also possible to\\nnote that laying class did not have aleatoric or model uncertainty.\\nBoth sitting and standing classes had a similar', '0.0 1.0 2.0 3.0 4.0\\n# Samples1e2Walking\\n0.0 1.0 2.0 3.0 4.0 5.0\\n# Uncertain Samples0.0 1.0 2.0 3.0 4.0\\nHowever, it was the class\\nwith the highest knowledge uncertainty.\\nBoth sitting and standing classes had a similar\\npattern in terms of uncertainty, where the sitting class was the one with the highest number\\nof uncertain samples.\\n\\nnote that laying class did not have aleatoric or model uncertainty.', '0.0 1.0 2.0 3.0 4.0\\n# Samples1e2Walking\\n0.0 1.0 2.0 3.0 4.0 5.0\\n# Uncertain Samples0.0 1.0 2.0 3.0 4.0\\n# Samples1e2Walking Upstairs\\n0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8\\n# Uncertain Samples1e10.0 1.0 2.0 3.0 4.0\\n# Samples1e2Walking Downstairs\\nUncertain\\n0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0\\n# Uncertain SamplesAleatoric\\nModel\\nKnowledge\\n0.0 1.0 2.0 3.0 4.0\\n# Samples1e2Sitting\\nof uncertain samples.\\n', '1.0 2.0 3.0 4.0 5.0\\n# Samples1e2Standing\\n0.0 0.5 1.0 1.5 2.0\\n# Uncertain Samples1e10.0 1.0 2.0 3.0 4.0 5.0\\n# Samples1e2Laying\\n0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8 2.0\\n# Uncertain Samples1e1\\n# Samples1e2Walking Downstairs\\nUncertain\\n0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0\\n# Uncertain SamplesAleatoric\\nModel\\nKnowledge\\n0.0 1.0 2.0 3.0 4.0\\n# Samples1e2Sitting\\n0.0 1.0 2.0 3.0 4.0\\n# Uncertain Samples1e10.0', 'To validate the combination strategy proposed in Section 4.1.2 using a real dataset,\\nwe decided to combine the two models with lower accuracy and higher uncertainty.\\nHAR dataset uncertainty overview by class.\\n\\n# Samples1e2Standing\\n0.0 0.5 1.0 1.5 2.0\\n# Uncertain Samples1e10.0 1.0 2.0 3.0 4.0 5.0\\n# Samples1e2Laying\\n0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8 2.0\\n# Uncertain Samples1e1\\nFigure 11.\\nThus,', 'Thus,\\nthe KDE Bayes model and logistic regression were combined for the different training\\nsizes.\\nTo validate the combination strategy proposed in Section 4.1.2 using a real dataset,\\nwe decided to combine the two models with lower accuracy and higher uncertainty.\\nTo compare the performance of classiﬁers with rejection, we needed to ensure', 'To compare the performance of classiﬁers with rejection, we needed to ensure\\nthe same rejection fraction for the three classiﬁers.\\nThus, the obtained rejection fraction\\nfor the models’ combination, given by Equation (16), was employed for both the KDE\\nthe KDE Bayes model and logistic regression were combined for the different training\\nsizes.', 'Observing\\nThus, the obtained rejection fraction\\nfor the models’ combination, given by Equation (16), was employed for both the KDE\\nBayes and logistic regression classiﬁers.\\nFigure 12 shows the performance measures for\\nclassiﬁcation with rejection for the individual models and their combination.\\nthe same rejection fraction for the three classiﬁers.', 'It is also interesting\\nFigure 12 shows the performance measures for\\nclassiﬁcation with rejection for the individual models and their combination.\\nBayes and logistic regression classiﬁers.\\nObserving\\nthe results, we can conclude that the combination strategy outperformed the individual\\nclassiﬁers for almost all training sizes and performance measures.', 'It is also interesting\\nto note that the combination strategy resulted always in a lower rejection fraction thanElectronics 2022 ,11, 396 18 of 20\\nthe obtained rejection fraction for the individual classiﬁers, which can be conﬁrmed by\\nthe results, we can conclude that the combination strategy outperformed the individual\\nclassiﬁers for almost all training sizes and performance measures.', 'Fraction\\nthe obtained rejection fraction for the individual classiﬁers, which can be conﬁrmed by\\nanalyzing Figures 9 and 12.\\n103104\\n# train samples0.8000.8250.8500.8750.9000.9250.950Nonrejected Accuracy\\n103104\\n# train samples0.800.820.840.860.880.90Classification Quality\\n103104\\n# train samples2.55.07.510.012.515.0Rejection Quality\\n103104\\n# train samples0.020.040.060.08Rejection', \"Conclusions\\n103104\\n# train samples0.800.820.840.860.880.90Classification Quality\\n103104\\n# train samples2.55.07.510.012.515.0Rejection Quality\\n103104\\n# train samples0.020.040.060.08Rejection\\n5.\\nPerformance measures for classiﬁcation with rejection for different training sizes.\\n\\nFraction\\nKDE Bayes Logistic Regression Models' Combination\\nFigure 12.\", \"5.\\nPerformance measures for classiﬁcation with rejection for different training sizes.\\n\\nKDE Bayes Logistic Regression Models' Combination\\nFigure 12.\\nConclusions\\nAs ML models are increasingly being integrated into safety-critical applications, in-\\ncorporating uncertainty quantiﬁcation estimates should become a required part of the ML\", 'Uncertainty quantiﬁcation can be used for “uncertainty-informed” decisions\\nand to support developers and end-users by increasing the interpretability of and trust in\\nmodel predictions.\\n5.\\nConclusions\\nAs ML models are increasingly being integrated into safety-critical applications, in-\\ncorporating uncertainty quantiﬁcation estimates should become a required part of the ML\\nmethodology.', 'Uncertainty quantiﬁcation can be used for “uncertainty-informed” decisions\\nand to support developers and end-users by increasing the interpretability of and trust in\\nmodel predictions.\\n\\nmethodology.\\nWe introduced a complete study focused on how uncertainty quantiﬁcation can be\\nused in practice through three research questions: (1) How can UQ contribute to choosing', '(2) Can UQ be used to combine\\ndifferent models in a principled manner?\\nWe introduced a complete study focused on how uncertainty quantiﬁcation can be\\nused in practice through three research questions: (1) How can UQ contribute to choosing\\nthe most suitable model for a given classiﬁcation task?\\n(3) Can visualization techniques improve UQ’s\\nmodel predictions.\\n', '(2) Can UQ be used to combine\\ndifferent models in a principled manner?\\nThese questions were answered using a synthetic dataset and a HAR\\ndataset from the UCI repository.\\n\\nthe most suitable model for a given classiﬁcation task?\\n(3) Can visualization techniques improve UQ’s\\ninterpretability?\\nRegarding the ﬁrst question, we showed that uncertainty quantiﬁcation in combination', 'Regarding the ﬁrst question, we showed that uncertainty quantiﬁcation in combination\\nwith the model’s accuracy can give us important elements to choose the most suitable\\nmodel.\\nFor instance, the decision between different classiﬁers with the same accuracy\\ncan beneﬁt from the uncertainty quantiﬁcation methods, whereas classiﬁers with lower\\ndataset from the UCI repository.\\n', 'For instance, the decision between different classiﬁers with the same accuracy\\ncan beneﬁt from the uncertainty quantiﬁcation methods, whereas classiﬁers with lower\\ndegrees of uncertainty can be preferable.\\nFurthermore, if model uncertainty is high and the\\naddition of new samples is possible, the increase of training samples can reduce the model\\nmodel.', 'Furthermore, if model uncertainty is high and the\\naddition of new samples is possible, the increase of training samples can reduce the model\\nuncertainty and consequently increase the model’s accuracy.\\nBy using uncertainty as a\\ncomplement of performance measures, we can make more informed decisions in model\\ndegrees of uncertainty can be preferable.', 'Active learning is the subset of ML in which the learning algorithm\\nIn future work, we will explore how the UQ measures can be used in the context\\nof active learning.\\nBy using uncertainty as a\\ncomplement of performance measures, we can make more informed decisions in model\\nselection.\\nuncertainty and consequently increase the model’s accuracy.', 'Alternative\\nThe choice of the samples to be labeled is achieved\\nthrough measures that rank samples based on their potential informativeness.\\nActive learning is the subset of ML in which the learning algorithm\\nqueries users to label training data.\\nselection.\\nIn future work, we will explore how the UQ measures can be used in the context\\nof active learning.', 'Alternative\\nor complementary ranking measures based on uncertainty can be explored.\\n\\nThe choice of the samples to be labeled is achieved\\nthrough measures that rank samples based on their potential informativeness.\\nqueries users to label training data.\\nBased on two models with different degrees of uncertainty, we proposed a naive', 'The preliminary results showed that the combination strategy outperformed the individual\\nBased on two models with different degrees of uncertainty, we proposed a naive\\nuncertainty combination approach for models’ combination to answer the second question.\\n\\nor complementary ranking measures based on uncertainty can be explored.\\n', 'The preliminary results showed that the combination strategy outperformed the individual\\nmodels.\\nuncertainty combination approach for models’ combination to answer the second question.\\n\\nAlthough the proposed naive approach achieved good results, the combination\\nstrategy presented some limitations for its application in a scenario with more than two', 'Although the proposed naive approach achieved good results, the combination\\nstrategy presented some limitations for its application in a scenario with more than two\\nmodels.\\nmodels.\\nA more versatile combination that considers the possibility of adding more\\nmodels and uses their degree of uncertainty must be developed.\\nTherefore, for future', 'Therefore, for future\\nwork, we will explore more comprehensive model combination methods to address more\\ncomplex problems.\\n\\nmodels.\\nA more versatile combination that considers the possibility of adding more\\nmodels and uses their degree of uncertainty must be developed.\\nIn the third question, we explored visualization techniques to assist in interpreting', 'In the third question, we explored visualization techniques to assist in interpreting\\nclassiﬁers’ uncertainty during the model’s development and also to audit a given decision.\\n\\nwork, we will explore more comprehensive model combination methods to address more\\ncomplex problems.\\n\\nUnderstanding which type of uncertainty is present during the model’s development can', 'classiﬁers’ uncertainty during the model’s development and also to audit a given decision.\\n\\nUnderstanding which type of uncertainty is present during the model’s development can\\ngive us insights into the limitations of each model and allow us to take actions in accordance.\\n\\nIn the context of prediction reliability, the proposed visualization techniques were used to', 'In the context of prediction reliability, the proposed visualization techniques were used to\\naccess the interpretability of the rejection option in which a rejection may correspond to\\na low prediction probability (aleatoric uncertainty), a poor model ﬁt (model uncertainty),\\ngive us insights into the limitations of each model and allow us to take actions in accordance.\\n', 'access the interpretability of the rejection option in which a rejection may correspond to\\na low prediction probability (aleatoric uncertainty), a poor model ﬁt (model uncertainty),\\nor an outlier (knowledge uncertainty).\\nAs a limitation of our study, we identify that anElectronics 2022 ,11, 396 19 of 20\\nindividual rejection threshold for each source of uncertainty may not be a reliable solution', 'individual rejection threshold for each source of uncertainty may not be a reliable solution\\nfor every ML problem.\\nDeﬁning the best rejection threshold is still an open challenge.\\nOur\\nfuture research on this topic will focus on understanding how optimization techniques\\ncan be used to establish the most adequate rejection thresholds, either individually or by', 'future research on this topic will focus on understanding how optimization techniques\\ncan be used to establish the most adequate rejection thresholds, either individually or by\\nunifying the three quantiﬁcation measures.\\n\\nWe hope this paper might spark future research on how to consider uncertainty\\nquantiﬁcation as a tool to improve the ML model development lifecycle.', 'Author Contributions: Conceptualization, M.B. and H.G.; methodology, M.B., D.F. and H.G.;\\nsoftware, M.B.; validation, M.B., D.F. and H.G.; investigation, M.B., D.F., R.S. (Ricardo Santos),\\nunifying the three quantiﬁcation measures.\\n\\nWe hope this paper might spark future research on how to consider uncertainty\\nquantiﬁcation as a tool to improve the ML model development lifecycle.\\n', 'Author Contributions: Conceptualization, M.B. and H.G.; methodology, M.B., D.F. and H.G.;\\nsoftware, M.B.; validation, M.B., D.F. and H.G.; investigation, M.B., D.F., R.S. (Ricardo Santos),\\nR.S. (Raquel Simão) and H.G.; writing—original draft preparation, M.B. and D.F.; writing— review\\nand editing, M.B., D.F., R.S. (Ricardo Santos), R.S. (Raquel Simão) and H.G.; visualization,', 'R.S. (Raquel Simão) and H.G.; writing—original draft preparation, M.B. and D.F.; writing— review\\nand editing, M.B., D.F., R.S. (Ricardo Santos), R.S. (Raquel Simão) and H.G.; visualization,\\nR.S. (Ricardo Santos) and M.B.; supervision, H.G. All authors have read and agreed to the published\\nversion of the manuscript.', 'Funding:\\nR.S. (Ricardo Santos) and M.B.; supervision, H.G.\\nAll authors have read and agreed to the published\\nversion of the manuscript.\\n\\nThis research was ﬁnancially supported by the project Geolocation non-Assisted by GPS\\nfor Mobile Networks in Indoor and Outdoor Environment (GARMIO), co-funded by Portugal 2020,', 'Funding:\\nThis research was ﬁnancially supported by the project Geolocation non-Assisted by GPS\\nfor Mobile Networks in Indoor and Outdoor Environment (GARMIO), co-funded by Portugal 2020,\\nframed under the COMPETE 2020 (Operational Programme Competitiveness and Internationaliza-\\ntion) and European Regional Development Fund (ERDF) from European Union (EU), with Operation', 'framed under the COMPETE 2020 (Operational Programme Competitiveness and Internationaliza-\\ntion) and European Regional Development Fund (ERDF) from European Union (EU), with Operation\\nCode POCI-01-0247-FEDER-033479.\\n\\nInstitutional Review Board Statement: Not applicable\\nInformed Consent Statement: Not applicable.', 'Data Availability Statement: Publicly available datasets were analyzed in this study.\\nInstitutional Review Board Statement: Not applicable\\nInformed Consent Statement: Not applicable.\\n\\nCode POCI-01-0247-FEDER-033479.\\n\\nThese data can\\nbe found at the UC Irvine Machine Learning Repository, available at https://archive.ics.uci.edu/ml/', 'Conﬂicts of Interest:\\nThe authors declare no conﬂict of interest.\\nReferences\\nData Availability Statement: Publicly available datasets were analyzed in this study.\\nThese data can\\nbe found at the UC Irvine Machine Learning Repository, available at https://archive.ics.uci.edu/ml/\\ndatasets/human+activity+recognition+using+smartphones (accessed on 20 December 2021).\\n', 'Conﬂicts of Interest:\\nCobb, A.D.; Jalaian, B.; Bastian, N.D.; Russell, S. Toward Safe Decision-Making via Uncertainty Quantiﬁcation in Machine\\nReferences\\n1.\\nThe authors declare no conﬂict of interest.\\n\\ndatasets/human+activity+recognition+using+smartphones (accessed on 20 December 2021).\\n', 'Conﬂicts of Interest:\\nIn Systems Engineering and Artiﬁcial Intelligence ; Springer: Berlin/Heidelberg, Germany, 2021; pp.\\nCobb, A.D.; Jalaian, B.; Bastian, N.D.; Russell, S. Toward Safe Decision-Making via Uncertainty Quantiﬁcation in Machine\\nLearning.\\n379–399.\\nReferences\\n1.\\nThe authors declare no conﬂict of interest.\\n', '[CrossRef]\\nIn Systems Engineering and Artiﬁcial Intelligence ; Springer: Berlin/Heidelberg, Germany, 2021; pp.\\nInf. Sci. 2014 ,255, 16–29.\\nSenge, R.; Bösner, S.; Dembczy´ nski, K.; Haasenritter, J.; Hirsch, O.; Donner-Banzhoff, N.; Hüllermeier, E. Reliable classiﬁcation:\\n\\nLearning classiﬁers that distinguish aleatoric and epistemic uncertainty.\\n2.\\n379–399.\\n\\nLearning.', 'Second opinion needed:\\nNPJ Digit.\\nMed. 2021 ,4, 1–6.\\nInf. Sci. 2014 ,255, 16–29.\\n[CrossRef] [PubMed]\\n4.\\nCommunicating uncertainty in medical machine learning.\\n[CrossRef]\\n3.\\nLearning classiﬁers that distinguish aleatoric and epistemic uncertainty.\\nKompa, B.; Snoek, J.; Beam, A.L.\\nHüllermeier, E.; Waegeman, W. Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and', 'arXiv 2021 , arXiv:2110.12122.\\nLearn. 2021 ,110, 457–506.\\nMed. 2021 ,4, 1–6.\\n[CrossRef]\\n5. Huang, Z.; Lam, H.; Zhang, H. Quantifying Epistemic Uncertainty in Deep Learning.\\nHüllermeier, E.; Waegeman, W. Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and\\nmethods.\\nMach.\\n[CrossRef] [PubMed]\\n4.', '[CrossRef] [PubMed]\\n2019 ,9, e1312.\\narXiv 2021 , arXiv:2110.12122.\\n\\nLearn. 2021 ,110, 457–506.\\n[CrossRef]\\n5. Huang, Z.; Lam, H.; Zhang, H. Quantifying Epistemic Uncertainty in Deep Learning.\\nDiscov.\\nRev. Data Min. Knowl.\\nWiley Interdiscip.\\n6.\\nMach.', '[CrossRef] [PubMed]\\n7. Nguyen, V .L.; Shaker, M.H.; Hüllermeier, E. How to measure uncertainty in uncertainty sampling for active learning.\\n2019 ,9, e1312.\\nMach.\\nLearn. 2021 , 1–34.\\n[CrossRef]\\n8. Bota, P .; Silva, J.; Folgado, D.; Gamboa, H. A semi-automatic annotation approach for human activity recognition.\\nDiscov.\\nRev. Data Min. Knowl.\\nWiley Interdiscip.\\nSensors 2019 ,', 'Ghosh, S.; Liao, Q.V .; Ramamurthy, K.N.; Navratil, J.; Sattigeri, P .; Varshney, K.R.; Zhang, Y. Uncertainty Quantiﬁcation 360: A\\n[CrossRef]\\n8. Bota, P .; Silva, J.; Folgado, D.; Gamboa, H. A semi-automatic annotation approach for human activity recognition.\\nSensors 2019 ,\\n19, 501.\\nLearn. 2021 , 1–34.\\n[CrossRef] [PubMed]\\n9.', 'arXiv 2021 , arXiv:2106.01410.\\n19, 501.\\nGhosh, S.; Liao, Q.V .; Ramamurthy, K.N.; Navratil, J.; Sattigeri, P .; Varshney, K.R.; Zhang, Y. Uncertainty Quantiﬁcation 360: A\\nHolistic Toolkit for Quantifying and Communicating the Uncertainty of AI.\\n[CrossRef] [PubMed]\\n9.', 'arXiv 2021 , arXiv:2109.10254.\\narXiv 2021 , arXiv:2106.01410.\\n\\nChung, Y.; Char, I.; Guo, H.; Schneider, J.; Neiswanger, W. Uncertainty toolbox: An open-source library for assessing, visualizing,\\nand improving uncertainty quantiﬁcation.\\n10.\\nHolistic Toolkit for Quantifying and Communicating the Uncertainty of AI.', 'arXiv 2021 , arXiv:2109.10254.\\n\\nChoudhary, S.; Fehr, J.; Leite, A.W.; Goldschmidt, P .G.; Johner, C.; Schörverth, E.D.;\\nNakasi, R.; et al.\\nSyst. 2021 ,45, 1–8.\\nOala, L.; Murchison, A.G.; Balachandran, P .;\\nJ. Med.\\nMachine Learning for Health: Algorithm Auditing & Quality Control.\\n11.\\nand improving uncertainty quantiﬁcation.', '[CrossRef]\\nData Anal. 2009 ,13, 385–401.\\nSyst. 2021 ,45, 1–8.\\n12.\\nNakasi, R.; et al.\\nIntell.\\n\\nAn overview of advances in reliability estimation of individual predictions in machine learning.\\nJ. Med.\\nMachine Learning for Health: Algorithm Auditing & Quality Control.\\nBosni´ c, Z.; Kononenko, I.', 'arXiv 2021 , arXiv:2107.09414.\\nData Anal. 2009 ,13, 385–401.\\nBosni´ c, Z.; Kononenko, I.\\nTornede, A.; Gehring, L.; Tornede, T.; Wever, M.; Hüllermeier, E. Algorithm selection on a meta level.\\n[CrossRef]\\n13.\\nIntell.\\n\\nAn overview of advances in reliability estimation of individual predictions in machine learning.\\n12.', '[CrossRef] [PubMed]\\nGraph. 2020 ,27, 1427–1437.\\nData Anal. 2009 ,13, 385–401.\\nPaulovich, F.V .\\nNeto, M.P .;\\narXiv 2021 , arXiv:2107.09414.\\n\\nComput.\\nVis.\\nIEEE Trans.\\nExplainable Matrix-Visualization for Global and Local Interpretability of Random Forest Classiﬁcation\\nEnsembles.', 'Graph. 2020 ,27, 1427–1437.\\narXiv 2021, arXiv:2107.10384.\\n\\nShaker, M.H.; Hüllermeier, E. Ensemble-based Uncertainty Quantification: Bayesian versus Credal Inference.\\nMalinin, A.; Prokhorenkova, L.; Ustimenko, A. Uncertainty in gradient boosting via ensembles.\\n16.\\n[CrossRef] [PubMed]\\n15.\\nComput.\\nVis.\\nIEEE Trans.\\nEnsembles.', 'arXiv 2020 , arXiv:2006.10562.Electronics 2022 ,11, 396 20 of 20\\n17.\\nMalinin, A.; Prokhorenkova, L.; Ustimenko, A. Uncertainty in gradient boosting via ensembles.\\nDepeweg, S.; Hernandez-Lobato, J.M.; Doshi-Velez, F.; Udluft, S. Decomposition of uncertainty in Bayesian deep learning for\\n16.', 'Depeweg, S.; Hernandez-Lobato, J.M.; Doshi-Velez, F.; Udluft, S. Decomposition of uncertainty in Bayesian deep learning for\\nefﬁcient and risk-sensitive learning.\\nIn Proceedings of the International Conference on Machine Learning, Stockholm, Sweden,\\n10–15 July 2018; pp.\\n1184–1193.\\n17.', 'arXiv 2020 , arXiv:2001.00893.\\nShaker, M.H.; Hüllermeier, E. Aleatoric and epistemic uncertainty with random forests.\\nIn Proceedings of the International Conference on Machine Learning, Stockholm, Sweden,\\n10–15 July 2018; pp.\\n18.\\n1184–1193.\\n\\nefﬁcient and risk-sensitive learning.', '[CrossRef]\\narXiv 2020 , arXiv:2001.00893.\\n\\nShaker, M.H.; Hüllermeier, E. Aleatoric and epistemic uncertainty with random forests.\\nSci. 1986 ,1, 54–75.\\nStat.\\n19.\\n18.\\n1184–1193.\\n\\n10–15 July 2018; pp.\\nEfron, B.; Tibshirani, R. Bootstrap methods for standard errors, conﬁdence intervals, and other measures of statistical accuracy.\\n', '[CrossRef]\\n20. Stracuzzi, D.J.; Darling, M.C.; Peterson, M.G.; Chen, M.G. Quantifying Uncertainty to Improve Decision Making in Machine Learning ;\\nTechnical Report; Sandia National Lab.\\nSci. 1986 ,1, 54–75.\\n(SNL-NM): Albuquerque, NM, USA, 2018.\\nEfron, B.; Tibshirani, R. Bootstrap methods for standard errors, conﬁdence intervals, and other measures of statistical accuracy.\\n\\nStat.\\n19.', '[CrossRef]\\n2020 ,43,\\n3614–3631.\\nIEEE Access 2020 ,8, 101721–101746.\\n\\nGeng, C.; Huang, S.j.; Chen, S. Recent advances in open set recognition: A survey.\\nMena, J.; Pujol, O.; Vitrià, J. Uncertainty-based rejection wrappers for black-box classiﬁers.\\n(SNL-NM): Albuquerque, NM, USA, 2018.\\n\\nIntell.\\nMach.\\nPattern Anal.\\nIEEE Trans.', '2020 ,43,\\n3614–3631.\\nGeng, C.; Huang, S.j.; Chen, S. Recent advances in open set recognition: A survey.\\nPerello-Nieto, M.; Telmo De Menezes Filho, E.S.; Kull, M.; Flach, P .\\n[CrossRef]\\n23.\\nIntell.\\nMach.\\nPattern Anal.\\nIEEE Trans.\\n[CrossRef]\\n22.\\nBackground Check: A general technique to build more reliable', 'Perello-Nieto, M.; Telmo De Menezes Filho, E.S.; Kull, M.; Flach, P .\\nIn Proceedings of the 2016 IEEE 16th International Conference on Data Mining (ICDM), Barcelona, Spain,\\n12–15 December 2016; pp.\\n1143–1148.\\n[CrossRef]\\n23.\\n3614–3631.\\nBackground Check: A general technique to build more reliable\\nand versatile classiﬁers.', '[CrossRef]\\nExtr. 2020 ,2, 505–532.\\nIn Proceedings of the 2016 IEEE 16th International Conference on Data Mining (ICDM), Barcelona, Spain,\\n12–15 December 2016; pp.\\nPires, C.; Barandas, M.; Fernandes, L.; Folgado, D.; Gamboa, H. Towards Knowledge Uncertainty Estimation for Open Set\\nRecognition.\\nKnowl.\\nLearn.\\nMach.\\n24.\\n1143–1148.\\n\\nand versatile classiﬁers.', '[CrossRef]\\nExtr. 2020 ,2, 505–532.\\nTheory 1970 ,16, 41–46.\\nChow, C. On optimum recognition error and reject tradeoff.\\nInf.\\nIEEE Trans.\\n[CrossRef]\\n25.\\nKnowl.\\nLearn.\\nMach.', '[CrossRef]\\nExtr. 2020 ,2, 505–532.\\nIEEE Trans.\\nMach.\\nLearn.\\nKnowl.\\n[CrossRef]\\n25.\\nInf.\\n[CrossRef]\\n26.\\nPattern Recognit.', '[CrossRef]\\n2000 ,33, 2099–2101.\\n2008 ,29, 1565–1570.\\nTax, D.M.; Duin, R.P .\\nPattern Recognit.\\n[CrossRef]\\n27.\\nLett.\\nPattern Recognit.\\n26.\\nFumera, G.; Roli, F.; Giacinto, G. Reject option with multiple thresholds.', 'arXiv 2021 , arXiv:2101.12523.\\n2019 ,96, 106984.\\n2000 ,33, 2099–2101.\\n[CrossRef]\\n28. Hanczar, B. Performance visualization spaces for classiﬁcation with rejection option.\\nFranc, V .; Prusa, D.; Voracek, V .\\nOptimal strategies for reject option classiﬁers.\\n[CrossRef]\\n29.\\nPattern Recognit.\\nPattern Recognit.\\n27.', 'arXiv 2021 , arXiv:2101.12523.\\n\\nFranc, V .; Prusa, D.; Voracek, V .\\nIn Proceedings of the International Conference on Machine Learning, Virtual, 13–15 April 2021; pp.\\nCharoenphakdee, N.; Cui, Z.; Zhang, Y.; Sugiyama, M. Classiﬁcation with rejection based on cost-sensitive classiﬁcation.\\n\\n1507–1517.\\n30.\\nOptimal strategies for reject option classiﬁers.\\n29.', 'In Proceedings of the International Conference on Machine Learning, Virtual, 13–15 April 2021; pp.\\nNadeem, M.S.A.; Zucker, J.D.; Hanczar, B. Accuracy-rejection curves (ARCs) for comparing classiﬁcation methods with a\\nGal, Y. Uncertainty in Deep Learning.\\nPh.D. Dissertation, University of Cambridge, Cambridge, UK, 2016.\\n\\n32.\\n31.\\n1507–1517.\\n', 'Nadeem, M.S.A.; Zucker, J.D.; Hanczar, B. Accuracy-rejection curves (ARCs) for comparing classiﬁcation methods with a\\nreject option.\\nIn Proceedings of the third International Workshop on Machine Learning in Systems Biology, Ljubljana, Slovenia,\\n5–6 September 2009; pp.\\n65–81.\\n32.', '[CrossRef]\\nCondessa, F.; Bioucas-Dias, J.; Kovaˇ cevi´ c, J. Performance measures for classiﬁcation systems with rejection.\\n2017 ,\\n63, 437–450.\\nIn Proceedings of the third International Workshop on Machine Learning in Systems Biology, Ljubljana, Slovenia,\\n5–6 September 2009; pp.\\nPattern Recognit.\\n33.\\n65–81.\\n\\nreject option.', '[CrossRef]\\n34. Kläs, M. Towards identifying and managing sources of uncertainty in AI and machine learning models-an overview.\\narXiv 2018 ,\\narXiv:1811.11669.\\nCondessa, F.; Bioucas-Dias, J.; Kovaˇ cevi´ c, J. Performance measures for classiﬁcation systems with rejection.\\n2017 ,\\n63, 437–450.\\nPattern Recognit.\\n33.\\n65–81.\\n\\n5–6 September 2009; pp.', 'arXiv 2018 ,\\narXiv:1811.11669.\\n\\n63, 437–450.\\n[CrossRef]\\n34. Kläs, M. Towards identifying and managing sources of uncertainty in AI and machine learning models-an overview.\\nCampagner, A.; Cabitza, F.; Ciucci, D. Three-way decision for handling uncertainty in machine learning: A narrative review.\\n35.', 'arXiv 2021 ,\\narXiv:2110.11012.\\nSambyal, A.S.; Krishnan, N.C.; Bathula, D.R. Towards Reducing Aleatoric Uncertainty for Medical Imaging Tasks.\\nInInternational Joint Conference on Rough Sets ; Springer: Berlin/Heidelberg, Germany, 2020; pp.\\nCampagner, A.; Cabitza, F.; Ciucci, D. Three-way decision for handling uncertainty in machine learning: A narrative review.\\n\\n36.\\n137–152.\\n\\n35.\\narXiv:1811.11669.\\n', '[CrossRef]\\nNeurocomputing 2016 ,214, 445–457.\\narXiv 2021 ,\\narXiv:2110.11012.\\n\\nSambyal, A.S.; Krishnan, N.C.; Bathula, D.R. Towards Reducing Aleatoric Uncertainty for Medical Imaging Tasks.\\nFischer, L.; Hammer, B.; Wersing, H. Optimal local rejection for classiﬁers.\\n37.\\n36.', 'Neurocomputing 2016 ,214, 445–457.\\nFischer, L.; Hammer, B.; Wersing, H. Optimal local rejection for classiﬁers.\\nDua, D.; Graff, C. UCI Machine Learning Repository ; University of California, School of Information and Computer Science: Irvine,\\nCA, USA, 2019.\\n[CrossRef]\\n38.\\n37.\\narXiv:2110.11012.\\n\\nAvailable online: http://archive.ics.uci.edu/ml (accessed on 20 December 2021).', 'The role of movement\\nCA, USA, 2019.\\nBuckley, C.; Alcock, L.; McArdle, R.; Rehman, R.Z.U.; Del Din, S.; Mazzà, C.; Yarnall, A.J.; Rochester, L.\\nAnguita, D.; Ghio, A.; Oneto, L.; Parra, X.; Reyes-Ortiz, J.L.\\nEsann 2013 ,3, 3.\\n40.\\n39.\\nA public domain dataset for human activity recognition using\\nsmartphones.\\nAvailable online: http://archive.ics.uci.edu/ml (accessed on 20 December 2021).\\n', '[CrossRef] [PubMed]\\nBrain Sci. 2019 ,\\n9, 34.\\nBuckley, C.; Alcock, L.; McArdle, R.; Rehman, R.Z.U.; Del Din, S.; Mazzà, C.; Yarnall, A.J.; Rochester, L.\\nEsann 2013 ,3, 3.\\n40.\\nThe role of movement\\nanalysis in diagnosing and monitoring neurodegenerative conditions: Insights from gait and postural control.\\nsmartphones.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "model = Word2Vec(sample, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def sentence_vector(sentence, model):\n",
    "    words = word_tokenize(sentence)\n",
    "    word_vecs = [model.wv[word] for word in words if word in model.wv]\n",
    "    if not word_vecs:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(word_vecs, axis=0)\n",
    "\n",
    "def document_vector(document, model):\n",
    "    words = word_tokenize(document)\n",
    "    word_vecs = [model.wv[word] for word in words if word in model.wv]\n",
    "    if not word_vecs:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(word_vecs, axis=0)\n",
    "\n",
    "def e_summary(text, numsent):\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    \n",
    "   \n",
    "    doc_vec = document_vector(text, model)\n",
    "    \n",
    "    \n",
    "    sentence_scores = []\n",
    "    for sent in sentences:\n",
    "        sent_vec = sentence_vector(sent, model)\n",
    "        similarity = np.dot(doc_vec, sent_vec) / (np.linalg.norm(doc_vec) * np.linalg.norm(sent_vec))\n",
    "        sentence_scores.append(similarity)\n",
    "    \n",
    "   \n",
    "    print(\"Sentence scores:\", sentence_scores)\n",
    "    \n",
    "\n",
    "    top_sentence_indices = np.argsort(sentence_scores)[-numsent:][::-1]\n",
    "    \n",
    " \n",
    "    summary = [sentences[i] for i in top_sentence_indices]\n",
    "    \n",
    "    return '\\n'.join(summary)\n",
    "\n",
    "\n",
    "num_sentences = 10\n",
    "\n",
    "summary = [e_summary(text_chunk, num_sentences) for text_chunk in texts]\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer=pipeline(task=\"summarisation\",model=\"facebook/bart-large-cnn\")\n",
    "def a_summary(text,max_length,min_length):\n",
    "  input_length = len(text)\n",
    "  default_max_length=max_length\n",
    "  max_length = min(default_max_length, input_length // 2)\n",
    "  min_length = min(min_length, max_length - 1)\n",
    "  print(f\"Input length: {input_length}\")\n",
    "  print(f\"Max length set to: {max_length}\")\n",
    "  print(f\"Min length set to: {min_length}\")\n",
    "  nlp=summarizer(text,max_length=max_length,min_length=min_length,do_sample=False)\n",
    "  return nlp[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input length: 367\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 377\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 398\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 360\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 366\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 341\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 388\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 394\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 395\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 388\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 385\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 381\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 398\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 327\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 362\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 350\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 362\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 385\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 377\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 376\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 357\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 360\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 266\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 320\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 393\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 348\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 365\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 352\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 353\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 382\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 370\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 364\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 358\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 333\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 337\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 359\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 355\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 372\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 370\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 318\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 396\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 353\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 342\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 339\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 348\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 355\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 353\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 381\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 326\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 382\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 381\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 383\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 361\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 362\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 340\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 353\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 376\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 350\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 337\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 338\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 393\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 388\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 355\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 356\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 352\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 379\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 352\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 386\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 332\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 349\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 352\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 351\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 360\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 367\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 367\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 362\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 356\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 395\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 343\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 361\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 366\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 348\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 396\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 314\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 397\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 339\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 321\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 397\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 360\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 364\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 366\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 364\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 383\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 388\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 398\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 340\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 351\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 359\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 371\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 364\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 353\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 359\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 355\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 352\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 362\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 358\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 365\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 378\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 372\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 393\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 383\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 350\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 367\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 346\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 400\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 365\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 330\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 395\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 359\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 365\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 353\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 353\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 373\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 353\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 341\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 373\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 358\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 316\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 323\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 397\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 400\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 336\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 331\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 325\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 336\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 350\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 315\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 356\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 330\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 348\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 363\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 321\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 395\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 342\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 344\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 340\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 338\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 329\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 330\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 397\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 395\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 372\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 368\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 351\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 344\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 345\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 352\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 310\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 397\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 394\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 380\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 397\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 350\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 345\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 398\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 347\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 350\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 319\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 319\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 372\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 328\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 389\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 351\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 355\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 356\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 388\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 364\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 384\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 394\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 363\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 363\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 386\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 389\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 349\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 351\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 344\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 345\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 353\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 363\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 358\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 371\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 342\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 400\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 361\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 363\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 389\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 395\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 346\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 346\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 357\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 356\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 389\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 399\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 354\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 386\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 396\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 332\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 387\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 360\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 376\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 360\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 364\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 358\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 352\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 357\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 358\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 396\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 385\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 346\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 354\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 351\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 342\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 360\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 364\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 361\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 352\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 372\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 320\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 377\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 348\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 374\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 376\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 336\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 364\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 341\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 347\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 370\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 392\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 328\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 371\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 357\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 382\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 316\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 362\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 327\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 348\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 352\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 380\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 324\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 367\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 355\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 385\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 389\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 392\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 325\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 352\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 339\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 337\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 397\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 322\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 359\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 357\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 357\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 355\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 359\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 357\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 373\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 337\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 395\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 375\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 353\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 358\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 357\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 359\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 362\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 363\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 372\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 364\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 357\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 367\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 397\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 390\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 369\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 306\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 343\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 372\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 344\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 355\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 318\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 311\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 358\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 352\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 373\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 382\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 367\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 371\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 399\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 389\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 392\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 390\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 340\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 343\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 349\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 351\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 387\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 380\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 346\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 333\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 386\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 365\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 359\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 374\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 373\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 353\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 349\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 344\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 356\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 329\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 327\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 349\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 340\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 354\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 363\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 365\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 370\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 397\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 360\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 368\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 380\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 378\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 316\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 313\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 370\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 312\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 329\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 363\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 286\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 319\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 367\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 398\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 329\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 388\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 374\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 326\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 267\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 312\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 324\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 292\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 315\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 398\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 387\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 290\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 284\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 278\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 325\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 384\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 381\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 304\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 321\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 354\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 304\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 319\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 265\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 385\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 354\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 339\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 279\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 323\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 343\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 298\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 397\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 272\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 374\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 385\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n",
      "Input length: 316\n",
      "Max length set to: 50\n",
      "Min length set to: 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Citation: Barandas, M., Folgado, D., Santos, R., Simão, R.; Gamboa, H. Uncertainty-Based Rejection in MachineLearning: Implications for ModelDevelopment and Interpret'},\n",
       " {'summary_text': 'Uncertainty-Based Rejection in Machine.Learning: Implications for ModelDevelopment and Interpretability.'},\n",
       " {'summary_text': 'This article is an open access article. Use this article to help people with reading comprehension and vocabulary. Use the weekly Newsquiz to test your knowledge of stories you saw in this article.'},\n",
       " {'summary_text': 'This article is an open access articledistributed under the terms and conditions of the Creative CommonsAttribution (CC BY) license. The author is responsible for the publication of this article.'},\n",
       " {'summary_text': 'Uncertainty-Based Rejection in Machine Learning: Implications for Model Development and Interpretability. distributed under the terms and conditions of the Creative CommonsAttribution (CC BY) license.'},\n",
       " {'summary_text': 'Associação Fraunhofer Portugal Research, Rua Alfredo Allen 455/461, 4200-135 Porto, Portugal. for Model Development and Interpretability.'},\n",
       " {'summary_text': 'Departamento de Física, Faculdade de Ciências e Tecnologia, Universidade Nova de Lisboa, 282829-516 Caparica, Portugal.'},\n",
       " {'summary_text': 'Uncertainty is present in every single prediction of Machine Learning (ML) models. Uncer-tainty Quantiﬁcation (UQ) is arguably relevant for safety-critical applications.'},\n",
       " {'summary_text': ' Quantiﬁcation (UQ) is arguably relevant, in particular for safety-critical applications. This work focused on applying UQ into practice, closing the gap of its utility in the ML pipeline.'},\n",
       " {'summary_text': 'This work focused on applying UQ into practice, closing the gap of its utility in the ML pipeline and giving insights into how UQ is used to improve model development.'},\n",
       " {'summary_text': 'We ask how UQ can be used to improve model development and its interpretability. We also ask if visualization techniques can improve UQ’sinterpretability.'},\n",
       " {'summary_text': 'Can uncertainty be used to combine different models? Can visualization techniques improve UQ’s interpretability? These questionsare answered by applying several methods to quantify uncertainty in a simulated and real-world dataset.'},\n",
       " {'summary_text': '. are answered by applying several methods to quantify uncertainty in both a simulated dataset and a real-world dataset of Human Activity Recognition. Our results showed that uncertainty can increase model robustness and interpretability.'},\n",
       " {'summary_text': 'Machine Learning (ML) has continuously attracted the interest of the research com-munity, motivated by the promising results obtained in many decision-critical domains.'},\n",
       " {'summary_text': 'Machine Learning (ML) has continuously attracted the interest of the research com-munity. We argue that approaches that are safe to use in decision-critical domains must account for the inherent uncertainty in the process.'},\n",
       " {'summary_text': 'We argue that approaches that are safe to use in decision-critical domains must account for the inherent uncertainty in the process. ML models learn from data and use the extracted models to make predictions. Learning from data is inseparably con-nect'},\n",
       " {'summary_text': ' ML models are susceptible to noise and suboptimal model inference. It is highly de- \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0sirable to take into account uncertainty as a path towards trustworthy Artiﬁcial Intelligence.'},\n",
       " {'summary_text': ' ML models should have the ability to quantify uncertainty in their predictions and abstain from providing a decision when a large amount of uncertainty is present. It is highly de- \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0sirable to take into account uncertainty as a path towards trustworthy Art'},\n",
       " {'summary_text': 'ML models should have the ability to quantify uncertainty in their predictions. They should abstain from providing a decision when a large amount of uncertainty is present. Aleatoric uncertainty refers to the origin of uncertainty.'},\n",
       " {'summary_text': 'Aleatoric uncertainty refers to the notion of randomness, and it is related to the data-measurement process. Epistemicuncertainty refers to uncertainty associated with the model and by the lack of knowl-'},\n",
       " {'summary_text': ' Epistemicuncertainty refers to the uncertainty associated with the model and by the lack of knowl-edge. In principle, epistemic uncertainty can be reduced by extending the training data,better modeling, or better data analysis.'},\n",
       " {'summary_text': 'In principle, epistemic uncertainty can be reduced by extending the training data, better modeling, or better data analysis. Different types of uncertainty should be measured differently, this distinction in ML has only received attention recently.'},\n",
       " {'summary_text': 'This distinction in ML has only received attention recently [ 4]. In particular, in the literature on deep learning, this distinction has been studied due to the limited awareness of neural networks of their own conﬁdence.'},\n",
       " {'summary_text': 'The limited awareness of neural networks of their own conﬁdence. In particular, in the literature on deep learning, this distinction has been studied. Recently there has been a surge in interest in this topic.'},\n",
       " {'summary_text': 'Deep learning models are known as being. overconﬁdent with out-of-distribution examples or even adversarial. examples. Uncertainty Quanti ﬁcation (UQ) plays an important role'},\n",
       " {'summary_text': 'Uncertainty Quantiﬁcation (UQ) plays an important role in AI deploymentscenarios for cost-sensitive decision-making domains, such as medicine. It is also an important concept within the ML methodology'},\n",
       " {'summary_text': 'UQ is important for cost-sensitive decision-making domains, such as medicine. It is also an important concept within the ML methodology itself, as for instance in active learning.'},\n",
       " {'summary_text': 'UQ is importantacross several stakeholders of the ML lifecycle. It helps developers debug their models so they can be used for model improvement. Recent uncertainty frameworks have been proposed that provide different capabilities to quantify uncertainty.'},\n",
       " {'summary_text': 'UQ increases interpretability and trust in model predictions. For regulators and certiﬁcation bodies, it contributes. across several stakeholders of the ML lifecycle. It helps developers debug their models.'},\n",
       " {'summary_text': 'UQ increases interpretability and trust in model predictions. For regulators and certiﬁcation bodies, it contributes to algorithm auditing and quality control.'},\n",
       " {'summary_text': 'Previous research has been focused on the development of techniques to characterizeand quantify uncertainty. This workfocused on leveraging the outcome from uncertainty quantiﬁcation to improve the model.'},\n",
       " {'summary_text': 'This workfocused on leveraging the outcome from uncertainty quantiﬁcation to improve the modeldevelopment process. We applied the UQ concept in practice, giving insights into why it can be an effective procedure to improve model development.'},\n",
       " {'summary_text': 'We applied the UQ concept in practice, giving insights into why it can be an effective procedure to improve model development. We identiﬁed the following research questions: How can UQ contribute to choosing the most suitable model'},\n",
       " {'summary_text': 'In ML, various criteria can be used in the problem of model selection. How can UQ contribute to choosing the most suitable model for a given classification task? Can UQ be used to combine different models in a principled manner?'},\n",
       " {'summary_text': 'In ML, various criteria can be used in the problem of model selection. Model selectionconsists of selecting a model among a collection of candidates for a training dataset.'},\n",
       " {'summary_text': 'Model selection. consists of selecting a model among a collection of candidates for a training dataset. It can be applied to different types of models or the same type conﬁgured with different hyperparameters.'},\n",
       " {'summary_text': 'The main goal of model selection is to achieve the best predictiveperformance for modeling learning data. In supervised learning, the predictiveaccuracy is usually considered as the most important criterion for model selection.'},\n",
       " {'summary_text': 'In supervised learning, the predictiveaccuracy is usually considered as the most important criterion for model selection. However, other criteria for the predictive model quality, such as interpretability or computationalcost, can also play a key role in model selection'},\n",
       " {'summary_text': 'Uncertainty isnot being considered as criterion for model selection. various criteria for the predictive model quality, such as interpretability or computationalcost, can also play a key role in model Selection. Question 1 addresses how uncertaintymight contribute to'},\n",
       " {'summary_text': 'Question 1 addresses how uncertaintymight contribute to model characterization with valuable quantitative information. Question 2 addresses if sufﬁcient training data were provided to calculate trustworthy predictions.'},\n",
       " {'summary_text': 'There are several combination rules to train and combine different models. Some rules address the quality of the model’s predictions.'},\n",
       " {'summary_text': 'There are several combination rules to train and combine different models. Some rules address models’ combination using the average of the predictions or the class probabilities.'},\n",
       " {'summary_text': 'In ordinary classiﬁcation, the classi ﬁer is usually forced to predict a label. With Question 2, weaddress how uncertainty can be taken into account.'},\n",
       " {'summary_text': '. address how uncertainty can be taken into account for model combination. In these scenarios, it will be more appropriate to avoid making decisions. For difﬁcultsamples, it might lead to misclassi�'},\n",
       " {'summary_text': '. samples, it might lead to misclassiﬁcation, which may cause problems in risk-sensitiveapplications. In these scenarios, it will be more appropriate to avoid making decisions on the dif�'},\n",
       " {'summary_text': 'In addition to quantitative methods for sample rejection, it is important to provide the interpretability of why a particular sample was rejected. This approach is known as classiﬁcation with arejecting option.'},\n",
       " {'summary_text': 'In addition to quantitative methods for sample rejection, it is importantto provide the interpretability of why a particular sample was rejected. In this context,Neto et al. [14] proposed a visualization explainable matrix applied to random forests'},\n",
       " {'summary_text': 'Neto et al. proposed a visualization explainable matrix applied to random forests. However, with regard to uncertainty visualization for a given prediction or applied to the model itself, few or no studies have considered this.'},\n",
       " {'summary_text': 'Electronics 2022 ,11, 396 3 of 20literature. Question 3 addresses how visualization techniques might be used to improve UQ’s interpretability. In Section 2, we introduce the prediction.'},\n",
       " {'summary_text': 'The remainder of this paper is organized as follows: In Section 2, we introduce thebackground concepts and related work. Section 3 contains a thorough description of the methods used to answer the research questions. Section 4 contains experimental results,and in'},\n",
       " {'summary_text': 'The awareness of uncertainty is of major importance in ML and constitutes a keyelement of its methodology. Traditionally, uncertainty in ML is modeled using probability. Section 4 contains experimental results, and in Section 5, we detail the conclusions and discuss'},\n",
       " {'summary_text': 'The awareness of uncertainty is of major importance in ML and constitutes a keyelement of its methodology. Traditionally, uncertainty in ML is modeled using probabilitytheory. In the recent ML literature, two inherently different sources of uncertainty are commonly used'},\n",
       " {'summary_text': 'Aleatoric uncertainty refers to notion of randomness and cannot be reduced by adding more samples to the training. Aleatoric and epistemic uncertainty refer to two inherently different sources of uncertainty.'},\n",
       " {'summary_text': 'Aleatoric uncertainty refers to the notion of randomness and cannot be reduced by adding more samples to the training process. Epistemic uncertainty is caused by a lack of knowledge, either due to the uncertainty associated with the model or the'},\n",
       " {'summary_text': 'In principle, this uncertainty can be reduced by adding more training data. On the other hand, epistemic uncertainty refers to the uncertainty caused by a lack of knowledge, either due to the model or the lack of data.'},\n",
       " {'summary_text': 'In standard probabilistic modeling and Bayesian inference, the representation of UQ is uncertain. In principle, this uncertainty can be reduced by adding more training data. In the following subsections, we present an overview of previous works that have'},\n",
       " {'summary_text': 'In standard probabilistic modeling and Bayesian inference, the representation of ofuncertainty about a prediction is given by the posterior distribution. We. explored different strategies for UQ and methods about classiﬁcation with rejection'},\n",
       " {'summary_text': 'The posterior distribution of uncertainty about a prediction is given by the posterior distribution. Let us consider a training dataset, D=f(xi,wi)gNi, with Nsamples.'},\n",
       " {'summary_text': 'Each hypothesis can be considered as anexplanation of how the world works. Samples from the posterior distribution should be taken.'},\n",
       " {'summary_text': 'From a Bayesian perspective, each hypothesis is equipped with a probability distribution. Samples from the posterior distribution should yield explanations consistent with the observations of the world contained within the data.'},\n",
       " {'summary_text': 'Each hypothesis is equipped with a prior and posterior distribution. The posterior distribution can be computed via the Bayes rule: p(hjD) = p(Djh)p(h)'},\n",
       " {'summary_text': 'Predictive uncertainty of a classiﬁcation model depends on how the uncertainty is represented as a basis for prediction and decision-making. In Bayesian inference, the belief about the outcome wkis represented by a second'},\n",
       " {'summary_text': 'In Bayesian inference, the belief about the outcome wkis represented by a second-orderprobability: a probability distribution of probability distributions. A given prediction is obtained through model averaging, i.e., different.'},\n",
       " {'summary_text': 'Bayesian inference is a type of Bayesian inference. Predictive posterior distribution is given by:p(wjx) =Zp( wjx,h)dP(hjD) (2)'},\n",
       " {'summary_text': 'Predictive posterior distribution is given by:p(wjx) =Z (Z) (2) The predicted probability of an outcome wis the expected probability p( wjx,h)'},\n",
       " {'summary_text': 'Predictive probability of an outcome wis the expected probability p(wjx,h), where the expectation over the hypotheses is taken with respect to the posterior distribution, P(hjD) In \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0ML, it is'},\n",
       " {'summary_text': 'Model averaging is often difﬁcult and computationally costly. It is common to make predictions considering a single probability distribution for each class. The most well-known measure of uncertainty is the (Shannon) entropy.'},\n",
       " {'summary_text': 'The most well-known measure of uncertainty of a single probability distribution, p, is the (Shannon) entropy. This measure primarily captures the shape of the distribution and is mostly concerned with the aleatoric part of the overall uncertainty'},\n",
       " {'summary_text': 'In order to account for both aleatoric and epistemic uncertainty, the Bayesian per-spective is common in ML. This measure of uncertainty primarily captures the shape of the distribution.'},\n",
       " {'summary_text': 'Bayesian per-spective is quite common in ML, where the (total) uncertainty is quantiﬁed on the basis of the predictive posterior distribution. Depeweg et al. proposed an approach to quantify and separate uncertainties'},\n",
       " {'summary_text': 'Depeweg et al. [ 17] proposed an approach to quantify and separate uncertainties with classical information-theoretic measures. The authors’ idea was more general and canalso be applied to other settings, such as in the'},\n",
       " {'summary_text': 'The authors’ idea was more general and canalso be applied to other settings, such as in the work of Shaker et al. [ 18], where mea-sures of entropy were applied using a random forest classi'},\n",
       " {'summary_text': 'More speciﬁcally, Depeweg et al. [ 17] proposed to measure the total uncertainty in terms of the entropy of the predictive posterior distribution, H[p(wjx) and measure the ale'},\n",
       " {'summary_text': 'Depeweg et al. proposed to measure the total uncertainty in terms of the entropy of the predictive posterior distribution, H[p(wjx)]. Measure the aleatoricuncertainty in terms. of the expectation of'},\n",
       " {'summary_text': 'The aleatoric uncertainty is measured in terms of the expectation over \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0the entropies of distributions, since his not precisely known. The idea is that by by hypothesis h, the epistemic uncertainty is essentially removed.'},\n",
       " {'summary_text': 'Epistemic uncertainty is high if the distribution p(wjx,h)varies greatly. The entropies of distributions are not precisely known. The idea is that by hypothesis h, the uncertainty is essentially removed.'},\n",
       " {'summary_text': 'Epistemic uncertainty is high if the distribution p(wjx,h)varies greatly for different hypotheses h with high probability, but leading to quite different predictions.'},\n",
       " {'summary_text': 'An approximation by means of ensemble techniques, based on an ensemble of Mhypotheses, can be obtained using the following equations. For different hypotheses hwith high probability, but leading to quite different predictions.'},\n",
       " {'summary_text': 'Besides the classical information-theoretic measures, the bootstrap method [ 19] is also used. an ensemble of Mhypotheses, can be obtained using the following equations.'},\n",
       " {'summary_text': 'Besides the classical information-theoretic measures, the bootstrap method is also a common approach to estimate uncertainty. In order to quantify the uncertainty in the results of a given algorithm, the sampling distribution of a parameter of interest is required'},\n",
       " {'summary_text': 'In order to quantify the uncertainty in the results of a given algorithm, the sampling distribution of a parameter of interest is required. Because data represent one collection of observable data, resampling methods that generateadditional representative samples in order to'},\n",
       " {'summary_text': 'The bootstrap method uses Monte Carlo simulation to approximate the sampling distribution by repeatedly simulating bootstrap samples. Because data represent one collection of observable data, resampling methods that generate additional representative samples in order to obtain a sampling distribution are'},\n",
       " {'summary_text': 'The bootstrap method uses Monte Carlo simulation to approximate the samplingdistribution by repeatedly simulating bootstrap samples. To sample Sbootstrap datasets, one would need to run the learning procedure from scratch each time.'},\n",
       " {'summary_text': 'A measure to quantify uncertainty using the bootstrap method is the variation ratios. To bootstrap a supervised learning algorithm, one would need to sample Sbootstrap datasetsand run the learning procedure from scratch each time.'},\n",
       " {'summary_text': 'A measure to quantify uncertainty using the bootstrap method is the variation ratios. The variation ratios measure the variability of the predictions obtained from sampling. For a given instance x, the variationratios are computed as follows.'},\n",
       " {'summary_text': 'The dispersion of the predictions around its mode [ 21]. For a given instance x, the variation in the predictions is computed as follows. Measures for novelty, anomaly, or outlier detection where testing sam-'},\n",
       " {'summary_text': 'Electronics 2022 ,11, 396 5 of 20. where fwk=åS \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0i=11[wi=w] (8) \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0w \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0=arg max \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0w=w1,...,wKS \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0å'},\n",
       " {'summary_text': 'Electronics 2022 ,11, 396 5 of 20uncertainty. ples come from a different population than the training set. Approaches based on generative models typically use densities to decide whether to reject a test input.'},\n",
       " {'summary_text': 'Generative models typically use densities to decide whether to reject a test input that is located in a region without training inputs. These low-density regions, where no training inputs have been encountered so far, repre-sent a high'},\n",
       " {'summary_text': 'Low-density regions, where no training inputs have been encountered so far, repre-sent a high knowledge uncertainty. Traditional methods, such as Kernel Density Estimation(KDE), can be used to estimate densities.'},\n",
       " {'summary_text': 'KDE, can be used to estimate densities, and often, threshold-based methods are applied on top of the density where a classiﬁer can refuse to predict a test input in that region. Knowledge Uncertain'},\n",
       " {'summary_text': ' Knowledge Uncertainty Estimation (KUE) learns the feature density from the training data, to reject test inputs that represent a density differentfrom the training dataset. For a test input xi, represented by P-dimensional feature vectors'},\n",
       " {'summary_text': 'For a test input xi, represented by P-dimensional feature vectors, the KUE measure is calculated as follows. KUE is an uncertainty distance obtained from the feature density.'},\n",
       " {'summary_text': 'The KUE measure is calculated as follows:. KUE(xijwk) =1 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0  \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0Põj=1dunc(fjjwk,xi)!1 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0P(9) is an uncertainty distance'},\n",
       " {'summary_text': 'The process of abstaining from producing an answer or discarding a prediction when the system is not conﬁdent enough is more than 60 years old. In the interval [0, 1], where one represents the maximum density'},\n",
       " {'summary_text': 'The process of abstaining from producing an answer or discarding a prediction when the system is not conﬁdent enough is more than 60 years old and was introduced by Chow. Chow’s theory suggests that objects are'},\n",
       " {'summary_text': 'Chow’s theory suggests that objects are rejected for which the maximumposterior probability is below a threshold. If the classiﬁer is not suf ﬁciently accurate for the task at hand'},\n",
       " {'summary_text': 'Chow’s theory is suitable when asufﬁciently large training sample is available for all classes and when the training sampleis not contaminated by outliers. Fumera et al. [ 27] showed'},\n",
       " {'summary_text': 'Chow’s rule does not not perform well if a signiﬁcant error in the probability estimation is present. In that case, adifferent rejection threshold per class has to be used. In classi�'},\n",
       " {'summary_text': 'A different rejection threshold per class has to be used. perform well if a signiﬁcant error in the probability estimation is present. In classi ﬁers with a rejection option, the key parameters are the'},\n",
       " {'summary_text': 'In these kinds of methods, the rejection is mostly applied to samples with highaleatoric uncertainty. the key parameters are the thresholds that deﬁne the rejection area.'},\n",
       " {'summary_text': 'Rejection is mostly applied to samples with high uncertainty. It has been argued that probability distributions are less suitable for representing ignorance in the sense of a lack of knowledge.'},\n",
       " {'summary_text': 'Recent works included the classiﬁcation with rejection with a distinction between \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0aleatoric and epistemic uncertainty using ensemble techniques and/or deep learningapproaches. The threshold value needs to be for representing ignorance in the sense'},\n",
       " {'summary_text': 'A threshold value needs to be indicating the rejection point. Different cost-based rejection methods have been proposed to minimize the classiﬁcation risk. In probabilistic classi ﬁers, risk can be minimized using'},\n",
       " {'summary_text': 'Risk canderive from the observation of the output probabilities employing different metrics. Different cost-based rejection methods have been proposed to minimize the classiﬁcation risk.'},\n",
       " {'summary_text': 'The evaluation of the performance of classiﬁers with rejection usually uses standard metrics, such as accuracy, to obtain an Accuracy-Rejection Curve (ARC) According to the ARC, the output probabilities. derive from the observation'},\n",
       " {'summary_text': 'The evaluation of the performance of classiﬁers with rejection usually uses standardmetrics, such as accuracy, to obtain an Accuracy-Rejection Curve (ARC) An ARC is a function representing the accuracy of a classi'},\n",
       " {'summary_text': 'ARC is a function representing the accuracy of a classiﬁer as a function of its rejection rate. Since the accuracy is always 100% when the rejectionrate is one, all curves converge to the point (1, 1'},\n",
       " {'summary_text': 'All curves converge to the point (1, 1), where the initial accuracy of the classiﬁer, with 0% of rejected samples. Since the accuracy is always 100% when the rejectionrate is one, all curves'},\n",
       " {'summary_text': 'Using this approach, it is not possible to determine the optimal rejection rate. Other metrics for evaluating classiﬁers with rejection are centered only on the nonrejected accuracy as a core component of ARCs.'},\n",
       " {'summary_text': 'Condessa et al. [ 33] expanded the set of performance measures for classiﬁcation withrejection. They proposed two novel performance measures to evaluate the best rejection point.'},\n",
       " {'summary_text': 'A new way to evaluate the best rejection point, namely classiﬁcation quality and rejection quality. A is a partition of a set of samples in subsets A,M,N, and R.'},\n",
       " {'summary_text': 'Nonrejected accuracy measures the ability of the classiﬁer to accurately classify non-re-rejected samples.'},\n",
       " {'summary_text': 'Nonrejected accuracy measures the ability of the classiﬁer to accurately classify nonre-jected samples, and it is computed as, \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0NRA =jA\\\\Nj \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0jNj; (10)'},\n",
       " {'summary_text': ' quality measures the ability of the classiﬁer with rejection to accurately classify nonrejected samples and to reject misclassi ﬁed samples. It is computed as, \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0CQ=jA'},\n",
       " {'summary_text': 'Rejection quality measures the ability of the classiﬁer with rejection to make errors onrejected samples only. Unlike other measures, the rejection quality has a minimum value of zero. The nonrejected accuracy and the class'},\n",
       " {'summary_text': 'The nonrejected accuracy and the classiﬁcation quality are bounded in the interval[0, 1]. Unlike these measures, the rejection quality has a minimum value of zero, and itsmaximum is unbounded by construction.'},\n",
       " {'summary_text': 'In this work, we considered the uncertainty estimation problem in a traditional MLclassiﬁcation setting. Besides the common division between aleatoric and epistemic uncer-tainty, we further divided the epistemic uncertainty into'},\n",
       " {'summary_text': 'We have divided the epistemic uncertainty into two additional categories, namelyknowledge and model uncertainty. Although these terms are commonly used to refer to the broad view of the uncertainty, we refer to knowledge uncertainty as the uncertainty.'},\n",
       " {'summary_text': ' knowledge and model uncertainty. Although these terms are commonly used to refer to thebroad view of epistemic uncertainty, we refer to knowledge uncertainty as the uncertaintyrelated to the lack of data.'},\n",
       " {'summary_text': 'We refer to model uncertainty as the uncertainty related to the model itself, i.e., the quality of the model on known data or uncertainty about the model parameters. We also refer to the regions in space where there is little or no'},\n",
       " {'summary_text': 'ML systems share a set of core components comprising data, an ML model, and outputs. Uncertainties are present in all ML components under different sources, asvisualized in Figure 1.'},\n",
       " {'summary_text': 'ML systems share a set of core components comprising data, an ML model, and outputs. Uncertainties are present in all ML components under different sources.'},\n",
       " {'summary_text': 'Data used to feed ML models are limited in their accuracy and potentiallyaffected by various kinds of quality issues. This limits the models from being ap- \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0plied under optimal conditions. For example, uncertainty caused due to the uncertainty caused by'},\n",
       " {'summary_text': 'Although the aleatoric uncertainty is supposed to be irreducible for a speciﬁc dataset, it can be affected by various kinds of quality issues. For example, the uncertainty caused due toerrors in the measurement'},\n",
       " {'summary_text': 'Although the aleatoric uncertainty is supposed to be irreducible for a speciﬁc dataset, additional features or improving the quality of the existing features can help reduce its reduction. For a given classi�'},\n",
       " {'summary_text': 'For a given classiﬁcation task, several ML models can be applied and de-veloped. The choice of a model is arguably important and is often based on thedegree of error in the model’s outcomes'},\n",
       " {'summary_text': 'The choice of a model is arguably important and is often based on thedegree of error in the model’s outcomes. Besides models’ accuracy, the use of uncertainty quantiﬁcation methods during model development can provide'},\n",
       " {'summary_text': 'Use of uncertainty quantiﬁcation methods during model development can provide important elements to choose the right model for the problem at hand.understanding the model’s uncertainty during training can give us insights about the limitations of each'},\n",
       " {'summary_text': ' understanding the model’s uncertainty during training can give us insights about the limitations of each model and help in developing more robust models. The estimation of model uncertainty increases model interpretability.'},\n",
       " {'summary_text': 'Predictive models are arguablyrelevant, all the more in safety-critical applications. For instance, in the context ofcomputer-aided diagnosis systems, a prediction with high uncertainty shall justify.'},\n",
       " {'summary_text': 'computer-aided diagnosis systems. A prediction with high uncertainty shall justify disregarding its output or conducting further medical examinations of thepatient.'},\n",
       " {'summary_text': 'The goal is to retrieve additional evidence that supports orcontradicts a given hypothesis. In the former, it is the case of classiﬁcation with \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0rejection, which is a viable option. The presence and cost'},\n",
       " {'summary_text': 'The presence and cost of errors can bedetrimental to the performance of automated classiﬁcation systems. To illustrate the different sources of uncertainty and the methods for UQ, we introduce the different methods.'},\n",
       " {'summary_text': 'To illustrate the different sources of uncertainty and the methods for UQ, we introduce a scenario using a simulated small dataset shown in Figure 2. The scenario consists of atwo-dimensional dataset with two classes, where features from class A were'},\n",
       " {'summary_text': 'A scenario using a simulated small dataset is shown in Figure 2. The scenario consists of atwo-dimensional dataset with two classes, where features from class A were modeled with an unimodal Gaussian distribution. Features from class B were'},\n",
       " {'summary_text': 'minor mode is approximately 5.5% of the mass of the major mode. an unimodal Gaussian distribution and features from class B were modeled as a bimodal distribution with a mixture of two Gaussian distributions with'},\n",
       " {'summary_text': 'Minor mode is approximately 5.5% of the mass of the major mode. For model training, a Naive Bayes (NB) classiﬁer using KDE was applied.'},\n",
       " {'summary_text': 'A Naive Bayes (NB) classiﬁer using KDE was applied using a bootstrap approach. Using this approach, it is possible to access the amount that a prediction changes when the model is used on slightly different'},\n",
       " {'summary_text': 'The selected uncertainty quantiﬁcation methods for each source of uncertainty were used. Using this approach, it is possible to access the amount of uncertainty when a model is used on slightly different data.'},\n",
       " {'summary_text': 'The Shannon entropy is the most notable measure of uncer-tainty for probability distributions. Equation (4) measures the aleatoric uncertainty in terms of expectation over the entropies.'},\n",
       " {'summary_text': 'Equation (4) measures the aleatoric uncertainty in terms of expectation over the entropies of distributions. Equation (7) was selected as a primary uncer-tainty for probability distributions.'},\n",
       " {'summary_text': ' Variation ratios (Equation (7)) were selected as a primary uncer-tainty quantiﬁcation method, to estimate model uncertainty. We were interested in evaluating the quality of the model ﬁt.'},\n",
       " {'summary_text': 'Changes in the predicted label have a signiﬁcant impact on the variation ratio measure. Contrarily, measures based on entropies (Equation (6) is commonly used) can also be used.'},\n",
       " {'summary_text': 'Equation (6) can also be used, but the impact on the measure is lower, since in variation ratios, we are merely counting changes in the pre- \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0dictions. In entropy measures we are averaging the prediction probabilities.'},\n",
       " {'summary_text': 'We argue that these kinds of measures are more akin to model un-model un. dictions, and in entropy measures, we are averaging the prediction probabilities.'},\n",
       " {'summary_text': 'The uncertainty related to the lack of data might be poorly modeled by these measures. We argue that these kinds of measures are more akin to model un-certainty.'},\n",
       " {'summary_text': 'The uncertainty related to the lack of data might be poorly modeled by thesemeasures. We considered density estimation methods, commonlyused for outlier or novelty detection, more prone to model knowledge uncertainty. The KUE measure (Equation (9'},\n",
       " {'summary_text': 'In order to visualize the uncertainty estimations in the whole region presented in Figure 2, we applied the uncertainty quantiﬁcation measures to a new set of points that were more prone to model knowledge uncertainty.'},\n",
       " {'summary_text': 'The uncertainty quantiﬁcation measures were applied to a new set of points that included all combinations of feature values. Figure 3 shows the uncertainty values for each point of the feature space.'},\n",
       " {'summary_text': 'Figure 3. Toy dataset uncertainty measures for aleatoric, model, and knowledge uncertainty. uncertainty values for each point of the feature space.'},\n",
       " {'summary_text': 'Figure 3. Toy dataset uncertainty measures for aleatoric, model, and knowledge uncertainty. 0.00.20.40.60.81.5.'},\n",
       " {'summary_text': 'Observing the uncertainty regions for each source of uncertainty, one can see com-pletely different behaviors depending on the uncertainty. The aleatoric uncertainty is highin the middle of the two major clusters (Feature 1 equals to 0.'},\n",
       " {'summary_text': 'Feature 1 equals to 0.15 approximately. in the middle of the two major clusters. The overlap between the cluster of class A and the minor Cluster of class B presents a higher uncertainty compared to the rest of the region.'},\n",
       " {'summary_text': 'The entropy value isnormalized to the maximum entropy, i.e., the logarithm of the number of classes. cluster of class B also presents a higher uncertainty compared to the rest of the region.'},\n",
       " {'summary_text': 'The maximum possible value occurs when the frequency of both classes is equal. The entropy value isnormalized to the maximum entropy, i.e., the logarithm of the number of classes.'},\n",
       " {'summary_text': 'The maximum possible value occurs when the frequency of both classes is equal, i.e., thevariation ratios have a value of 0.5. The regions with higher uncertainty values are the ones with little evidence.'},\n",
       " {'summary_text': 'The regions with higher uncertainty values are the ones with little evidence. The model in these regions is highly dependent on the available data.'},\n",
       " {'summary_text': 'Electronics 2022 ,11, 396 9 of 20in regions with little evidence, have a high impact on the model. Observing the minor cluster of class B produces a high model uncertainty.'},\n",
       " {'summary_text': 'Minor cluster of class B produces a high model uncertainty. Upper and lower regions between major clusters also produce a high uncertainty. knowledge uncertainty was modeled using the feature density on the training.'},\n",
       " {'summary_text': 'The knowledge uncertainty was modeled using the feature density on the training data. The rejection rule for each type of uncer-tainty was deﬁne using the previously uncertainty measures.'},\n",
       " {'summary_text': 'problem of choosing the optimal rejection point is not trivial and was not addressed in this work. There are several works entirely dedicated to this topic, such as the work ofCondessa et al. [33] and Fisher et al [37'},\n",
       " {'summary_text': 'In our classiﬁcation setting, the ﬁnal prediction is given by the following rejection rule. There are several works entirely dedicated to this topic.'},\n",
       " {'summary_text': 'F(x) is a function on the input thatevaluates the uncertainty of the prediction model. This uncertainty function is given by the set of uncertainties through thefollowing equation.'},\n",
       " {'summary_text': 'F(x) =å \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0u2U1[fu(x), tu (x) where U2[a,m,k] is the set of available uncertainties, fuis an uncertainty function that evaluates uncertainty u'},\n",
       " {'summary_text': 'The optimal threshold for aleatoric uncertainty was obtained using the following equation. evaluating uncertainty u, and tuis a threshold for the rejection point for uncertainty u.'},\n",
       " {'summary_text': 'Ta is a threshold in the interval [0, 1], representing a normalized entropy value. ta, was obtained using the following equation.'},\n",
       " {'summary_text': 'The uncertainty function used for model uncertainty, fm, is equal to Equation (7), and bis a rejection cost, here set to 0.5. The subsets represent the true rejectionsand false rejections using threshold q'},\n",
       " {'summary_text': 'The uncertainty function used for model uncertainty, fm, is equal to Equation (7), andtmwas set to zero, which means that a prediction must be equal in all bootstraps samples. This assumption was made because if'},\n",
       " {'summary_text': ' tmwas set to zero, which means that a prediction must be equal in all bootstraps samples. This assumption was made because if a sample is predicted differentlyusing slightly different datasets, the model in that particular region will still have'},\n",
       " {'summary_text': 'For knowledge uncertainty, fkis equal to Equation (9). To deﬁne tk, we used a P95% value of the training uncertainty values. A detailed description of this approach is available in [24'},\n",
       " {'summary_text': 'Our proposed approach was developed in the context of classiﬁcationwith rejection. Rejection was obtained through measures of uncertainty. These un-certainty measures were distinguished by three different sources: aleatoric, model, and'},\n",
       " {'summary_text': 'Uncertainty measures were distinguished by three different sources: aleatoric, model, andknowledge uncertainty. For the uncertainty quantiﬁcation, we used an entropy measure for aleatorIC uncertainty. We used the variation ratio'},\n",
       " {'summary_text': 'We used an entropy measure for aleatoric uncertainty and a variation ratio measure for model uncertainty. We applied the rejection rule from Equation (13) for each source of uncertainty.'},\n",
       " {'summary_text': 'We used the rejection rule from Equation (13) and KUE to quantify knowledge uncertainty. For the training procedure, a bootstrapapproach with 20 bootstrap samples was used, and the uncertainty measures were calcu-based.'},\n",
       " {'summary_text': 'Electronics 2022 ,11, 396 10 of 20. has an uncertainty function given by Equation (14). For the training procedure, a bootstrapapproach with 20 bootstrap samples was used.'},\n",
       " {'summary_text': 'In this section, we demonstrate the usefulness of uncertainty quantiﬁcation using the models’ combination. The performancemeasures from Equations (10)–(12) were also employed. In the case of the models'},\n",
       " {'summary_text': 'In this section, we demonstrate the usefulness of uncertainty quantiﬁcation using synthetic datasets and a benchmark dataset from the University of California Irvine (UCI) repository. We answer the following questions: How can UQ contribute to'},\n",
       " {'summary_text': 'Predicted uncertainties are often evaluated indirectly, since normally, data do not. We answer the following questions: How can UQ contribute to choosing the most suitable model for a given task? Can UQ be use to combine different models?'},\n",
       " {'summary_text': 'Predicted uncertainties are often evaluated indirectly, since normally, data do not contain information about any sort of ‘ground truth’ uncertainties. For this reason, theuse of a synthetic dataset can more easily provide an intuition about the different'},\n",
       " {'summary_text': 'A synthetic dataset can more easily provide an intuition about the different types ofuncertainties and their quantiﬁcation. In a controllable setting, we can alter the size of the datasets, evaluate the models’'},\n",
       " {'summary_text': '1.4. Uncertainty for Model Selection (Q1) To answer Q1, we generated a dataset composed of a total of 150,000 ten-dimensional models.'},\n",
       " {'summary_text': 'To answer Q1, we generated a dataset composed of a total of 150,000 ten-dimensional points corresponding to six different classes equally distributed. Features from each class were modeled using Gaussian, exponential, and uniform distributions. The distributions'},\n",
       " {'summary_text': 'The models were trained for different training sizes using a k-fold cross-validation. The distributions were randomly selected and could be unimodal or bimodal.'},\n",
       " {'summary_text': 'The models were trained for different training sizes using a k-fold cross-validation as the validation strategy. An exponential growth of the training samples was applied, starting with 50 samples per class.'},\n",
       " {'summary_text': 'For model training, different classiﬁers using a training size of 7692 samples were tested. An exponential growth of the training samples was applied, starting with 50 samples per class (training size equals 300 samples)'},\n",
       " {'summary_text': 'For model training, different classiﬁers using a training size of 7692 samples were tested. Since features data were simulated using Gaussian, expo-nential, and uniform distributions, a focus on Bayesian models'},\n",
       " {'summary_text': 'Bayesian models obtained higherbaseline accuracies than the other tested classiﬁers. Part of the features likelihoodwas modeled with the true data distribution.'},\n",
       " {'summary_text': 'The three classiﬁers highlighted in Table 1, with a similar baseline accuracy, were selected to continue the analysis. The NB classi ﬁer where the features likelihood was modeled with the true data distribution was chosen'},\n",
       " {'summary_text': 'The three classiﬁers highlighted in Table 1, with a similar baseline accuracy, were selected to continue the analysis. The features likelihood was assumed to be Gaussian, exponential or Bayes.'},\n",
       " {'summary_text': 'For this analysis, only aleatoric and model uncertainty measures were considered. The selected classiﬁers were trained using a bootstrap procedure with 20 bootstrap samples.'},\n",
       " {'summary_text': 'For this analysis, only aleatoric and model uncertainty measures were considered. A synthetic dataset without outliers was used. KUE would be near zero and would not bring relevant information for this analysis.'},\n",
       " {'summary_text': 'Figure 4 shows the rejection fraction and accuracy with the increasing number of training samples for the different tested models. The rejection fraction was obtainedusing both aleatoric and model uncertainty measures independently.'},\n",
       " {'summary_text': 'As previously mentioned, the model’s accuracy is often one of the most important. The rejection fraction was obtainedusing both aleatoric and model uncertainty measures independently. The nonrejectedaccuracy was obtained by rejecting all samples with'},\n",
       " {'summary_text': 'Model accuracy is often one of the most important elements to model selection. We argue that uncertainty quantiﬁcation methods should also be evaluated during the model’s training. accuracy was obtained by rejecting all samples with aleator'},\n",
       " {'summary_text': 'We argue that uncertainty quantiﬁcation methodsshould also be evaluated during the model’s training, to help us choose the right model. Different models can achieve the same accuracy, but with differentdegrees of uncertainty.'},\n",
       " {'summary_text': 'The three models obtained a baseline accuracy of 84%, approximately. Seen onlyfrom this point of view, the decision between the three models would be equal. However,observing the rejection fraction from uncertainty measures, it is easy to understand that'},\n",
       " {'summary_text': 'KDE model had higher model uncertainty compared with the other two models. The reason for this difference is that the KDE model is more complex, which means that it is more likely to be rejected.'},\n",
       " {'summary_text': 'KDE model is more complex, which means that it needs more data to correctly model the data distribution. The differences in the bootstrap samples have a high impact on the model.'},\n",
       " {'summary_text': ' differences in the bootstrap samples have a high impact on the model. The model. needs more data to correctly model the data distribution. Additionally, with the increasing number of training samples, we can observe the standard deviation.'},\n",
       " {'summary_text': 'The rejection fraction and accuracy values of the models are different depending on the bootstrap sample used to train the model. The standard deviation of the model is also classiﬁed differently depending on how many training samples are used.'},\n",
       " {'summary_text': 'Note a slight decrease in both the rejection fraction and accuracy values. Since the accuracy was approximately equal for the three models, the choice of a Gaussian NB would be probably preferable.'},\n",
       " {'summary_text': 'Table 1. Performance measures (mean standard deviation) for different models using a trainingsize of 7692 samples. The highlighted baseline accuracies represent the selected models that were considered for further analysis. The choice of a Gaussian NB would'},\n",
       " {'summary_text': 'The highlighted baseline accuracies represent the selected models that were considered for further analysis. The models attained similar accuracy values. size of 7692 samples. modelBaseline Nonrejected RejectionAccuracy Accuracy FractionGaussian Naive Bay'},\n",
       " {'summary_text': 'ModelBaseline Nonrejected RejectionAccuracy Accuracy FractionGaussian Naive Bayes 0.838.0.004 0.929.0 0.050.003 0.056.00.006'},\n",
       " {'summary_text': 'KDE Bayes 0.20.4Rejection Fraction 0.00.4Guassian Naive Bayes - Exponential NaiveBayes.'},\n",
       " {'summary_text': ' k-Nearest Neighbors 0.820 \\xa0\\xa0\\xa00.004 0.902 \\xa0œ.007 0.202 0.005 0.173 0.0100.00.20.4Rejection Fraction'},\n",
       " {'summary_text': 'Guassian Naive Bayes and Exponential Bayes models are used. The accuracy of the models is measured using a k-fold cross-validation.'},\n",
       " {'summary_text': 'Figure 4. Uncertainties’ rejection fraction and obtained accuracies using a k-fold cross-validation with an increasing number of training samples for 3 different models. The vertical line represents a training size that obtained a similar baseline'},\n",
       " {'summary_text': 'Electronics 2022 ,11, 396 12 of 20same dataset, which was veriﬁed with these experimental results. Increasing the number of samples is an option, and a different analysis can be performed.'},\n",
       " {'summary_text': ' increasing the number of training samples did not change the aleatoric uncertainty, making the rejection fractionmostly constant across the different training sizes. Contrarily, model uncertainty decreased with the increase of the number. of the training samples.'},\n",
       " {'summary_text': \"Model uncertainty decreased with the increase of the number of training samples. Analysis of model uncertainty can give us insights about the usefulness of adding more samples for the model's training.\"},\n",
       " {'summary_text': 'The decrease of model uncertainty had a clear increase in the baselineaccuracy. For the Gaussian NB model, from 103training samples, the baseline accuracy was equal for all bootstrap samples.'},\n",
       " {'summary_text': 'For the Gaussian NB model, from 103training samples, the baseline accuracy wasmostly constant and the decrease of model uncertainty was not signiﬁcant. This means that the model did not change using different bootstrap samples'},\n",
       " {'summary_text': 'The model did not change using different bootstrap samples, and the addition of new data did not improve the model’s performance. The decrease of model uncertainty was not signiﬁcant. mostly constant.'},\n",
       " {'summary_text': 'The nonrejected accuracy was always higher than the baseline accuracy, and it was mostly constant across the different training sizes. This is due to the high rejection fraction of model uncertainty.'},\n",
       " {'summary_text': 'The nonrejected accuracy was always higher than the baseline accuracy. The model uncertainty measure was in fact detecting the regions in the feature space responsible for a high number of misclassiﬁcations due to a poor model.'},\n",
       " {'summary_text': 'A poor model is responsible for a high number of misclassiﬁcations due to a poor model. Since different models werebased on different assumptions, we hypothesized that uncertainty measures can be used.'},\n",
       " {'summary_text': 'We hypothesized that uncertainty measures can be used to combine different models, producing a more robust model. We created a new dataset composed of 150,000 ten-dimensional points corresponding to different degrees of uncertainty.'},\n",
       " {'summary_text': 'A Gaussian NB and a KDE Bayes classiﬁer were trained with a bootstrap approach. to combine different models, producing a more robust model. A new dataset composed of 150,000 ten-dimensional points corresponding'},\n",
       " {'summary_text': 'A Gaussian NB and a KDE Bayes classiﬁer were trained with a bootstrap approach. Figure 5 shows the rejection fraction and accuracy with theincreasing number of training samples for both models.'},\n",
       " {'summary_text': 'Figure 5 shows the rejection fraction and accuracy with theincreasing number of training samples for both models. The Gaussian NB classiﬁer presented a high rejection fraction with 20 bootstrap samples.'},\n",
       " {'summary_text': 'The dataset was composed of features modelled as bimodal Gaussian distributions. The Gaussian NB classiﬁer presented a high rejection fraction due to aleatoric uncertainty. Contrarily, the KDE Bayes class'},\n",
       " {'summary_text': 'Both models started with a high. rejection fraction due to aleatoric uncertainty, since the overlap between the ﬁt distributions was high. Contrarily, the KDE Bayes classiﬁer deals well with bim'},\n",
       " {'summary_text': 'The Gaussian NB reached 105training samples with almost zero rejection. The KDE model, due to its complexity, still had a 10% rejection rate.'},\n",
       " {'summary_text': 'The Gaussian NB reached 105training samples with almost zero rejection. The KDE model, due to its complexity, still had a 10% rejection rate.'},\n",
       " {'summary_text': 'In the. summary, the Gaussian NB had high aleatoric uncertainty and low model uncertainty, and the. KDE Bayes classiﬁer had low aleatorIC uncertainty and high model uncertainty. To verify the potential'},\n",
       " {'summary_text': 'C1and c2represent the Gaussian NB and KDE Bayes classiﬁer and Fcis the uncer-tainty function deﬃned in Equation (14)'},\n",
       " {'summary_text': 'To validate that the proposed combination strategy performed better than the individual models, we applied the performance measures proposed in the work of Condessa et al. [33] .'},\n",
       " {'summary_text': 'To validate that the proposed combination strategy performed better than the individualmodels, we applied the performance measures proposed in the work of Condessa et al. [33] To compare the performance of the classifiers with rejection, 10% of the'},\n",
       " {'summary_text': 'To compare the performance of the classifiers with rejection, 10% of the rejected samples were used. The obtained results for the three models using a 10% rejection fractionare shown. The combination strategy using the uncertainties of both individual models was'},\n",
       " {'summary_text': 'The combination strategy using the uncertainties of both individual modelsElectronics 2022 ,11, 396 13 of 20. resulted in higher values for the three performance measures for classiﬁers with rejection.'},\n",
       " {'summary_text': 'The nonrejected accuracy, classiﬁcation quality, and rejection quality. namely the nonrejection accuracy, Classi ﬁcation quality and rejected quality. were calculated using a k-fold cross-'},\n",
       " {'summary_text': 'These preliminary results showed that the access to uncertainty estimations during training was better than previously thought. We used a k-fold cross-validation with an increasing number of training samples.'},\n",
       " {'summary_text': 'These preliminary results showed that the access to uncertainty estimations during the model’s development might be a useful source of information to develop more robust models. Although a simpler model, such as an NB classiﬁer,'},\n",
       " {'summary_text': 'Using uncertainty estimations can provide information about the speciﬁc regions where the model has low uncertainty. Using this information can be a useful source of information to develop more robust models.'},\n",
       " {'summary_text': 'Using uncertainty estimations can provide information about the speciﬁc regions where the model has low uncertainty. Using this information in combination with more powerful models can in fact increase the overallmodel performance.'},\n",
       " {'summary_text': 'The results were obtained using a rejection fraction of 10% and a training size of 90,000 samples. information in combination with more powerful models can in fact increase the overallmodel performance.'},\n",
       " {'summary_text': 'The results were obtained using a rejection fraction of 10% and a training size of 90,000 samples. a combination of both models.'},\n",
       " {'summary_text': 'To use ML in high-stakes applications, we need auditing tools to build conﬁdence in the models and their decisions. Besides quantiﬃcation metrics, visualization techniques, such as Uncertainty Visual'},\n",
       " {'summary_text': 'To use ML in high-stakes applications, we need auditing tools. Besides quantiﬁcation metrics, visualization techniques have been used to support the interpretability of classi \\ufb09cation models.'},\n",
       " {'summary_text': 'We quantiﬁed the different sources of uncertainty using visualization methods to assist in interpreting the models’ uncertainty during model development. For uncertainty visualization, the dataset from Section 4.1.2 with a training size of 4'},\n",
       " {'summary_text': 'For uncertainty visualization, the dataset from Section 4.1.2 was used. To simulate a realistic real-world setting, some outliers were addedElectronics 2022 ,11, 396 14 of 20.'},\n",
       " {'summary_text': 'To simulate a realistic real-world setting, some outliers were addedElectronics 2022 ,11, 396 14 of 20to the test set. 50 outliers per class were generated, resulting in a total of 300 outliers. 2'},\n",
       " {'summary_text': 'Fifty outliers per class were generated, resulting in a total of 300 outliers. Figure 6 shows an overview of the uncertainty estimation obtained during the model’s development.'},\n",
       " {'summary_text': 'In Figure 6, an overview of the uncertainty estimation obtained during the model’sdevelopment is shown. In this visualization, the x-axis represents the number of samples where samples are ordered by uncertainty. Using this ordering scheme, it'},\n",
       " {'summary_text': 'The size of each barrepresents the number of samples rejected by each type of uncertainty. Using this ordering scheme, it was possible to interpret the overall dataset uncertainty.'},\n",
       " {'summary_text': 'visualization allowed us to make some observations, such as noting that all rejected samples by model uncertainty were also rejected by aleatoric uncertainty. The size of each barrepresents the number of samples rejected by each type of uncertainty.'},\n",
       " {'summary_text': 'Aleatoric uncertainty. by model uncertainty were also rejected by aleatoric. uncertainty. Figure 6. Overview of the overall dataset uncertainty ( upper bar ) and uncertainties distribution by the uncertainty source ( lower bars ).'},\n",
       " {'summary_text': 'The uncertainty distribution can be applied to each individual class. Analyzing theuncertainty by each class can give us insights about the particular limitations of the model.'},\n",
       " {'summary_text': 'Note that almost all samples with knowledge uncertainty from Figure 6 were the generated. Analyzing theuncertainty by each class can give us insights about the particular limitations of the model.'},\n",
       " {'summary_text': 'Note that almost all samples with knowledge uncertainty from Figure 6 were the generatedoutliers and do not have a representation in Figure 7. Figure 7 presents the obtained uncertainty by uncertainty source and class. being used.'},\n",
       " {'summary_text': '0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 12.0 13.0 14.0 15.'},\n",
       " {'summary_text': '0.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8. # Samples1e3Class 2 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0Uncertain0. 0.0 2.0 4.0'},\n",
       " {'summary_text': 'Figure 7. Uncertainty distribution by uncertainty source and class. # Samples1e3Class 4.0 0.2 0.5 0.8 1.0 1.2 1.5 1.8# Samples'},\n",
       " {'summary_text': 'Figure 7. Uncertainty distribution by uncertainty source and class. # Uncertain Samples1e2e2.Electronics 2022 ,11, 396 15 of 20.'},\n",
       " {'summary_text': 'Figure 8 was obtained. In this visualization, the bar’s size represents how much the reliability of a prediction is questioned.'},\n",
       " {'summary_text': 'The bar’s size represents how much the model is conﬁdent or uncertain about a prediction by uncertainty type. For this purpose, using the uncertainty estimations for each type of uncertainty, Figure 8 was obtained.'},\n",
       " {'summary_text': 'The bars’ sizes where normalized between 0 and 1 by themaximum/minimum theoretical value for each uncertainty. 0 conﬁdence/uncertainty represents the obtained threshold for rejecting a sample.'},\n",
       " {'summary_text': 'Note that, in the aleatoric uncertainty, we visualize the prediction’s expected dataentropy. In Figure 8a, the prediction probability was near 100% (entropy of 0). In the case of Figure 8b'},\n",
       " {'summary_text': 'In the case of model uncertainty, we evaluated if a given. entropy, meaning that in Figure 8a, the prediction probability was near 100% (entropy of 0), was greater than the deﬁned threshold for rejection'},\n",
       " {'summary_text': 'In the case of model uncertainty, we evaluated if a givenprediction changes between different bootstrap samples. In Figure 8a, the prediction was the same in all bootstraps.'},\n",
       " {'summary_text': 'The bar’s size represents thenormalized variation ratios. prediction changes between different bootstrap samples. In Figure 8a, the prediction was the same in all bootstrapsamples, obtaining a maximum conﬁdence'},\n",
       " {'summary_text': 'The prediction is based on the total number of possibilities, which are given by the number of bootstrap samples. For instance, the maximum variation ratio was 0.8, and the prediction from. samples, obtaining a maximum con�'},\n",
       " {'summary_text': 'The knowledge uncertainty represents how much a prediction is similar to the training dataset, in terms of probability density. and the number of classes. For instance, this dataset had 6 classes and 20 bootstrap samples.'},\n",
       " {'summary_text': 'Figure 8a represents a prediction where the combination of the features densityresulted in a value close to the rejection threshold. Figure 8b obtained a variation ratio of 0.4. Finally, the knowledge uncertainty represents how much a prediction is'},\n",
       " {'summary_text': 'Figure 8a represents a prediction where the combination of the features density \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0resulted in a value close to the rejection threshold. In the case of Figure 8b, the sample was more similar to the datasets in the training dataset.'},\n",
       " {'summary_text': 'The sample was more similar to the training dataset. similar to this prediction. In the case of Figure 8b, the samples in the training datasets were more similar. to the sample in Figure 8a.'},\n",
       " {'summary_text': 'Figure 8. Prediction uncertainty. A conﬁdence value of 0 represents the obtained threshold for reject-phthaling a sample by the uncertainty source. Bars’ sizes are normalized between the maximum theoretical.'},\n",
       " {'summary_text': 'In order to broaden our analysis, we conducted an additional experiment with a Human Activity Recognition Dataset.'},\n",
       " {'summary_text': 'In order to broaden our analysis, we conducted an additional experiment with abenchmark dataset from the UCI repository. As a case study, we selected a HumanActivity Recognition (HAR) dataset that contains six classes.'},\n",
       " {'summary_text': 'We selected a HumanActivity Recognition (HAR) dataset from the UCI repository. HAR contains six classes ( walking, sitting, standing, and laying) recorded with the accelerometer andgyroscope smartphone sensors.'},\n",
       " {'summary_text': 'Movements recorded with the accelerometer andgyroscope smartphone sensors. The use of uncertainty measures for human movements analysis plays also an important role in the recognition of abnormal human activities.'},\n",
       " {'summary_text': 'The use of uncertainty measures for human movements analysis plays an important role in the recognition of abnormal human activities or the analysis, diagnosis, and monitoring of neurodegenerative conditions. The high number of available samples in this dataset allowed us to'},\n",
       " {'summary_text': 'High number of available samples allowed us to make a similar evaluation to the synthetic data. of neurodegenerative conditions [ 40]. For the data split into training and test sets, we used the available partition in the\\xa0repository'},\n",
       " {'summary_text': '70% of the volunteers were selected for generating the training data and 30% the test data. The original 561-feature vector with timeand frequency domain variables was reduced using features correlation and the sequential data.'},\n",
       " {'summary_text': 'Similar to Section 4.1.1, we applied a training size exponential growth, starting with 30% of the test data. The original 561-feature vector with timeand frequency domain variables was reduced using features correlation.'},\n",
       " {'summary_text': 'Similar to Section 4.1.1, we applied a training size exponential growth, starting with 300 samples (50 per class) until the maximum training size of 7352 samples. For model training, we tested different classi�'},\n",
       " {'summary_text': 'For model training, we tested different classiﬁers with 20 bootstrap samples. 300 samples (50 per class) until the maximum training size of 7352 samples. Table 3 shows the baseline accuracy, as well as the'},\n",
       " {'summary_text': 'Figure 9 shows these performance measures with the increased number of models. To visualize the behavior of accuracy and the corresponding rejection fraction, we selected the 4 models that obtained higher baseline accuracy.'},\n",
       " {'summary_text': 'Table 3. Performance measures for different models using a training size of 7352 samples and the Human Activity Recognition (HAR) dataset. Figure 9 shows these performance measures with the increased number of samples used to train the classi�'},\n",
       " {'summary_text': 'Performance measures for different models using a training size of 7352 samples and the Human Activity Recognition (HAR) dataset.'},\n",
       " {'summary_text': 'Gaussian Naive Bayes 0.89 0.90 0.03 0.01 0.10.3Rejection Fraction 0.87 0.94 0.13 0.06 0.00.3 Rejection'},\n",
       " {'summary_text': 'Support Vector Machines 0.91 0.93 0.06 0.10.20.3Rejection Fraction. Naive Bayes.'},\n",
       " {'summary_text': 'Figure 9. Uncertainties’ rejection fraction and obtained accuracies with the increasing number of training samples for the Human Activity Recognition (HAR) dataset.'},\n",
       " {'summary_text': 'For the HAR dataset, the rejection fraction obtained with both the aleatoric andknowledge uncertainty measures presented a low value for all training sizes and classiﬁers.'},\n",
       " {'summary_text': 'The rejection fraction obtained with both the aleatoric andknowledge uncertainty measures presented a low value for all training sizes and classiﬁersbeing analyzed. As expected, regarding the model uncertainty, the rejection fractiondecreased with'},\n",
       " {'summary_text': 'The rejection fraction progressivelydecreased with the increasing number of training samples. Morecomplex classiﬁers had a higher rejection fraction than simpler classi \\ufb09ers. Due to the lowobtained uncertainty (rejection'},\n",
       " {'summary_text': 'Using the visualization scheme presented in Section 4.1.3, Figure 10 shows the overall rejection fraction of complex classiﬁers. Due to the low uncertainty (rejection fraction < 4%) and satisfactory accuracy (baseline'},\n",
       " {'summary_text': 'Using the visualization scheme presented in Section 4.1.3, Figure 10 shows the overalldataset uncertainty and the uncertainty type distribution across the uncertain samples. Although only 4% of the test samples were rejected, we can make some'},\n",
       " {'summary_text': 'Although only 4% of the test samples were rejected, we can make some observations about the uncertain samples. The majority of uncertain samples rejected by aleatoric uncertaintywere also rejected by model uncertainty. Regions with an overlap between classes (ale'},\n",
       " {'summary_text': 'The majority of uncertain samples rejected by aleatoric uncertainty were also rejected by model uncertainty. Regions with an overlap between classes (aleatoricuncertainty) were also regions where it was expected that the model would change.'},\n",
       " {'summary_text': 'ForElectronics 2022 ,11, 396 17 of 20 samples had aleatoric uncertainty. It is possible that some samples shared both model and knowledge uncertainty.'},\n",
       " {'summary_text': 'It is possible that some samples shared both model and knowledgeuncertainty, which is also veriﬁed with Figure 10.0. Figure 11 shows the uncertainty distribution by class.'},\n",
       " {'summary_text': 'Figure 11 shows the uncertainty distribution by class. From it, we can conclude that Aleatoric uncertainty was presented only in walking.'},\n",
       " {'summary_text': 'Laying class did not have aleatoric or model uncertainty. However, it was the classwith the highest knowledge uncertainty. Both sitting and standing classes had a similar uncertainty.'},\n",
       " {'summary_text': 'Both sitting and standing classes had a similarpattern in terms of uncertainty. The sitting class was the one with the highest number of uncertain samples.'},\n",
       " {'summary_text': '0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 12.0 13.0 14.0 15.'},\n",
       " {'summary_text': '# Samples1e2Walking Downstairs. # Uncertain SamplesAleatoricModel. # Unsettled Samples.'},\n",
       " {'summary_text': 'To validate the combination strategy proposed in Section 4.1.2 using a real dataset, we decided to combine the two models with lower accuracy and higher uncertainty.'},\n",
       " {'summary_text': 'KDE Bayes model and logistic regression were combined for the different trainingsizes. To compare the performance of classiﬁers with rejection, we needed to ensure.'},\n",
       " {'summary_text': 'KDE Bayes model and logistic regression were combined for the different training sizes. To compare the performance of classiﬁers with rejection, we needed to ensure the same rejection fraction for the three classi ﬁ'},\n",
       " {'summary_text': 'The rejection fraction for the models’ combination, given by Equation (16), was employed for both the KDEBayes and logistic regression classiﬁers. Figure 12 shows the performance measures for the three classi'},\n",
       " {'summary_text': 'Figure 12 shows the performance measures for Bayes and logistic regression classiﬁers. Observing the results, we can conclude that the combination strategy outperformed the individual models for almost all training sizes and performance measures.'},\n",
       " {'summary_text': 'The combination strategy outperformed the individual classiﬁers for almost all training sizes and performance measures. The combination strategy resulted always in a lower rejection fraction thanElectronics 2022 ,11, 396 18 of 20.'},\n",
       " {'summary_text': 'The rejection fraction for the individual classiﬁers can be. conﬀrmed by analyzing Figures 9 and 12. Figure 9: The rejection fraction. Figure 12: The rejected fraction.'},\n",
       " {'summary_text': \"KDE Bayes Logistic Regression Models' CombinationFigure 12. Performance measures for classiﬁcation with rejection for different training sizes.\"},\n",
       " {'summary_text': 'As ML models are increasingly being integrated into safety-critical applications, in-corporating uncertainty quantiﬁcation estimates should become a required part of the ML.'},\n",
       " {'summary_text': 'ML models are increasingly being integrated into safety-critical applications. Uncertainty quantiﬁcation can be used for “uncertainty-informed’ decisions.'},\n",
       " {'summary_text': 'Uncertainty quantiﬁcation can be used for “uncertainty-informed” decisions. It can also support developers and end-users by increasing the interpretability of and trust in predictions.'},\n",
       " {'summary_text': 'We introduced a complete study focused on how uncertainty quantiﬁcation can be used in practice. We asked three research questions: How can UQ contribute to choosing the most suitable model for a given task? Can UQ be'},\n",
       " {'summary_text': 'Can uncertainty quantiﬁcation be used to combine models in a principled manner? Can visualization techniques improve UQ’sinterpretability? These questions were answered using a synthetic dataset and a HARdataset from the UC'},\n",
       " {'summary_text': 'We showed that uncertainty quantiﬁcation in combination with the model’s accuracy can give us important elements to choose the most suitablemodel. For instance, different classi ﬁers with the same accuracy can bene'},\n",
       " {'summary_text': 'The decision between different classiﬁers with the same accuracy can be made from the uncertainty quanti ﬁcation methods. If model uncertainty is high and the addition of new samples is possible, the increase of training samples'},\n",
       " {'summary_text': '. degrees of uncertainty can be preferable. If model uncertainty is high and theaddition of new samples is possible, the increase of training samples can reduce the modeluncertainty and consequently increase the model’s accuracy.'},\n",
       " {'summary_text': 'Using uncertainty as a complement of performance measures, we can make more informed decisions in model selection. In future work, we will explore how the UQ measures can be used in the context of active learning.'},\n",
       " {'summary_text': 'Active learning is the subset of ML in which the learning algorithm queries users to label training data. The choice of the samples to be labeled is achieved through measures that rank samples based on their potential informativeness.'},\n",
       " {'summary_text': 'Based on two models with different degrees of uncertainty, we proposed a naive training data set. The choice of the samples to be labeled is achieved through measures that rank samples based on their potential informativeness. Alternative ranking measures based on uncertainty'},\n",
       " {'summary_text': 'Based on two models with different degrees of uncertainty, we proposed a naiveuncertainty combination approach for models’ combination. The preliminary results showed that the combination strategy outperformed the individual strategy.'},\n",
       " {'summary_text': 'The preliminary results showed that the combination strategy outperformed the individual models. Although the proposed naive approach achieved good results, the combinationstrategy presented some limitations for its application.'},\n",
       " {'summary_text': 'The proposed naive approach achieved good results. The combinationstrategy presented some limitations for its application in a scenario with more than two models. A more versatile combination that considers the possibility of adding more models must be developed.'},\n",
       " {'summary_text': 'In the third question, we explored visualization techniques to assist in interpreting models. A more versatile combination that considers the possibility of adding moremodels and uses their degree of uncertainty must be developed.'},\n",
       " {'summary_text': 'In the third question, we explored visualization techniques to assist in interpreting classiﬁers’ uncertainty during the model’s development and also to audit a given decision. We will explore more comprehensive model combination methods to address'},\n",
       " {'summary_text': 'Understanding which type of uncertainty is present during the model’s development can give us insights into the limitations of each model and allow us to take actions in accordance. classiﬁers’ uncertainty.'},\n",
       " {'summary_text': 'In the context of prediction reliability, the proposed visualization techniques were used to access the interpretability of the rejection option in which a rejection may correspond to a low prediction probability. give us insights into the limitations of each model.'},\n",
       " {'summary_text': 'Electronics 2022 ,11, 396 19 of 20individual rejection threshold for each source of uncertainty may not be a reliable solution. access the interpretability of the rejection option in which a rejection may correspond to a low prediction probability.'},\n",
       " {'summary_text': ' individual rejection threshold for each source of uncertainty may not be a reliable solution. Deﬁning the best rejection threshold is still an open challenge. Future research will focus on understanding how optimization techniques can be used to establish the most adequate'},\n",
       " {'summary_text': 'We hope this paper might spark future research on how to consider uncertaintyquantiﬁcation as a tool to improve the ML model development lifecycle. future research will focus on understanding how optimization techniques can be used to establish the most'},\n",
       " {'summary_text': 'We hope this paper might spark future research on how to consider uncertaintyquantiﬁcation as a tool to improve the ML model development lifecycle.'},\n",
       " {'summary_text': 'The author is responsible for the conceptualization, methodology, and methodology of the study. The author also wrote the original draft preparation and editing of the manuscript.'},\n",
       " {'summary_text': 'R.S. (Raquel Simão) and H.G. (Ricardo Santos) have read and agreed to the published version of the manuscript.'},\n",
       " {'summary_text': 'This research was supported by the project Geolocation non-Assisted by GPSfor Mobile Networks in Indoor and Outdoor Environment (GARMIO)'},\n",
       " {'summary_text': 'This research was ﬁnancially supported by the project Geolocation non-Assisted by GPS for Mobile Networks in Indoor and Outdoor Environment (GARMIO)'},\n",
       " {'summary_text': 'Institutional Review Board Statement: not applicable. Informed Consent Statement: Not applicable. framed under the COMPETE 2020 (Operational Programme Competitiveness and Internationaliza-tion) and European Regional Development Fund (ERDF) from European'},\n",
       " {'summary_text': 'Data Availability Statement: Publicly available datasets were analyzed in this study. Code POCI-01-0247-FEDER-033479.'},\n",
       " {'summary_text': 'Publicly available datasets were analyzed in this study. These data can be found at the UC Irvine Machine Learning Repository.'},\n",
       " {'summary_text': \"The authors declare no conﬂict of interest. The study was published in the journal Computer Vision and Pattern Recognition. For more information, visit the study's website.\"},\n",
       " {'summary_text': 'The authors declare no conﬂict of interest. The study was published in the journal Systems Engineering and Artiﬁcial Intelligence.'},\n",
       " {'summary_text': '2. Reliable classiﬁcation: Classes that distinguish aleatoric and epistemic uncertainty. Learning. Inf. Sci. 2014 ,255, 16–29.'},\n",
       " {'summary_text': '3. Kompa, B.; Snoek, J.; Beam, A.L. Second opinion needed: Communicating uncertainty in medical machine learning. 4. Hüllermeier, E.; Waegeman, W. Ale'},\n",
       " {'summary_text': '4. Hüllermeier, E.; Waegeman, W. Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts andmethods. Mach. Learn. 2021 ,110, 457–506.'},\n",
       " {'summary_text': '5. Huang, Z.; Lam, H.; Zhang, H. Quantifying Epistemic Uncertainty in Deep Learning. arXiv 2021 , arXv:2110.12122. methods. 6. Holz'},\n",
       " {'summary_text': '7. Nguyen, V .L.; Shaker, M.H.; Hüllermeier, E. How to measure uncertainty in uncertainty sampling for active learning. Mach.Learn. 2021 , 1–34.'},\n",
       " {'summary_text': '8. Bota, P .; Silva, J.; Folgado, D.; Gamboa, H. A semi-automatic annotation approach for human activity recognition. Learn. 2021 , 1–34.'},\n",
       " {'summary_text': '9. Ghosh, S.; Liao, Q.V .; Ramamurthy, K.N.; Navratil, J.; Sattigeri, P.R.; Zhang, Y. Uncertainty Quant'},\n",
       " {'summary_text': 'Chung, Y.; Char, I.; Guo, H.; Schneider, J.; Neiswanger, W. Holistic Toolkit for Quantifying and Communicating the Uncertainty of AI. arXiv 2021 ,'},\n",
       " {'summary_text': 'Oala, L.; Murchison, A.G.; Balachandran, P. .; Choudhary, S.; Fehr, J.; Leite,. A.W.; Goldschmidt, P .'},\n",
       " {'summary_text': '12. Nakasi, R.; et al. Machine Learning for Health: Algorithm Auditing & Quality Control. J. Med. Syst. 2021 ,45, 1–8.'},\n",
       " {'summary_text': '12. Bosni´ c, Z.; Kononenko, I. An overview of advances in reliability estimation of individual predictions in machine learning. IntellData Anal. 2009 ,13, 385–401. 13. Tornede'},\n",
       " {'summary_text': '13. ArXiv 2021 , arXiv:2107.09414.14. Neto, M.P .; Paulovich, F.V . Explainable Matrix-Visualization for Global and Local Interpretability of'},\n",
       " {'summary_text': '15. Shaker, M.H.; Hüllermeier, E. Ensemble-based Uncertainty Quantification: Bayesian versus Credal Inference. arXiv 2021. 16. Malinin, A'},\n",
       " {'summary_text': 'Electronics 2022 ,11, 396 20 of 2017. Malinin, A.; Prokhorenkova, L.; Ustimenko, A. Uncertainty in gradient boosting via ensembles. arXiv'},\n",
       " {'summary_text': 'Decomposition of uncertainty in Bayesian deep learning forcient and risk-sensitive learning. In Proceedings of the International Conference on Machine Learning.'},\n",
       " {'summary_text': 'Shaker, M.H.; Hüllermeier, E. Aleatoric and epistemic uncertainty with random forests. efﬁcient and risk-sensitive learning. In Proceedings of the International Conference on Machine Learning,'},\n",
       " {'summary_text': 'ArXiv:2001.00893.19. Shaker, M.H.; Hüllermeier, E. Aleatoric and epistemic uncertainty with random forests. arXiv 2020. 10–15 July 2018;'},\n",
       " {'summary_text': 'Stat. Sci. 1986 ,1, 54–75. Quantifying Uncertainty to Improve Decision Making in Machine Learning. Sandia National Lab. (SNL-NM): Albuquerque, NM, USA, 2018.'},\n",
       " {'summary_text': '21. Uncertainty-based rejection wrappers for black-box classiﬁers. Technical Report; Sandia National Lab. (SNL-NM): Albuquerque, NM, USA, 2018.'},\n",
       " {'summary_text': '22. Recent advances in open set recognition: A survey. 23. Background Check: A general technique to build more reliable systems.'},\n",
       " {'summary_text': '23. Background Check: A general technique to build more reliableand versatile classiﬁers. In Proceedings of the 2016 IEEE 16th International Conference on Data Mining (ICDM), Barcelona, Spain, 12–15 December 2016'},\n",
       " {'summary_text': 'Pires, C.; Barandas, M.; Fernandes, L.; Folgado, D.; Gamboa, H. Towards Knowledge Uncertainty Estimation for Open Set Recognition. In Proceedings of the 2016 IEEE 16th'},\n",
       " {'summary_text': 'Pires, C.; Barandas, M.; Fernandes, L.; Folgado, D.; Gamboa, H. Towards Knowledge Uncertainty Estimation for Open SetRecognition. Mach. Learn. Knowl.'},\n",
       " {'summary_text': '25. Chow, C. On optimum recognition error and reject tradeoff. 26. Tax, D.M.; Duin, R.P. Growing a multi-class classiﬁer with a reject option.'},\n",
       " {'summary_text': '27. Fumera, G.; Roli, F.; Giacinto, G. Reject option with multiple thresholds. Pattern Recognit. Lett. 2000 ,33, 2099–2101. 26. Tax,'},\n",
       " {'summary_text': '27. Fumera, G.; Roli, F.; Giacinto, G. Reject option with multiple thresholds. Pattern Recognit. 2000 ,33, 2099–2101. arXiv 2021 , arX'},\n",
       " {'summary_text': 'In Proceedings of the International Conference on Machine Learning, Virtual, 13–15 April 2021; pp. 1507–1517.'},\n",
       " {'summary_text': '31. Uncertainty in Deep Learning. In Proceedings of the International Conference on Machine Learning, Virtual, 13–15 April 2021; pp. 1507–1517.32. Accuracy-rejection curves (ARCs) for'},\n",
       " {'summary_text': 'Accuracy-rejection curves (ARCs) for comparing classiﬁcation methods with a rejection option. In Proceedings of the third International Workshop on Machine Learning in Systems Biology, Ljubljana, Slovenia,'},\n",
       " {'summary_text': 'Phenomenon of classiﬁcation systems with rejection. reject option. In Proceedings of the third International Workshop on Machine Learning in Systems Biology, Ljubljana, Slovenia, September 2009.'},\n",
       " {'summary_text': '33. Condessa, F.; Bioucas-Dias, J.; Kovaˇ cevi´ c, J. Performance measures for classiﬁcation systems with rejection. Pattern Recognit. 2017 ,'},\n",
       " {'summary_text': '34. Kläs, M. Towards identifying and managing sources of uncertainty in AI and machine learning models. arXiv:1811.11669. 35. Campagner, A.; Cabitza, F.; C'},\n",
       " {'summary_text': 'InInternational Joint Conference on Rough Sets ; Springer: Berlin/Heidelberg, Germany, 2020; pp. 137–152.'},\n",
       " {'summary_text': 'Fischer, L.; Hammer, B.; Wersing, H. Optimal local rejection for classiﬁers. Neurocomputing 2016 ,214, 445–457. arXiv 2021, 36.'},\n",
       " {'summary_text': 'Fischer, L.; Hammer, B.; Wersing, H. Optimal local rejection for classiﬁers. Neurocomputing 2016 ,214, 445–457. arXiv:2110.11012'},\n",
       " {'summary_text': '39. Anguita, D.; Ghio, A.; Oneto, L.; Parra, X.; Reyes-Ortiz, J.L. A public domain dataset for human activity recognition usingsmartphones. Esann'},\n",
       " {'summary_text': 'The role of movementanalysis in diagnosing and monitoring neurodegenerative conditions. Insights from gait and postural control.'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a_summary(text,50,20) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [17/Jul/2024 21:19:04] \"GET / HTTP/1.1\" 200 -\n",
      "Your max_length is set to 50, but your input_length is only 49. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n",
      "127.0.0.1 - - [17/Jul/2024 21:20:55] \"POST /summarize HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "from werkzeug.utils import secure_filename\n",
    "import os\n",
    "import spacy\n",
    "import numpy as np\n",
    "from PyPDF2 import PdfReader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import pipeline\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Set the upload folder\n",
    "UPLOAD_FOLDER = 'uploads/'\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "\n",
    "# Ensure the upload folder exists\n",
    "if not os.path.exists(UPLOAD_FOLDER):\n",
    "    os.makedirs(UPLOAD_FOLDER)\n",
    "\n",
    "# Load models\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "summarizer = pipeline(task=\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Define summarization functions\n",
    "def e_summary(text, numsent):\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    vector = TfidfVectorizer()\n",
    "    top = vector.fit_transform(sentences)\n",
    "    sentence_scores = np.sum(top.toarray(), axis=1)\n",
    "    summary = [sentences[i] for i in sentence_scores.argsort()[-numsent:][::-1]]\n",
    "    return ' '.join(summary)\n",
    "\n",
    "def a_summary(text, max_length, min_length):\n",
    "    input_length = len(text)\n",
    "    default_max_length = max_length\n",
    "    max_length = min(default_max_length, input_length // 2)\n",
    "    min_length = min(min_length, max_length - 1)\n",
    "    nlp_result = summarizer(text, max_length=max_length, min_length=min_length, do_sample=False)\n",
    "    return nlp_result[0]['summary_text']\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('indexnlp.html')\n",
    "\n",
    "@app.route('/summarize', methods=['POST'])\n",
    "def summarize():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file part'})\n",
    "\n",
    "    file = request.files['file']\n",
    "    \n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'})\n",
    "\n",
    "    summary_type = request.form.get('summary_type')\n",
    "\n",
    "    if file:\n",
    "        filename = secure_filename(file.filename)\n",
    "        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "        file.save(file_path)\n",
    "\n",
    "   \n",
    "        raw_text = ''\n",
    "        if file_path.endswith('.txt'):\n",
    "            with open(file_path, 'r') as f:\n",
    "                raw_text = f.read()\n",
    "        elif file_path.endswith('.pdf'):\n",
    "            reader = PdfReader(file_path)\n",
    "            for page_num in range(len(reader.pages)):\n",
    "                page = reader.pages[page_num]\n",
    "                raw_text += page.extract_text()\n",
    "        else:\n",
    "            return jsonify({'error': 'Unsupported file format'})\n",
    "\n",
    "       \n",
    "        text_splitter = CharacterTextSplitter(\n",
    "            separator=\"\\n\",\n",
    "            chunk_size=400,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len,\n",
    "        )\n",
    "        texts = text_splitter.split_text(raw_text)\n",
    "\n",
    "   \n",
    "        if summary_type == 'extractive':\n",
    "            summaries = [e_summary(text, 3) for text in texts]  \n",
    "        elif summary_type == 'abstractive':\n",
    "            summaries = [a_summary(text, max_length=50, min_length=20) for text in texts]  \n",
    "        else:\n",
    "            return jsonify({'error': 'Invalid summary type selected'})\n",
    "\n",
    "        result = ' '.join(summaries)\n",
    "\n",
    "        return render_template('indexnlp.html', result=result)\n",
    "\n",
    "    return jsonify({'error': 'File upload failed'})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [18/Jul/2024 09:55:15] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jul/2024 09:55:49] \"POST /summarize_text HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jul/2024 09:56:08] \"POST /summarize_text HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "from werkzeug.utils import secure_filename\n",
    "import os\n",
    "import spacy\n",
    "import numpy as np\n",
    "from PyPDF2 import PdfReader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import pipeline\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "UPLOAD_FOLDER = 'uploads/'\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "\n",
    "\n",
    "if not os.path.exists(UPLOAD_FOLDER):\n",
    "    os.makedirs(UPLOAD_FOLDER)\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "summarizer = pipeline(task=\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "\n",
    "def e_summary(text, numsent):\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    vector = TfidfVectorizer()\n",
    "    top = vector.fit_transform(sentences)\n",
    "    sentence_scores = np.sum(top.toarray(), axis=1)\n",
    "    summary = [sentences[i] for i in sentence_scores.argsort()[-numsent:][::-1]]\n",
    "    return ' '.join(summary)\n",
    "\n",
    "def a_summary(text, max_length, min_length):\n",
    "    input_length = len(text)\n",
    "    default_max_length = max_length\n",
    "    max_length = min(default_max_length, input_length // 2)\n",
    "    min_length = min(min_length, max_length - 1)\n",
    "    nlp_result = summarizer(text, max_length=max_length, min_length=min_length, do_sample=False)\n",
    "    return nlp_result[0]['summary_text']\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('indexnlp.html')\n",
    "\n",
    "@app.route('/summarize_file', methods=['POST'])\n",
    "def summarize_file():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file part'})\n",
    "\n",
    "    file = request.files['file']\n",
    "    \n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'})\n",
    "\n",
    "    summary_type = request.form.get('summary_type')\n",
    "\n",
    "    if file:\n",
    "        filename = secure_filename(file.filename)\n",
    "        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "        file.save(file_path)\n",
    "\n",
    "       \n",
    "        raw_text = ''\n",
    "        if file_path.endswith('.txt'):\n",
    "            with open(file_path, 'r') as f:\n",
    "                raw_text = f.read()\n",
    "        elif file_path.endswith('.pdf'):\n",
    "            reader = PdfReader(file_path)\n",
    "            for page_num in range(len(reader.pages)):\n",
    "                page = reader.pages[page_num]\n",
    "                raw_text += page.extract_text()\n",
    "        else:\n",
    "            return jsonify({'error': 'Unsupported file format'})\n",
    "\n",
    "      \n",
    "        text_splitter = CharacterTextSplitter(\n",
    "            separator=\"\\n\",\n",
    "            chunk_size=400,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len,\n",
    "        )\n",
    "        texts = text_splitter.split_text(raw_text)\n",
    "\n",
    "    \n",
    "        if summary_type == 'extractive':\n",
    "            summaries = [e_summary(text, 3) for text in texts] \n",
    "        elif summary_type == 'abstractive':\n",
    "            summaries = [a_summary(text, max_length=130, min_length=30) for text in texts]  \n",
    "        else:\n",
    "            return jsonify({'error': 'Invalid summary type selected'})\n",
    "\n",
    "        result_file = ' '.join(summaries)\n",
    "\n",
    "        return render_template('indexnlp.html', result_file=result_file)\n",
    "\n",
    "    return jsonify({'error': 'File upload failed'})\n",
    "\n",
    "@app.route('/summarize_text', methods=['POST'])\n",
    "def summarize_text():\n",
    "    text = request.form.get('text')\n",
    "    summary_type = request.form.get('summary_type')\n",
    "\n",
    "    if not text:\n",
    "        return jsonify({'error': 'No text provided'})\n",
    "\n",
    "   \n",
    "    if summary_type == 'extractive':\n",
    "        result_text = e_summary(text, 3)  \n",
    "    elif summary_type == 'abstractive':\n",
    "        result_text = a_summary(text, max_length=130, min_length=30) \n",
    "    else:\n",
    "        return jsonify({'error': 'Invalid summary type selected'})\n",
    "\n",
    "    return render_template('indexnlp.html', result_text=result_text)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sarthak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
